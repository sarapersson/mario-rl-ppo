{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarapersson/mario-rl-ppo/blob/main/Mario_RL_PPO_Local_TrainingSuite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d14450ce",
      "metadata": {
        "id": "d14450ce"
      },
      "source": [
        "# Mario PPO - Local Training Suite\n",
        "\n",
        "This notebook trains a PPO agent (Stable-Baselines3, PyTorch) to play Super Mario Bros locally in Colab\n",
        "(no cloud storage required). Observations use 84x84 grayscale frames. Reward modes:\n",
        "- \"spec\" (default): +1 when forward progress occurs in a step, -15 on death, else 0 (matches project spec)\n",
        "- \"shaped\": dense progress shaping (+dx), step penalty, checkpoints, and death penalty\n",
        "\n",
        "Default action set: SIMPLE_MOVEMENT (7 actions).\n",
        "\n",
        "**Contents**\n",
        "- A0) Runtime hygiene and warning filters\n",
        "- A1) Pin NumPy version (requires runtime restart)\n",
        "- A2) Install dependencies\n",
        "- A3) Version information\n",
        "- B-LOCAL) Local storage in /content (no cloud)\n",
        "- C) Environment tools and wrappers (84x84 grayscale, reward mode toggle)\n",
        "- C1) Configuration panel\n",
        "- C2) Sanity check\n",
        "- C3) Action sets\n",
        "- D0) Hardware information\n",
        "- D) Training with auto-resume (warmup plus blocks)\n",
        "- T) Quick test (short training)\n",
        "- E) Learning analysis (reward curve)\n",
        "- F1) Video: trained model (60 s)\n",
        "- F2) Video: random agent (15 s)\n",
        "- G) Report generator (1–2 pages, covers all required points)\n",
        "- H) Export and import helpers\n",
        "- S-STATUS) Status overview (local artifacts)\n",
        "- S-SIZE) Size overview\n",
        "- S-LOCAL) Export - full bundle (ZIP)\n",
        "- S-LOCAL-LITE) Export - minimal bundle (ZIP)\n",
        "- J) Evaluation (N episodes)\n",
        "- J2) Evaluation with explicit distance (N episodes)\n",
        "- U-LOCAL-PACK) Prepare GitHub-ready zip (NO tokens)\n",
        "- P) Cleanup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8355652",
      "metadata": {
        "id": "c8355652"
      },
      "source": [
        "## A0) Runtime hygiene and warning filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f237f57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f237f57",
        "outputId": "dd56a0f3-f6cc-4119-f2ab-ec9e0ff906f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime hygiene and conservative settings have been applied.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, warnings\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "os.environ['MKL_NUM_THREADS'] = '1'\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "warnings.filterwarnings('ignore', category=UserWarning, message='.*deprecated.*')\n",
        "print('Runtime hygiene and conservative settings have been applied.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b3b06b3",
      "metadata": {
        "id": "4b3b06b3"
      },
      "source": [
        "## A1) Pin NumPy version (requires runtime restart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f06aaf33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f06aaf33",
        "outputId": "de077652-c66a-45d2-b9a1-078f8d41bec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "\u001b[33mWARNING: Skipping nes-py as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping gym-super-mario-bros as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: gym 0.25.2\n",
            "Uninstalling gym-0.25.2:\n",
            "  Successfully uninstalled gym-0.25.2\n",
            "Found existing installation: gymnasium 1.2.2\n",
            "Uninstalling gymnasium-1.2.2:\n",
            "  Successfully uninstalled gymnasium-1.2.2\n",
            "\u001b[33mWARNING: Skipping stable-baselines3 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping shimmy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: tensorflow 2.19.0\n",
            "Uninstalling tensorflow-2.19.0:\n",
            "  Successfully uninstalled tensorflow-2.19.0\n",
            "Found existing installation: tensorboard 2.19.0\n",
            "Uninstalling tensorboard-2.19.0:\n",
            "  Successfully uninstalled tensorboard-2.19.0\n",
            "Found existing installation: tensorboard-data-server 0.7.2\n",
            "Uninstalling tensorboard-data-server-0.7.2:\n",
            "  Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "\u001b[33mWARNING: Skipping tensorflow-estimator as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-io-gcs-filesystem as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m147.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m341.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, which is not installed.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "NumPy version: 2.0.2\n",
            "Please restart the runtime now: Runtime -> Restart session. After restarting, continue with section A2.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Pin NumPy to 1.26.4 to avoid ABI issues with older RL and game libraries.\n",
        "!python -m pip uninstall -y numpy nes-py gym-super-mario-bros gym gymnasium stable-baselines3 shimmy\n",
        "!python -m pip uninstall -y tensorflow tensorboard tensorboard-data-server tensorflow-estimator tensorflow-io-gcs-filesystem || true\n",
        "!python -m pip install --no-cache-dir numpy==1.26.4\n",
        "import numpy as np; print('NumPy version:', np.__version__)\n",
        "print('Please restart the runtime now: Runtime -> Restart session. After restarting, continue with section A2.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257160c0",
      "metadata": {
        "id": "257160c0"
      },
      "source": [
        "## A2) Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174d8f66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "174d8f66",
        "outputId": "580f12ae-54ab-4f5a-eee8-75133ac153ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting gym==0.26.2\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nes-py==8.2.1\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m206.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym-super-mario-bros==7.4.0\n",
            "  Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.2)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Collecting moviepy\n",
            "  Downloading moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting pillow\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (3.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m343.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (0.0.4)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym==0.26.2) (0.1.0)\n",
            "Collecting pyglet<=1.5.21,>=1.4.0 (from nes-py==8.2.1)\n",
            "  Downloading pyglet-1.5.21-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.12/dist-packages (from nes-py==8.2.1) (4.67.1)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.8.0+cu126)\n",
            "INFO: pip is looking at multiple versions of shimmy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting shimmy\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: decorator<6.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: python-dotenv>=0.10 in /usr/local/lib/python3.12/dist-packages (from moviepy) (1.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m253.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m387.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m432.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading moviepy-2.2.1-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m363.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m240.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m350.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m368.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym, nes-py\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827728 sha256=2e945974e82fa79f8564100b359b353a3bedd3a4b1703868c1e1e2e5842ea438\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x08q23aa/wheels/95/51/6c/9bb05ebbe7c5cb8171dfaa3611f32622ca4658d53f31c79077\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.2.1-cp312-cp312-linux_x86_64.whl size=535722 sha256=c8e60be4c467a78d0fa9a74856efafd58fb703d6f1533f71e7e8e6594e3e1bf9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x08q23aa/wheels/1f/a7/fa/9b0357f258d2e68bdc71df972e02418bceb02355ac1f365c59\n",
            "Successfully built gym nes-py\n",
            "Installing collected packages: pyglet, gymnasium, gym, shimmy, pandas, nes-py, moviepy, matplotlib, gym-super-mario-bros, stable-baselines3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 1.0.3\n",
            "    Uninstalling moviepy-1.0.3:\n",
            "      Successfully uninstalled moviepy-1.0.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2 gym-super-mario-bros-7.4.0 gymnasium-0.29.1 matplotlib-3.10.7 moviepy-2.2.1 nes-py-8.2.1 pandas-2.3.3 pyglet-1.5.21 shimmy-1.3.0 stable-baselines3-2.7.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python -m pip install -U --no-cache-dir \\\n",
        "  stable-baselines3 \\\n",
        "  gymnasium==0.29.1 shimmy \\\n",
        "  gym==0.26.2 \\\n",
        "  nes-py==8.2.1 gym-super-mario-bros==7.4.0 \\\n",
        "  imageio imageio-ffmpeg moviepy pillow markdown pandas matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89a88196",
      "metadata": {
        "id": "89a88196"
      },
      "source": [
        "## A3) Version information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b92bd7a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b92bd7a7",
        "outputId": "5dccb80c-0e96-461a-89c0-b63288dcb48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 1.26.4\n",
            "Gym: 0.26.2\n",
            "Gymnasium: 0.29.1\n",
            "Stable-Baselines3: 2.7.0\n",
            "PyTorch CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy, gym, gymnasium, stable_baselines3, torch\n",
        "print('NumPy:', numpy.__version__)\n",
        "print('Gym:', gym.__version__)\n",
        "print('Gymnasium:', gymnasium.__version__)\n",
        "print('Stable-Baselines3:', stable_baselines3.__version__)\n",
        "print('PyTorch CUDA available:', torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1a0762c",
      "metadata": {
        "id": "f1a0762c"
      },
      "source": [
        "## B-LOCAL) Local storage in /content (no cloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c6318e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c6318e2",
        "outputId": "65a973f7-9c59-45a1-8b75-fae653eb461b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local storage has been initialized at: /content/mario_rl_local\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "base_dir = \"/content/mario_rl_local\"\n",
        "for p in (\"logs\",\"models\",\"models/exports\",\"videos\",\"plots\",\"reports\"):\n",
        "    Path(f\"{base_dir}/{p}\").mkdir(parents=True, exist_ok=True)\n",
        "BASE = base_dir\n",
        "print('Local storage has been initialized at:', base_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e99c0a",
      "metadata": {
        "id": "14e99c0a"
      },
      "source": [
        "## C) Environment tools and wrappers (84x84 grayscale, reward mode toggle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f6c1f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10f6c1f3",
        "outputId": "6b1ed9d8-03ee-4a15-f5c5-3757583574f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Info: nes-py hotfix could not be applied: module 'nes_py._rom' has no attribute 'Rom'\n",
            "JoypadSpace.reset patched to ignore seed/options.\n",
            "Environment utilities initialized. REWARD_MODE = spec\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Environment wrappers and utilities\n",
        "# - 84x84 grayscale frames (channel last)\n",
        "# - Frame skip and action repeat\n",
        "# - Reward modes: \"spec\" (default) or \"shaped\"\n",
        "# - Early stop on stagnation and max episode length cap\n",
        "# - Compatibility fixes for nes-py overflow and JoypadSpace.reset kwargs\n",
        "\n",
        "import os, numpy as np, torch, torch.nn as nn\n",
        "from PIL import Image\n",
        "\n",
        "import gym_super_mario_bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT\n",
        "\n",
        "import gymnasium as gymn\n",
        "from gymnasium import spaces as gspaces\n",
        "\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import (\n",
        "    DummyVecEnv, SubprocVecEnv, VecFrameStack, VecTransposeImage, VecEnvWrapper\n",
        ")\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# Default reward mode and action set\n",
        "REWARD_MODE = \"spec\"   # \"spec\" or \"shaped\"\n",
        "\n",
        "# nes-py overflow hotfix\n",
        "try:\n",
        "    import nes_py._rom as _rom\n",
        "    def _kb(x): return int(x) * (1<<10)\n",
        "    _rom.Rom.prg_rom_stop = property(lambda self: int(self.prg_rom_start) + _kb(self.prg_rom_size))\n",
        "    if hasattr(_rom.Rom,'chr_rom_stop'):\n",
        "        _rom.Rom.chr_rom_stop = property(lambda self: int(self.chr_rom_start) + _kb(self.chr_rom_size))\n",
        "    print('nes-py overflow hotfix active.')\n",
        "except Exception as e:\n",
        "    print('Info: nes-py hotfix could not be applied:', e)\n",
        "\n",
        "def convert_spaces_to_gymnasium(env):\n",
        "    if not isinstance(env.observation_space, gspaces.Space):\n",
        "        os_ = env.observation_space\n",
        "        env.observation_space = gspaces.Box(low=0, high=255, shape=os_.shape, dtype=np.uint8)\n",
        "    if not isinstance(env.action_space, gspaces.Space):\n",
        "        a = env.action_space\n",
        "        if getattr(a, 'n', None) is not None:\n",
        "            env.action_space = gspaces.Discrete(a.n)\n",
        "    return env\n",
        "\n",
        "class DropResetKwargs(gymn.Wrapper):\n",
        "    def reset(self, *args, **kwargs):\n",
        "        kwargs.pop('seed', None); kwargs.pop('options', None)\n",
        "        out = self.env.reset()\n",
        "        return out if (isinstance(out, tuple) and len(out)==2) else (out, {})\n",
        "\n",
        "class GrayscaleResize84(gymn.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env); self.observation_space = gspaces.Box(0,255,shape=(84,84,1),dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        arr = np.array(Image.fromarray(obs).convert('L').resize((84,84)), dtype=np.uint8)\n",
        "        return arr[...,None]\n",
        "\n",
        "class FrameSkip(gymn.Wrapper):\n",
        "    def __init__(self, env, frame_skip=4): super().__init__(env); self.frame_skip=frame_skip\n",
        "    def step(self, a):\n",
        "        R=0.0; inf={}; d=t=False\n",
        "        for _ in range(self.frame_skip):\n",
        "            o,r,d,t,inf = self.env.step(a); R+=r\n",
        "            if d or t: break\n",
        "        return o,R,d,t,inf\n",
        "\n",
        "class ActionRepeatWrapper(gymn.Wrapper):\n",
        "    def __init__(self, env, action_repeat=2): super().__init__(env); self.action_repeat=action_repeat\n",
        "    def step(self, a):\n",
        "        R=0.0; inf={}; d=t=False\n",
        "        for _ in range(self.action_repeat):\n",
        "            o,r,d,t,inf = self.env.step(a); R+=r\n",
        "            if d or t: break\n",
        "        return o,R,d,t,inf\n",
        "\n",
        "class MaxStepsWrapper(gymn.Wrapper):\n",
        "    def __init__(self, env, max_steps=3000): super().__init__(env); self.max_steps=max_steps; self.t=0\n",
        "    def reset(self, **kw): self.t=0; return super().reset(**kw)\n",
        "    def step(self, a):\n",
        "        o,r,d,t,inf = self.env.step(a); self.t+=1\n",
        "        if self.t>=self.max_steps and not (d or t):\n",
        "            t=True; inf=dict(inf); inf['TimeLimit.truncated']=True\n",
        "        return o,r,d,t,inf\n",
        "\n",
        "class StagnationEarlyStop(gymn.Wrapper):\n",
        "    def __init__(self, env, patience=120): super().__init__(env); self.p=patience; self.prev=0; self.no=0\n",
        "    def reset(self, **kw): out=super().reset(**kw); self.prev=0; self.no=0; return out\n",
        "    def step(self, a):\n",
        "        o,r,d,t,inf = self.env.step(a); x=inf.get('x_pos',0)\n",
        "        if x>self.prev: self.no=0; self.prev=x\n",
        "        else:\n",
        "            self.no+=1\n",
        "            if self.no>=self.p and not (d or t):\n",
        "                t=True; inf=dict(inf); inf['EarlyStop.stagnation']=True\n",
        "        return o,r,d,t,inf\n",
        "\n",
        "class DeathPenaltyReward(gymn.Wrapper):\n",
        "    def step(self, a):\n",
        "        o,r,d,t,inf = self.env.step(a)\n",
        "        if d and not inf.get('flag_get'): r -= 15.0\n",
        "        return o,r,d,t,inf\n",
        "\n",
        "class ProgressShapingReward(gymn.Wrapper):\n",
        "    def __init__(self, env, progress_coef=0.5, per_step_penalty=0.01, progress_checkpoints=(120,300,700), checkpoint_bonus=(5.0,8.0,12.0)):\n",
        "        super().__init__(env)\n",
        "        self.c=progress_coef; self.ps=per_step_penalty\n",
        "        self.ck=list(progress_checkpoints); self.cb=list(checkpoint_bonus)\n",
        "        self.hit=None; self.prev=0\n",
        "    def reset(self, **kw): out=super().reset(**kw); self.hit=[False]*len(self.ck); self.prev=0; return out\n",
        "    def step(self, a):\n",
        "        o,r,d,t,inf = self.env.step(a); x=inf.get('x_pos',0); dx=max(0,x-self.prev)\n",
        "        shaped = r + self.c*dx - self.ps\n",
        "        for i,g in enumerate(self.ck):\n",
        "            if not self.hit[i] and self.prev < g <= x:\n",
        "                shaped += self.cb[i]; self.hit[i]=True\n",
        "        self.prev=x; return o,shaped,d,t,inf\n",
        "\n",
        "class SpecReward(gymn.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env); self.prev_x = 0\n",
        "    def reset(self, **kw):\n",
        "        obs, info = self.env.reset()\n",
        "        self.prev_x = info.get('x_pos', 0)\n",
        "        return obs, info\n",
        "    def step(self, a):\n",
        "        o, r, d, t, inf = self.env.step(a)\n",
        "        x = inf.get('x_pos', 0); dx = max(0, x - self.prev_x)\n",
        "        shaped = 1.0 if dx > 0 else 0.0\n",
        "        if d and not inf.get('flag_get', False):\n",
        "            shaped -= 15.0\n",
        "        self.prev_x = x\n",
        "        return o, shaped, d, t, inf\n",
        "\n",
        "class SmallCNNFeatures(BaseFeaturesExtractor):\n",
        "    def __init__(self, observation_space, features_dim=128):\n",
        "        super().__init__(observation_space, features_dim); C = observation_space.shape[0]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(C,16,8,4), nn.ReLU(),\n",
        "            nn.Conv2d(16,32,4,2), nn.ReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        with torch.no_grad(): n_flat = self.cnn(torch.zeros(1,C,84,84)).shape[1]\n",
        "        self.linear = nn.Sequential(nn.Linear(n_flat, features_dim), nn.ReLU())\n",
        "    def forward(self, x): return self.linear(self.cnn(x.float()/255.0))\n",
        "\n",
        "def make_env_compact(render_mode=None, action_set='SIMPLE_MOVEMENT', frame_skip=4, action_repeat=2):\n",
        "    e = gym_super_mario_bros.make('SuperMarioBros-1-1-v3', apply_api_compatibility=True, render_mode=render_mode)\n",
        "    e = JoypadSpace(e, RIGHT_ONLY if action_set=='RIGHT_ONLY' else SIMPLE_MOVEMENT)\n",
        "    e = ActionRepeatWrapper(e, action_repeat=action_repeat)\n",
        "    e = FrameSkip(e, frame_skip=frame_skip)\n",
        "    e = GrayscaleResize84(e)\n",
        "    e = MaxStepsWrapper(e, 3000)\n",
        "    e = StagnationEarlyStop(e, 120)\n",
        "    if REWARD_MODE == \"spec\":\n",
        "        e = SpecReward(e)\n",
        "    else:\n",
        "        e = ProgressShapingReward(e, progress_coef=0.5, per_step_penalty=0.01,\n",
        "                                  progress_checkpoints=(120,300,700), checkpoint_bonus=(5,8,12))\n",
        "        e = DeathPenaltyReward(e)\n",
        "    e = convert_spaces_to_gymnasium(e)\n",
        "    e = Monitor(e)\n",
        "    e = DropResetKwargs(e)\n",
        "    return e\n",
        "\n",
        "class VecDropResetKwargs(VecEnvWrapper):\n",
        "    def reset(self, **kwargs):\n",
        "        kwargs.pop(\"seed\", None); kwargs.pop(\"options\", None)\n",
        "        try: return self.venv.reset(**kwargs)\n",
        "        except TypeError: return self.venv.reset()\n",
        "    def step_async(self, actions): return self.venv.step_async(actions)\n",
        "    def step_wait(self): return self.venv.step_wait()\n",
        "\n",
        "def make_vector_env(num_envs, log_dir, render_mode=None, action_set='SIMPLE_MOVEMENT', frame_skip=4, action_repeat=2, frame_stack=2, prefer_subproc=True):\n",
        "    if prefer_subproc and num_envs>1:\n",
        "        try:\n",
        "            v = make_vec_env(make_env_compact, n_envs=num_envs, vec_env_cls=SubprocVecEnv, monitor_dir=log_dir,\n",
        "                             env_kwargs=dict(render_mode=render_mode, action_set=action_set, frame_skip=frame_skip, action_repeat=action_repeat))\n",
        "            print(f'SubprocVecEnv created: {num_envs}')\n",
        "        except Exception as e:\n",
        "            print('Info: SubprocVecEnv failed, falling back to DummyVecEnv:', e)\n",
        "            v = make_vec_env(make_env_compact, n_envs=num_envs, vec_env_cls=DummyVecEnv, monitor_dir=log_dir,\n",
        "                             env_kwargs=dict(render_mode=render_mode, action_set=action_set, frame_skip=frame_skip, action_repeat=action_repeat))\n",
        "            print(f'DummyVecEnv created: {num_envs}')\n",
        "    else:\n",
        "        v = make_vec_env(make_env_compact, n_envs=1, vec_env_cls=DummyVecEnv, monitor_dir=log_dir,\n",
        "                         env_kwargs=dict(render_mode=render_mode, action_set=action_set, frame_skip=frame_skip, action_repeat=action_repeat))\n",
        "        print('DummyVecEnv created: 1')\n",
        "    v = VecFrameStack(v, n_stack=frame_stack, channels_order=\"last\"); v = VecTransposeImage(v)\n",
        "    try:\n",
        "        v = VecDropResetKwargs(v); print(\"VecDropResetKwargs active.\")\n",
        "    except Exception as e:\n",
        "        print(\"Info: VecDropResetKwargs could not be activated:\", e)\n",
        "    return v\n",
        "\n",
        "# Patch JoypadSpace.reset to ignore seed and options kwargs\n",
        "if not getattr(JoypadSpace.reset, \"_patched_ignore_seed\", False):\n",
        "    _orig_reset = JoypadSpace.reset\n",
        "    def _reset_ignore_seed(self, *args, **kwargs):\n",
        "        kwargs.pop(\"seed\", None); kwargs.pop(\"options\", None)\n",
        "        return _orig_reset(self)\n",
        "    _reset_ignore_seed._patched_ignore_seed = True\n",
        "    JoypadSpace.reset = _reset_ignore_seed\n",
        "    print(\"JoypadSpace.reset patched to ignore seed/options.\")\n",
        "\n",
        "print('Environment utilities initialized. REWARD_MODE =', REWARD_MODE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b3b9463",
      "metadata": {
        "id": "5b3b9463"
      },
      "source": [
        "## C1) Configuration panel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b1cbc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14b1cbc2",
        "outputId": "3415de47-ee24-4abb-9834-fefd7e1cb52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration: action_set = SIMPLE_MOVEMENT | num_envs = 1 | frame_stack = 2 | action_repeat = 2 | frame_skip(warmup) = 4 | reward_mode = spec\n"
          ]
        }
      ],
      "source": [
        "\n",
        "action_set    = 'SIMPLE_MOVEMENT'  # 'SIMPLE_MOVEMENT' (default) or 'RIGHT_ONLY'\n",
        "num_envs      = 1\n",
        "frame_stack   = 2\n",
        "action_repeat = 2\n",
        "frame_skip    = 4\n",
        "print('Configuration:',\n",
        "      'action_set =', action_set,\n",
        "      '| num_envs =', num_envs,\n",
        "      '| frame_stack =', frame_stack,\n",
        "      '| action_repeat =', action_repeat,\n",
        "      '| frame_skip(warmup) =', frame_skip,\n",
        "      '| reward_mode =', REWARD_MODE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b4e7fe4",
      "metadata": {
        "id": "8b4e7fe4"
      },
      "source": [
        "## C2) Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464156fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "464156fe",
        "outputId": "01f8cb08-f829-4f4b-b874-576785a6ce4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyVecEnv created: 1\n",
            "VecDropResetKwargs active.\n",
            "Observation space: Box(0, 255, (2, 84, 84), uint8) | Action space: Discrete(7)\n",
            "Sanity check completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.spec to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.spec` for environment variables or `env.get_wrapper_attr('spec')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "venv = make_vector_env(1, f\"{base_dir}/logs/_sanity\", render_mode=None,\n",
        "                       action_set=('RIGHT_ONLY' if action_set=='RIGHT_ONLY' else 'SIMPLE_MOVEMENT'),\n",
        "                       frame_skip=frame_skip, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "print('Observation space:', venv.observation_space, '| Action space:', venv.action_space)\n",
        "venv.close(); print('Sanity check completed.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b90f8d9",
      "metadata": {
        "id": "3b90f8d9"
      },
      "source": [
        "## C3) Action sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "574ff68b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "574ff68b",
        "outputId": "00875d4e-a223-48df-f112-a65159b4c522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RIGHT_ONLY (n = 5): [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B']]\n",
            "SIMPLE_MOVEMENT (n = 7): [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left']]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT\n",
        "print('RIGHT_ONLY (n = 5):', RIGHT_ONLY)\n",
        "print('SIMPLE_MOVEMENT (n = 7):', SIMPLE_MOVEMENT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0acb6ef",
      "metadata": {
        "id": "c0acb6ef"
      },
      "source": [
        "## D0) Hardware information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f83de041",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f83de041",
        "outputId": "5980417d-deb2-4387-b920-2b8a54ace666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch CUDA availability: True\n",
            "GPU 0: Tesla T4 (UUID: GPU-53b67c7a-e7c4-aa4f-3655-a6c8f4728b61)\n",
            "Sun Nov 16 23:44:09 2025       \n",
            "Selected device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch, shutil, subprocess\n",
        "print('PyTorch CUDA availability:', torch.cuda.is_available())\n",
        "if shutil.which('nvidia-smi'):\n",
        "    print(subprocess.run(['nvidia-smi','-L'], capture_output=True, text=True).stdout.strip())\n",
        "    print(subprocess.run(['nvidia-smi'], capture_output=True, text=True).stdout.splitlines()[0])\n",
        "print('Selected device:', 'cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c9edc96",
      "metadata": {
        "id": "3c9edc96"
      },
      "source": [
        "## D) Training with auto-resume (warmup plus blocks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e480650",
      "metadata": {
        "id": "8e480650"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from shutil import copy2\n",
        "import os, json, numpy as np, random, warnings, torch\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=r\".*env\\.spec.*deprecated.*\")\n",
        "\n",
        "def find_latest_export_zip(base_dir_str):\n",
        "    base = Path(base_dir_str)\n",
        "    if not base.exists(): return None\n",
        "    exp = sorted((base/\"models\"/\"exports\").glob(\"*.zip\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    if exp: return str(exp[0])\n",
        "    runs = sorted((base/\"models\").glob(\"*\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    for r in runs:\n",
        "        bm = r / \"best_model.zip\"\n",
        "        if bm.exists(): return str(bm)\n",
        "    zips = sorted((base/\"models\").glob(\"*/*.zip\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return str(zips[0]) if zips else None\n",
        "\n",
        "def model_meta_path(zip_path):\n",
        "    return Path(zip_path).with_suffix(\".meta.json\")\n",
        "\n",
        "def read_model_meta(zip_path):\n",
        "    mp = model_meta_path(zip_path)\n",
        "    if mp.exists():\n",
        "        try: return json.loads(mp.read_text())\n",
        "        except Exception: pass\n",
        "    return None\n",
        "\n",
        "def write_model_meta(zip_path, action_set, frame_stack, action_repeat, reward_mode):\n",
        "    mp = model_meta_path(zip_path)\n",
        "    mp.write_text(json.dumps(dict(action_set=action_set,\n",
        "                                  frame_stack=int(frame_stack),\n",
        "                                  action_repeat=int(action_repeat),\n",
        "                                  reward_mode=str(reward_mode)), indent=2), encoding=\"utf-8\")\n",
        "    print(\"Model metadata written:\", mp.name)\n",
        "\n",
        "def export_model_copy(src_path, tag, base_dir_str, run_id):\n",
        "    dst = Path(base_dir_str)/\"models\"/\"exports\"/f\"{run_id}_{tag}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n",
        "    copy2(src_path, dst); print(\"Model exported:\", dst.name); return str(dst)\n",
        "\n",
        "def infer_action_set_from_model(zip_path):\n",
        "    m = read_model_meta(zip_path)\n",
        "    if m and m.get(\"action_set\") in (\"RIGHT_ONLY\",\"SIMPLE_MOVEMENT\"):\n",
        "        print(\"Action set from metadata:\", m[\"action_set\"]); return m[\"action_set\"]\n",
        "    tmp = PPO.load(zip_path, device=\"cpu\"); n_act = tmp.action_space.n\n",
        "    det = \"RIGHT_ONLY\" if n_act==5 else (\"SIMPLE_MOVEMENT\" if n_act==7 else None)\n",
        "    print(\"Action set inferred from action space:\", det); return det\n",
        "\n",
        "def make_training_bundle(frame_skip_used, ent_coef, action_set_used, num_envs, log_dir, action_repeat, frame_stack):\n",
        "    venv     = make_vector_env(num_envs, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=(num_envs>1))\n",
        "    eval_env = make_vector_env(1,       log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "    policy_kwargs = dict(features_extractor_class=SmallCNNFeatures, features_extractor_kwargs=dict(features_dim=128), net_arch=[128, 128])\n",
        "    model = PPO(\"CnnPolicy\", venv, policy_kwargs=policy_kwargs, n_steps=256, batch_size=512, n_epochs=3,\n",
        "                learning_rate=3e-4, gamma=0.999, gae_lambda=0.95, clip_range=0.2, ent_coef=ent_coef, vf_coef=0.5,\n",
        "                device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"), verbose=1, seed=42)\n",
        "    eval_cb = EvalCallback(eval_env, best_model_save_path=model_dir, log_path=log_dir, eval_freq=60000, n_eval_episodes=3, deterministic=True)\n",
        "    return model, venv, eval_env, eval_cb\n",
        "\n",
        "def learn_with_restart(model, total_timesteps, eval_cb, frame_skip_used, phase_tag, action_set_used, log_dir, action_repeat, frame_stack):\n",
        "    start = getattr(model, \"num_timesteps\", 0)\n",
        "    try:\n",
        "        model.learn(total_timesteps=total_timesteps, reset_num_timesteps=False, callback=eval_cb)\n",
        "        return\n",
        "    except (EOFError, BrokenPipeError, ConnectionResetError) as e:\n",
        "        print(f\"{phase_tag}: worker crashed ({type(e).__name__}), attempting restart.\")\n",
        "        try:\n",
        "            old_env = model.get_env(); n_model_envs = getattr(old_env, \"num_envs\", 1)\n",
        "        except Exception:\n",
        "            n_model_envs = 1\n",
        "        try: model.get_env().close()\n",
        "        except Exception: pass\n",
        "        train_re = make_vector_env(n_model_envs, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "        eval_re  = make_vector_env(1, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "        model.set_env(train_re)\n",
        "        cb2 = EvalCallback(eval_re, best_model_save_path=model_dir, log_path=log_dir, eval_freq=60000, n_eval_episodes=3, deterministic=True)\n",
        "        done_so_far = max(0, getattr(model, \"num_timesteps\", 0) - start)\n",
        "        remaining   = max(0, total_timesteps - done_so_far)\n",
        "        if remaining > 0:\n",
        "            model.learn(total_timesteps=remaining, reset_num_timesteps=False, callback=cb2)\n",
        "        try: train_re.close(); eval_re.close()\n",
        "        except Exception: pass\n",
        "\n",
        "from pathlib import Path\n",
        "run_id  = datetime.now().strftime(\"ppo_local_%Y%m%d_%H%M%S\")\n",
        "log_dir   = f\"{base_dir}/logs/{run_id}\"\n",
        "model_dir = f\"{base_dir}/models/{run_id}\"\n",
        "for d in (log_dir, model_dir): Path(d).mkdir(parents=True, exist_ok=True)\n",
        "Path(f\"{base_dir}/models/exports\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "import random\n",
        "np.random.seed(42); random.seed(42); torch.manual_seed(42)\n",
        "\n",
        "num_blocks           = 2\n",
        "timesteps_per_block  = 30000\n",
        "warmup_timesteps     = 10000\n",
        "warmup_frame_skip    = int(globals().get('frame_skip',4))\n",
        "warmup_ent_coef      = 0.02\n",
        "\n",
        "resume_zip = find_latest_export_zip(base_dir)\n",
        "if resume_zip is not None:\n",
        "    det = infer_action_set_from_model(resume_zip)\n",
        "    if det and det != globals().get('action_set'):\n",
        "        print(\"Notebook action_set differs from model; switching notebook to model action_set.\")\n",
        "        action_set = det\n",
        "\n",
        "if resume_zip is None:\n",
        "    print(f\"Warmup: frame_skip={warmup_frame_skip}, ent_coef={warmup_ent_coef}, action_set={action_set}, reward_mode={REWARD_MODE}.\")\n",
        "    model, venv, eval_env, eval_cb = make_training_bundle(warmup_frame_skip, warmup_ent_coef, action_set, num_envs, log_dir, action_repeat, frame_stack)\n",
        "    learn_with_restart(model, warmup_timesteps, eval_cb, warmup_frame_skip, \"warmup\", action_set, log_dir, action_repeat, frame_stack)\n",
        "    ckpt_boot = Path(model_dir)/\"ckpt_bootstrap.zip\"; model.save(str(ckpt_boot)); print(\"Warmup checkpoint saved:\", ckpt_boot.name)\n",
        "    resume_zip = export_model_copy(ckpt_boot, \"bootstrap\", base_dir, run_id)\n",
        "    write_model_meta(resume_zip, action_set, frame_stack, action_repeat, REWARD_MODE)\n",
        "    try: venv.close(); eval_env.close()\n",
        "    except Exception: pass\n",
        "\n",
        "for b in range(1, num_blocks + 1):\n",
        "    print(f\"=== Training block {b}/{num_blocks} from {Path(resume_zip).name} | ACTION_SET={action_set} | REWARD_MODE={REWARD_MODE} ===\")\n",
        "    train_env = make_vector_env(num_envs, log_dir, None, action_set=action_set, frame_skip=2, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=(num_envs>1))\n",
        "    eval_env  = make_vector_env(1,       log_dir, None, action_set=action_set, frame_skip=2, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "    model = PPO.load(resume_zip, env=train_env, device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    model.ent_coef = 0.01\n",
        "    eval_cb = EvalCallback(eval_env, best_model_save_path=model_dir, log_path=log_dir, eval_freq=60000, n_eval_episodes=3, deterministic=True)\n",
        "    learn_with_restart(model, timesteps_per_block, eval_cb, 2, f\"block-{b}\", action_set, log_dir, action_repeat, frame_stack)\n",
        "    ckpt = Path(model_dir) / f\"ckpt_auto_{b}.zip\"; model.save(str(ckpt)); print(\"Checkpoint saved:\", ckpt.name)\n",
        "    best_zip = Path(model_dir) / \"best_model.zip\"; src = best_zip if best_zip.exists() else ckpt\n",
        "    resume_zip = export_model_copy(src, f\"auto_best_b{b:02d}\", base_dir, run_id)\n",
        "    write_model_meta(resume_zip, action_set, frame_stack, action_repeat, REWARD_MODE)\n",
        "    try: train_env.close(); eval_env.close()\n",
        "    except Exception: pass\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42158dcf",
      "metadata": {
        "id": "42158dcf"
      },
      "source": [
        "## T) Quick test (short training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fefe0483",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fefe0483",
        "outputId": "0cc7975c-a5a7-4945-c0d8-597fab9a99f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warmup: 3000 steps, frame_skip=4, ent=0.02, reward_mode=spec.\n",
            "DummyVecEnv created: 1\n",
            "VecDropResetKwargs active.\n",
            "DummyVecEnv created: 1\n",
            "VecDropResetKwargs active.\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 65.5     |\n",
            "|    ep_rew_mean     | 34.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 32       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total_timesteps | 256      |\n",
            "---------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 94            |\n",
            "|    ep_rew_mean          | 51.7          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 35            |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 14            |\n",
            "|    total_timesteps      | 512           |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.1234155e-07 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.95         |\n",
            "|    explained_variance   | 5.92e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 63.8          |\n",
            "|    n_updates            | 3             |\n",
            "|    policy_gradient_loss | -3.73e-05     |\n",
            "|    value_loss           | 128           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 119          |\n",
            "|    ep_rew_mean          | 59.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 35           |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 768          |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 2.591405e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | -7.82e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 49.4         |\n",
            "|    n_updates            | 6            |\n",
            "|    policy_gradient_loss | -2.02e-05    |\n",
            "|    value_loss           | 99.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 60.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 37           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 27           |\n",
            "|    total_timesteps      | 1024         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 1.930166e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | 8.95e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 47.3         |\n",
            "|    n_updates            | 9            |\n",
            "|    policy_gradient_loss | 2.15e-05     |\n",
            "|    value_loss           | 95.5         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 131           |\n",
            "|    ep_rew_mean          | 61.2          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 37            |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 34            |\n",
            "|    total_timesteps      | 1280          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.6554259e-07 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.95         |\n",
            "|    explained_variance   | 2.93e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 35.7          |\n",
            "|    n_updates            | 12            |\n",
            "|    policy_gradient_loss | 1.08e-05      |\n",
            "|    value_loss           | 72.7          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 152           |\n",
            "|    ep_rew_mean          | 75.8          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 36            |\n",
            "|    iterations           | 6             |\n",
            "|    time_elapsed         | 42            |\n",
            "|    total_timesteps      | 1536          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.4191104e-07 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.95         |\n",
            "|    explained_variance   | 0.000334      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 47            |\n",
            "|    n_updates            | 15            |\n",
            "|    policy_gradient_loss | -1.24e-05     |\n",
            "|    value_loss           | 96.3          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 162          |\n",
            "|    ep_rew_mean          | 82.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 37           |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 1792         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.646143e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | 2.03e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 69.1         |\n",
            "|    n_updates            | 18           |\n",
            "|    policy_gradient_loss | -2.99e-06    |\n",
            "|    value_loss           | 143          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2000, episode_reward=1.00 +/- 0.00\n",
            "Episode length: 121.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 121          |\n",
            "|    mean_reward          | 1            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2000         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 1.787208e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | 0.000714     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 51.6         |\n",
            "|    n_updates            | 21           |\n",
            "|    policy_gradient_loss | -8.64e-05    |\n",
            "|    value_loss           | 108          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 155      |\n",
            "|    ep_rew_mean     | 80.1     |\n",
            "| time/              |          |\n",
            "|    fps             | 33       |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 60       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 157          |\n",
            "|    ep_rew_mean          | 80.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 34           |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 2304         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.853122e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | -0.00126     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 68.7         |\n",
            "|    n_updates            | 24           |\n",
            "|    policy_gradient_loss | -0.000102    |\n",
            "|    value_loss           | 143          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 141          |\n",
            "|    ep_rew_mean          | 72.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 35           |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 2560         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.151176e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | -0.000583    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 36           |\n",
            "|    n_updates            | 27           |\n",
            "|    policy_gradient_loss | -6.31e-05    |\n",
            "|    value_loss           | 77.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 143          |\n",
            "|    ep_rew_mean          | 74.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 35           |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 2816         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.685972e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | -0.00154     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 45.7         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -2.1e-05     |\n",
            "|    value_loss           | 94.7         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 148           |\n",
            "|    ep_rew_mean          | 76            |\n",
            "| time/                   |               |\n",
            "|    fps                  | 35            |\n",
            "|    iterations           | 12            |\n",
            "|    time_elapsed         | 85            |\n",
            "|    total_timesteps      | 3072          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.2997305e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.95         |\n",
            "|    explained_variance   | -0.000706     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 57.9          |\n",
            "|    n_updates            | 33            |\n",
            "|    policy_gradient_loss | 2.92e-05      |\n",
            "|    value_loss           | 122           |\n",
            "-------------------------------------------\n",
            "Warmup checkpoint saved: ckpt_bootstrap.zip\n",
            "Warmup model exported: ppo_quick_20251116_234415_bootstrap.zip\n",
            "Model metadata written: ppo_quick_20251116_234415_bootstrap.meta.json\n",
            "Main quick pass: 8000 steps, frame_skip=2, ent=0.01.\n",
            "DummyVecEnv created: 1\n",
            "VecDropResetKwargs active.\n",
            "DummyVecEnv created: 1\n",
            "VecDropResetKwargs active.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 143      |\n",
            "|    ep_rew_mean     | 74.1     |\n",
            "| time/              |          |\n",
            "|    fps             | 58       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 3328     |\n",
            "---------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 154           |\n",
            "|    ep_rew_mean          | 78.5          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 7             |\n",
            "|    total_timesteps      | 3584          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.9485203e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.95         |\n",
            "|    explained_variance   | -0.000106     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 85.1          |\n",
            "|    n_updates            | 39            |\n",
            "|    policy_gradient_loss | -0.00052      |\n",
            "|    value_loss           | 176           |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 149         |\n",
            "|    ep_rew_mean          | 76.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 67          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 3840        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.92207e-05 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.95       |\n",
            "|    explained_variance   | -0.000235   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 35.4        |\n",
            "|    n_updates            | 42          |\n",
            "|    policy_gradient_loss | -0.000689   |\n",
            "|    value_loss           | 73          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 149          |\n",
            "|    ep_rew_mean          | 76.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002417618 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | -0.000432    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 34.4         |\n",
            "|    n_updates            | 45           |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    value_loss           | 69.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 155          |\n",
            "|    ep_rew_mean          | 80.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 67           |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 4352         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003771379 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.94        |\n",
            "|    explained_variance   | -9.62e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 90.8         |\n",
            "|    n_updates            | 48           |\n",
            "|    policy_gradient_loss | -0.00106     |\n",
            "|    value_loss           | 185          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 164           |\n",
            "|    ep_rew_mean          | 84.3          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 68            |\n",
            "|    iterations           | 6             |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 4608          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00029313657 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.94         |\n",
            "|    explained_variance   | -0.00013      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 62.3          |\n",
            "|    n_updates            | 51            |\n",
            "|    policy_gradient_loss | -0.000432     |\n",
            "|    value_loss           | 126           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 168           |\n",
            "|    ep_rew_mean          | 87.8          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 69            |\n",
            "|    iterations           | 7             |\n",
            "|    time_elapsed         | 25            |\n",
            "|    total_timesteps      | 4864          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015170476 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.94         |\n",
            "|    explained_variance   | -5.96e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 41.6          |\n",
            "|    n_updates            | 54            |\n",
            "|    policy_gradient_loss | -0.000636     |\n",
            "|    value_loss           | 84.6          |\n",
            "-------------------------------------------\n",
            "Eval num_timesteps=5072, episode_reward=33.00 +/- 0.00\n",
            "Episode length: 48.00 +/- 0.00\n",
            "-------------------------------------------\n",
            "| eval/                   |               |\n",
            "|    mean_ep_length       | 48            |\n",
            "|    mean_reward          | 33            |\n",
            "| time/                   |               |\n",
            "|    total_timesteps      | 5072          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00022553373 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.94         |\n",
            "|    explained_variance   | 3.3e-05       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 59.2          |\n",
            "|    n_updates            | 57            |\n",
            "|    policy_gradient_loss | 4.71e-05      |\n",
            "|    value_loss           | 120           |\n",
            "-------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 172      |\n",
            "|    ep_rew_mean     | 89.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 63       |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 32       |\n",
            "|    total_timesteps | 5120     |\n",
            "---------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 168           |\n",
            "|    ep_rew_mean          | 88            |\n",
            "| time/                   |               |\n",
            "|    fps                  | 64            |\n",
            "|    iterations           | 9             |\n",
            "|    time_elapsed         | 35            |\n",
            "|    total_timesteps      | 5376          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011876505 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.94         |\n",
            "|    explained_variance   | 4.86e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 53.6          |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | -0.000324     |\n",
            "|    value_loss           | 108           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 172           |\n",
            "|    ep_rew_mean          | 90.2          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 10            |\n",
            "|    time_elapsed         | 39            |\n",
            "|    total_timesteps      | 5632          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00012092758 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.93         |\n",
            "|    explained_variance   | -6.08e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 80.1          |\n",
            "|    n_updates            | 63            |\n",
            "|    policy_gradient_loss | -0.000225     |\n",
            "|    value_loss           | 162           |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 174            |\n",
            "|    ep_rew_mean          | 89.8           |\n",
            "| time/                   |                |\n",
            "|    fps                  | 65             |\n",
            "|    iterations           | 11             |\n",
            "|    time_elapsed         | 43             |\n",
            "|    total_timesteps      | 5888           |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000104332576 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.93          |\n",
            "|    explained_variance   | -9.3e-06       |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 50.9           |\n",
            "|    n_updates            | 66             |\n",
            "|    policy_gradient_loss | 0.000105       |\n",
            "|    value_loss           | 103            |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 177           |\n",
            "|    ep_rew_mean          | 91.2          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 12            |\n",
            "|    time_elapsed         | 46            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010553934 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.93         |\n",
            "|    explained_variance   | -2.37e-05     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 29.5          |\n",
            "|    n_updates            | 69            |\n",
            "|    policy_gradient_loss | -0.000256     |\n",
            "|    value_loss           | 59.4          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 177           |\n",
            "|    ep_rew_mean          | 91.2          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 66            |\n",
            "|    iterations           | 13            |\n",
            "|    time_elapsed         | 50            |\n",
            "|    total_timesteps      | 6400          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021646498 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.93         |\n",
            "|    explained_variance   | -2.74e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 36.2          |\n",
            "|    n_updates            | 72            |\n",
            "|    policy_gradient_loss | -0.000828     |\n",
            "|    value_loss           | 73.3          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 174           |\n",
            "|    ep_rew_mean          | 90.3          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 14            |\n",
            "|    time_elapsed         | 54            |\n",
            "|    total_timesteps      | 6656          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020095706 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.93         |\n",
            "|    explained_variance   | -1.35e-05     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 61.9          |\n",
            "|    n_updates            | 75            |\n",
            "|    policy_gradient_loss | 3.16e-05      |\n",
            "|    value_loss           | 125           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 169           |\n",
            "|    ep_rew_mean          | 88.8          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 66            |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 57            |\n",
            "|    total_timesteps      | 6912          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013427809 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.93         |\n",
            "|    explained_variance   | -7.39e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 86.2          |\n",
            "|    n_updates            | 78            |\n",
            "|    policy_gradient_loss | -0.000459     |\n",
            "|    value_loss           | 173           |\n",
            "-------------------------------------------\n",
            "Eval num_timesteps=7072, episode_reward=33.00 +/- 0.00\n",
            "Episode length: 48.00 +/- 0.00\n",
            "-------------------------------------------\n",
            "| eval/                   |               |\n",
            "|    mean_ep_length       | 48            |\n",
            "|    mean_reward          | 33            |\n",
            "| time/                   |               |\n",
            "|    total_timesteps      | 7072          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00037881313 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.93         |\n",
            "|    explained_variance   | -1.67e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 77.4          |\n",
            "|    n_updates            | 81            |\n",
            "|    policy_gradient_loss | -0.00142      |\n",
            "|    value_loss           | 155           |\n",
            "-------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 166      |\n",
            "|    ep_rew_mean     | 87.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 64       |\n",
            "|    iterations      | 16       |\n",
            "|    time_elapsed    | 63       |\n",
            "|    total_timesteps | 7168     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 169          |\n",
            "|    ep_rew_mean          | 88.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 64           |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 7424         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005835991 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.93        |\n",
            "|    explained_variance   | -3.58e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 70.4         |\n",
            "|    n_updates            | 84           |\n",
            "|    policy_gradient_loss | -0.00168     |\n",
            "|    value_loss           | 142          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 171          |\n",
            "|    ep_rew_mean          | 89.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 7680         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003951632 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.92        |\n",
            "|    explained_variance   | 5.36e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 57.4         |\n",
            "|    n_updates            | 87           |\n",
            "|    policy_gradient_loss | 0.000133     |\n",
            "|    value_loss           | 116          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 171           |\n",
            "|    ep_rew_mean          | 89.4          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 19            |\n",
            "|    time_elapsed         | 74            |\n",
            "|    total_timesteps      | 7936          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020250399 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.92         |\n",
            "|    explained_variance   | -5.96e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 53.2          |\n",
            "|    n_updates            | 90            |\n",
            "|    policy_gradient_loss | -0.00024      |\n",
            "|    value_loss           | 107           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 175           |\n",
            "|    ep_rew_mean          | 90.4          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 20            |\n",
            "|    time_elapsed         | 78            |\n",
            "|    total_timesteps      | 8192          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032968214 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.92         |\n",
            "|    explained_variance   | -1.91e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 29.6          |\n",
            "|    n_updates            | 93            |\n",
            "|    policy_gradient_loss | -0.000916     |\n",
            "|    value_loss           | 59.9          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 176          |\n",
            "|    ep_rew_mean          | 91.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 65           |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 81           |\n",
            "|    total_timesteps      | 8448         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002836238 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.92        |\n",
            "|    explained_variance   | -3.58e-06    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 86           |\n",
            "|    n_updates            | 96           |\n",
            "|    policy_gradient_loss | 0.000214     |\n",
            "|    value_loss           | 173          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 179          |\n",
            "|    ep_rew_mean          | 92.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 66           |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 8704         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.542976e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.92        |\n",
            "|    explained_variance   | -8.34e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 68.2         |\n",
            "|    n_updates            | 99           |\n",
            "|    policy_gradient_loss | 0.000263     |\n",
            "|    value_loss           | 137          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 182           |\n",
            "|    ep_rew_mean          | 93.6          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 23            |\n",
            "|    time_elapsed         | 89            |\n",
            "|    total_timesteps      | 8960          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.0456572e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.92         |\n",
            "|    explained_variance   | -2.98e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 55.5          |\n",
            "|    n_updates            | 102           |\n",
            "|    policy_gradient_loss | -0.000159     |\n",
            "|    value_loss           | 112           |\n",
            "-------------------------------------------\n",
            "Eval num_timesteps=9072, episode_reward=33.00 +/- 0.00\n",
            "Episode length: 48.00 +/- 0.00\n",
            "-------------------------------------------\n",
            "| eval/                   |               |\n",
            "|    mean_ep_length       | 48            |\n",
            "|    mean_reward          | 33            |\n",
            "| time/                   |               |\n",
            "|    total_timesteps      | 9072          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 7.9327496e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.92         |\n",
            "|    explained_variance   | -1.18e-05     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 41.3          |\n",
            "|    n_updates            | 105           |\n",
            "|    policy_gradient_loss | -0.000471     |\n",
            "|    value_loss           | 83.3          |\n",
            "-------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 182      |\n",
            "|    ep_rew_mean     | 94.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 64       |\n",
            "|    iterations      | 24       |\n",
            "|    time_elapsed    | 94       |\n",
            "|    total_timesteps | 9216     |\n",
            "---------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 186           |\n",
            "|    ep_rew_mean          | 95.7          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 25            |\n",
            "|    time_elapsed         | 98            |\n",
            "|    total_timesteps      | 9472          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00024901237 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.92         |\n",
            "|    explained_variance   | -3.93e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 79.1          |\n",
            "|    n_updates            | 108           |\n",
            "|    policy_gradient_loss | -0.00183      |\n",
            "|    value_loss           | 159           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 184           |\n",
            "|    ep_rew_mean          | 94.7          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 64            |\n",
            "|    iterations           | 26            |\n",
            "|    time_elapsed         | 102           |\n",
            "|    total_timesteps      | 9728          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.4688036e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.92         |\n",
            "|    explained_variance   | 5.3e-06       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 15.2          |\n",
            "|    n_updates            | 111           |\n",
            "|    policy_gradient_loss | 0.000317      |\n",
            "|    value_loss           | 30.8          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 184           |\n",
            "|    ep_rew_mean          | 94.7          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 27            |\n",
            "|    time_elapsed         | 105           |\n",
            "|    total_timesteps      | 9984          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013170834 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.91         |\n",
            "|    explained_variance   | -1.19e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 80.6          |\n",
            "|    n_updates            | 114           |\n",
            "|    policy_gradient_loss | -0.000568     |\n",
            "|    value_loss           | 162           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 186           |\n",
            "|    ep_rew_mean          | 95.4          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 28            |\n",
            "|    time_elapsed         | 109           |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015088264 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.91         |\n",
            "|    explained_variance   | -2.38e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 66.6          |\n",
            "|    n_updates            | 117           |\n",
            "|    policy_gradient_loss | -0.000482     |\n",
            "|    value_loss           | 134           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 184           |\n",
            "|    ep_rew_mean          | 95.3          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 29            |\n",
            "|    time_elapsed         | 113           |\n",
            "|    total_timesteps      | 10496         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016321638 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.91         |\n",
            "|    explained_variance   | -9.54e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 55.2          |\n",
            "|    n_updates            | 120           |\n",
            "|    policy_gradient_loss | -0.000584     |\n",
            "|    value_loss           | 111           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 187           |\n",
            "|    ep_rew_mean          | 96.5          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 30            |\n",
            "|    time_elapsed         | 117           |\n",
            "|    total_timesteps      | 10752         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00017856248 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.91         |\n",
            "|    explained_variance   | -4.41e-06     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 76.7          |\n",
            "|    n_updates            | 123           |\n",
            "|    policy_gradient_loss | -0.000541     |\n",
            "|    value_loss           | 154           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 188           |\n",
            "|    ep_rew_mean          | 97.1          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 65            |\n",
            "|    iterations           | 31            |\n",
            "|    time_elapsed         | 120           |\n",
            "|    total_timesteps      | 11008         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015130267 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.91         |\n",
            "|    explained_variance   | 3.58e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 66.8          |\n",
            "|    n_updates            | 126           |\n",
            "|    policy_gradient_loss | -1.38e-05     |\n",
            "|    value_loss           | 135           |\n",
            "-------------------------------------------\n",
            "Eval num_timesteps=11072, episode_reward=33.00 +/- 0.00\n",
            "Episode length: 48.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 48           |\n",
            "|    mean_reward          | 33           |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 11072        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.471985e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.91        |\n",
            "|    explained_variance   | 8.34e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 63.2         |\n",
            "|    n_updates            | 129          |\n",
            "|    policy_gradient_loss | -2.29e-05    |\n",
            "|    value_loss           | 127          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 187      |\n",
            "|    ep_rew_mean     | 96.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 64       |\n",
            "|    iterations      | 32       |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 11264    |\n",
            "---------------------------------\n",
            "Quick-pass checkpoint saved: best_model.zip\n",
            "Quick-pass best exported: ppo_quick_20251116_234415_quick_best.zip\n",
            "Quick test complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from shutil import copy2\n",
        "import os, json, numpy as np, random, warnings, torch\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=r\".*env\\.spec.*deprecated.*\")\n",
        "\n",
        "TEST = dict(action_set='SIMPLE_MOVEMENT', num_envs=1, frame_stack=2, action_repeat=2,\n",
        "            frame_skip=4, warmup_timesteps=3000, num_blocks=1, timesteps_per_block=8000,\n",
        "            warmup_ent=0.02, main_ent=0.01, eval_freq=2000)\n",
        "\n",
        "frame_stack   = int(TEST.get('frame_stack',2))\n",
        "action_repeat = int(TEST.get('action_repeat',2))\n",
        "frame_skip    = int(TEST.get('frame_skip',4))\n",
        "EVALF         = int(TEST.get('eval_freq',2000))\n",
        "SEED=42; random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "run_id  = datetime.now().strftime(\"ppo_quick_%Y%m%d_%H%M%S\")\n",
        "log_dir   = f\"{base_dir}/logs/{run_id}\"\n",
        "model_dir = f\"{base_dir}/models/{run_id}\"\n",
        "for d in (log_dir, model_dir): Path(d).mkdir(parents=True, exist_ok=True)\n",
        "Path(f\"{base_dir}/models/exports\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def write_model_meta(zip_path, action_set, frame_stack, action_repeat, reward_mode):\n",
        "    mp = Path(zip_path).with_suffix(\".meta.json\")\n",
        "    mp.write_text(json.dumps(dict(action_set=action_set,\n",
        "                                  frame_stack=int(frame_stack),\n",
        "                                  action_repeat=int(action_repeat),\n",
        "                                  reward_mode=str(reward_mode)), indent=2), encoding=\"utf-8\")\n",
        "    print(\"Model metadata written:\", mp.name)\n",
        "\n",
        "def make_training_bundle(frame_skip_used, ent_coef, eval_freq, action_set_used):\n",
        "    venv     = make_vector_env(1, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "    eval_env = make_vector_env(1, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "    policy_kwargs = dict(features_extractor_class=SmallCNNFeatures, features_extractor_kwargs=dict(features_dim=128), net_arch=[128,128])\n",
        "    model = PPO('CnnPolicy', venv, policy_kwargs=policy_kwargs, n_steps=256, batch_size=256, n_epochs=3,\n",
        "                learning_rate=3e-4, gamma=0.999, gae_lambda=0.95, clip_range=0.2, ent_coef=ent_coef, vf_coef=0.5,\n",
        "                device=('cuda' if torch.cuda.is_available() else 'cpu'), verbose=1, seed=SEED)\n",
        "    eval_cb = EvalCallback(eval_env, best_model_save_path=model_dir, log_path=log_dir, eval_freq=eval_freq, n_eval_episodes=2, deterministic=True)\n",
        "    return model, venv, eval_env, eval_cb\n",
        "\n",
        "print(f\"Warmup: {TEST['warmup_timesteps']} steps, frame_skip={frame_skip}, ent={TEST['warmup_ent']}, reward_mode={REWARD_MODE}.\")\n",
        "model, venv, eval_env, eval_cb = make_training_bundle(frame_skip, TEST['warmup_ent'], EVALF, TEST['action_set'])\n",
        "model.learn(total_timesteps=TEST['warmup_timesteps'], reset_num_timesteps=False, callback=eval_cb)\n",
        "ckpt = Path(model_dir)/'ckpt_bootstrap.zip'; model.save(str(ckpt)); print('Warmup checkpoint saved:', ckpt.name)\n",
        "dst = (Path(base_dir)/'models'/'exports'/f\"{run_id}_bootstrap.zip\"); copy2(ckpt, dst); print(\"Warmup model exported:\", dst.name)\n",
        "write_model_meta(str(dst), TEST['action_set'], frame_stack, action_repeat, REWARD_MODE)\n",
        "try: venv.close(); eval_env.close()\n",
        "except: pass\n",
        "\n",
        "print(f\"Main quick pass: {TEST['timesteps_per_block']} steps, frame_skip=2, ent={TEST['main_ent']}.\")\n",
        "train_env = make_vector_env(1, log_dir, None, action_set=TEST['action_set'], frame_skip=2, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "eval_env  = make_vector_env(1, log_dir, None, action_set=TEST['action_set'], frame_skip=2, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n",
        "model = PPO.load(str(dst), env=train_env, device=('cuda' if torch.cuda.is_available() else 'cpu')); model.ent_coef = TEST['main_ent']\n",
        "eval_cb = EvalCallback(eval_env, best_model_save_path=model_dir, log_path=log_dir, eval_freq=EVALF, n_eval_episodes=3, deterministic=True)\n",
        "model.learn(total_timesteps=TEST['timesteps_per_block'], reset_num_timesteps=False, callback=eval_cb)\n",
        "best_zip = Path(model_dir)/'best_model.zip'\n",
        "src = best_zip if best_zip.exists() else (Path(model_dir)/'ckpt_quick.zip'); model.save(str(src)); print('Quick-pass checkpoint saved:', src.name)\n",
        "dst2 = (Path(base_dir)/'models'/'exports'/f\"{run_id}_quick_best.zip\"); copy2(src, dst2); print(\"Quick-pass best exported:\", dst2.name)\n",
        "(Path(str(dst2))).with_suffix(\".meta.json\").write_text(json.dumps(dict(action_set=TEST['action_set'], frame_stack=frame_stack, action_repeat=action_repeat, reward_mode=REWARD_MODE), indent=2), encoding='utf-8')\n",
        "print('Quick test complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ecc3dda",
      "metadata": {
        "id": "5ecc3dda"
      },
      "source": [
        "## E) Learning analysis (reward curve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e0eeef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "75e0eeef",
        "outputId": "a4b38e1f-a012-420d-dc37-ece9c00df05d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected log directory: /content/mario_rl_local/logs/ppo_quick_20251116_234415\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode count: 40\n",
            "Mean reward over the last 20 episodes: 108.9\n",
            "Total timesteps from logs (sum of l): 5961\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "def find_latest_log_dir(base_logs):\n",
        "    mfiles = sorted(Path(base_logs).glob('**/*.monitor.csv'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return mfiles[0].parent if mfiles else None\n",
        "\n",
        "_ld = find_latest_log_dir(f\"{base_dir}/logs\"); assert _ld, 'No log directory was found.'\n",
        "log_dir = str(_ld); print('Selected log directory:', log_dir)\n",
        "files = sorted(Path(log_dir).glob('**/*.monitor.csv'))\n",
        "df = pd.concat([pd.read_csv(f, comment='#') for f in files], ignore_index=True).reset_index(drop=True)\n",
        "df['episode'] = range(1, len(df)+1); df['ema20'] = df['r'].ewm(span=20).mean()\n",
        "plt.figure(figsize=(8,4)); plt.plot(df['episode'], df['r'], alpha=0.3, label='reward'); plt.plot(df['episode'], df['ema20'], label='EMA20')\n",
        "plt.legend(); plt.title('Reward per episode'); plt.grid(True); plt.tight_layout(); plt.show()\n",
        "print('Episode count:', len(df))\n",
        "print('Mean reward over the last 20 episodes:', float(df['r'].tail(20).mean()))\n",
        "print('Total timesteps from logs (sum of l):', int(df['l'].sum()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11eca9fa",
      "metadata": {
        "id": "11eca9fa"
      },
      "source": [
        "## F1) Video: trained model (60 s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7cc337e",
      "metadata": {
        "id": "d7cc337e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "from stable_baselines3 import PPO\n",
        "from pathlib import Path\n",
        "import json, torch\n",
        "\n",
        "def find_latest_export_zip(base_dir_str):\n",
        "    ex = sorted((Path(base_dir_str)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return str(ex[0]) if ex else None\n",
        "\n",
        "def model_meta_path(zip_path):\n",
        "    return Path(zip_path).with_suffix('.meta.json')\n",
        "\n",
        "def infer_action_set_from_model(zip_path):\n",
        "    mp = model_meta_path(zip_path)\n",
        "    if mp.exists():\n",
        "        try:\n",
        "            m = json.loads(mp.read_text())\n",
        "            if m.get('action_set') in ('RIGHT_ONLY','SIMPLE_MOVEMENT'):\n",
        "                print('Action set (metadata):', m['action_set'])\n",
        "                return m['action_set']\n",
        "        except Exception:\n",
        "            pass\n",
        "    tmp = PPO.load(zip_path, device='cpu')\n",
        "    n_act = tmp.action_space.n\n",
        "    return 'RIGHT_ONLY' if n_act == 5 else 'SIMPLE_MOVEMENT'\n",
        "\n",
        "model_zip = find_latest_export_zip(base_dir); assert model_zip, 'No exported model was found.'\n",
        "action_set_play  = infer_action_set_from_model(model_zip)\n",
        "frame_stack_play = int(globals().get('frame_stack',2))\n",
        "action_repeat_play = int(globals().get('action_repeat',2))\n",
        "\n",
        "play_env = make_vector_env(1, f\"{base_dir}/logs/_play\", render_mode='rgb_array',\n",
        "                           action_set=action_set_play, frame_skip=2, action_repeat=action_repeat_play, frame_stack=frame_stack_play, prefer_subproc=False)\n",
        "try:\n",
        "    RENDER_FPS = play_env.get_attr('metadata')[0].get('render_fps',30)\n",
        "except Exception:\n",
        "    RENDER_FPS = 30\n",
        "\n",
        "VIDEO_SECONDS=60; VIDEO_STEPS=int(RENDER_FPS*VIDEO_SECONDS)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = PPO.load(model_zip, env=play_env, device=device)\n",
        "\n",
        "p=Path(model_zip)\n",
        "VIDEO_DIR=p.parent.as_posix().replace('/models/','/videos/') if '/models/' in p.as_posix() else f'{base_dir}/videos'\n",
        "Path(VIDEO_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "video_env = VecVideoRecorder(play_env, VIDEO_DIR, record_video_trigger=lambda step: step==0, video_length=VIDEO_STEPS, name_prefix=f'play_{p.stem}')\n",
        "obs = video_env.reset(); steps=0\n",
        "while steps<VIDEO_STEPS:\n",
        "    a,_=model.predict(obs, deterministic=True); obs,_,done,_=video_env.step(a); steps+=1\n",
        "    if done.any(): obs=video_env.reset()\n",
        "try: video_env.close()\n",
        "except Exception as e: print('Info: video_env.close raised:', e)\n",
        "try: play_env.close()\n",
        "except Exception: pass\n",
        "print('Trained-model video saved in:', VIDEO_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af497394",
      "metadata": {
        "id": "af497394"
      },
      "source": [
        "## F2) Video: random agent (15 s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d236207",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d236207",
        "outputId": "6c6196d9-2d00-4004-c837-54c44c07a1d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action set (metadata): SIMPLE_MOVEMENT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyVecEnv created: 1\n",
            "VecDropResetKwargs active.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gym/utils/passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving video to /content/mario_rl_local/videos/_random/random_simple_movement-step-0-to-step-450.mp4\n",
            "MoviePy - Building video /content/mario_rl_local/videos/_random/random_simple_movement-step-0-to-step-450.mp4.\n",
            "MoviePy - Writing video /content/mario_rl_local/videos/_random/random_simple_movement-step-0-to-step-450.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready /content/mario_rl_local/videos/_random/random_simple_movement-step-0-to-step-450.mp4\n",
            "Random-agent video saved in: /content/mario_rl_local/videos/_random\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "from pathlib import Path\n",
        "import numpy as np, json\n",
        "\n",
        "def find_latest_export_zip(base_dir_str):\n",
        "    ex = sorted((Path(base_dir_str)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return str(ex[0]) if ex else None\n",
        "\n",
        "def infer_action_set_from_latest(base_dir_str, default='SIMPLE_MOVEMENT'):\n",
        "    z = find_latest_export_zip(base_dir_str)\n",
        "    if not z:\n",
        "        print(\"No model found. Using default ACTION_SET:\", default)\n",
        "        return default\n",
        "    mp = Path(z).with_suffix('.meta.json')\n",
        "    if mp.exists():\n",
        "        try:\n",
        "            m = json.loads(mp.read_text())\n",
        "            if m.get('action_set') in ('RIGHT_ONLY','SIMPLE_MOVEMENT'):\n",
        "                print('Action set (metadata):', m['action_set'])\n",
        "                return m['action_set']\n",
        "        except Exception: pass\n",
        "    print(\"Metadata not readable. Using default ACTION_SET:\", default)\n",
        "    return default\n",
        "\n",
        "action_set_rand  = infer_action_set_from_latest(base_dir, default='SIMPLE_MOVEMENT')\n",
        "frame_stack_play = int(globals().get('frame_stack',2))\n",
        "action_repeat_play = int(globals().get('action_repeat',2))\n",
        "\n",
        "play_env = make_vector_env(1, f\"{base_dir}/logs/_random\", render_mode='rgb_array',\n",
        "                           action_set=action_set_rand, frame_skip=4, action_repeat=action_repeat_play, frame_stack=frame_stack_play, prefer_subproc=False)\n",
        "try:\n",
        "    RENDER_FPS = play_env.get_attr('metadata')[0].get('render_fps',30)\n",
        "except Exception:\n",
        "    RENDER_FPS = 30\n",
        "\n",
        "VIDEO_SECONDS=15; VIDEO_STEPS=int(RENDER_FPS*VIDEO_SECONDS)\n",
        "VIDEO_DIR=f\"{base_dir}/videos/_random\"; Path(VIDEO_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "video_env = VecVideoRecorder(play_env, VIDEO_DIR, record_video_trigger=lambda step: step == 0, video_length=VIDEO_STEPS, name_prefix=f'random_{action_set_rand.lower()}')\n",
        "\n",
        "obs = video_env.reset(); steps=0\n",
        "while steps<VIDEO_STEPS:\n",
        "    a = np.array([play_env.action_space.sample()], dtype=np.int64)\n",
        "    obs,_,done,_=video_env.step(a); steps+=1\n",
        "    if done.any(): obs=video_env.reset()\n",
        "try: video_env.close()\n",
        "except Exception as e: print('Info: video_env.close raised:', e)\n",
        "try: play_env.close()\n",
        "except Exception: pass\n",
        "print('Random-agent video saved in:', VIDEO_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4c00b8",
      "metadata": {
        "id": "0f4c00b8"
      },
      "source": [
        "## G) Report generator (1–2 pages, covers all required points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ca5942",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ca5942",
        "outputId": "de1f874d-213f-4937-8c43-19717b7914ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report saved:\n",
            " - /content/mario_rl_local/reports/report_local.md\n",
            " - /content/mario_rl_local/reports/report_local.html\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd, datetime as dt, markdown as mdlib, json\n",
        "\n",
        "def find_latest_log_dir(base_logs):\n",
        "    mfiles = sorted(Path(base_logs).glob('**/*.monitor.csv'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return mfiles[0].parent if mfiles else None\n",
        "\n",
        "LOGP = find_latest_log_dir(f\"{base_dir}/logs\"); assert LOGP, \"No log directory was found.\"\n",
        "files = sorted(Path(LOGP).glob('**/*.monitor.csv'))\n",
        "df = pd.concat([pd.read_csv(f, comment='#') for f in files], ignore_index=True).reset_index(drop=True)\n",
        "\n",
        "episodes = int(len(df))\n",
        "timesteps = int(df['l'].sum()) if 'l' in df else 0\n",
        "mean_last20 = float(df['r'].tail(20).mean()) if episodes > 0 else 0.0\n",
        "best_reward = float(df['r'].max()) if episodes > 0 else 0.0\n",
        "\n",
        "ts = dt.datetime.now().strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "cfg = {\n",
        "    \"action_set\": globals().get(\"action_set\", \"SIMPLE_MOVEMENT\"),\n",
        "    \"frame_stack\": int(globals().get(\"frame_stack\", 2)),\n",
        "    \"action_repeat\": int(globals().get(\"action_repeat\", 2)),\n",
        "    \"reward_mode\": str(globals().get(\"REWARD_MODE\", \"spec\"))\n",
        "}\n",
        "\n",
        "report_md = f\"\"\"# Short Report — Mario PPO (Local Training Suite)\n",
        "\n",
        "**Author:** Sara Persson\n",
        "**Date:** {ts}\n",
        "\n",
        "## Data preparation\n",
        "Observations are derived directly from the environment (no static dataset). Each frame is converted to **84x84 grayscale** and we apply **frame stacking** (stack={cfg['frame_stack']}) to expose short-term temporal context.\n",
        "We also use **frame skip** and **action repeat** (repeat={cfg['action_repeat']}) to reduce computational load and improve sample efficiency.\n",
        "Reward mode is **{cfg['reward_mode']}**:\n",
        "- **spec (default):** +1 only when forward progress occurs within a step, and -15 on death; 0 otherwise.\n",
        "- **shaped (optional):** adds dense progress shaping and small step penalties.\n",
        "\n",
        "## Model choice and motivation\n",
        "We use **PPO (Proximal Policy Optimization)** from Stable-Baselines3 with a compact CNN feature extractor.\n",
        "PPO is chosen because it is:\n",
        "- **Stable and robust** for on-policy training in discrete-control environments like NES Mario.\n",
        "- **Well-supported** with reliable implementations, monitoring, and callbacks.\n",
        "- **Sample-efficient enough** for short Colab runs while still converging with modest tuning.\n",
        "\n",
        "## Performance and evaluation\n",
        "- **Episodes:** {episodes}\n",
        "- **Total timesteps (from logs):** {timesteps}\n",
        "- **Mean reward (last 20 episodes):** {mean_last20:.2f}\n",
        "- **Best single-episode reward:** {best_reward:.2f}\n",
        "\n",
        "We additionally provide two evaluation utilities:\n",
        "- **J:** aggregate rewards over N episodes.\n",
        "- **J2:** reports both reward and maximum `x_pos` (how far Mario progressed).\n",
        "\n",
        "## Improvement suggestions\n",
        "If performance is below target, we suggest:\n",
        "1. **Longer training** (increase warmup and block timesteps) and ensure GPU runtime.\n",
        "2. **Curriculum**: start with `RIGHT_ONLY`, then switch to `SIMPLE_MOVEMENT` once forward progress is consistent.\n",
        "3. **Entropy schedule**: higher entropy early, then lower (0.02 -> 0.005) to solidify behaviors.\n",
        "4. **Reward mode swap**: try `shaped` to speed early learning, then revert to `spec` for alignment with project spec.\n",
        "5. **Model capacity**: modestly larger CNN (e.g., +64 filters) if learning plateaus.\n",
        "6. **Frame skip/repeat**: tune (e.g., skip 2–4, repeat 2) to balance fidelity and speed.\n",
        "\n",
        "## Reproducibility and artifacts\n",
        "- Notebook: **Mario_RL_PPO_Local_TrainingSuite.ipynb**\n",
        "- Logs and monitor CSVs under `/content/mario_rl_local/logs`\n",
        "- Exported models under `/content/mario_rl_local/models/exports`\n",
        "- Videos under `/content/mario_rl_local/videos`\n",
        "\"\"\"\n",
        "\n",
        "reports_dir = Path(base_dir) / \"reports\"\n",
        "reports_dir.mkdir(parents=True, exist_ok=True)\n",
        "md_path = reports_dir / \"report_local.md\"\n",
        "html_path = reports_dir / \"report_local.html\"\n",
        "\n",
        "md_path.write_text(report_md, encoding='utf-8')\n",
        "html_path.write_text(mdlib.markdown(report_md, extensions=['tables']), encoding='utf-8')\n",
        "\n",
        "print(\"Report saved:\")\n",
        "print(\" -\", md_path)\n",
        "print(\" -\", html_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d48298",
      "metadata": {
        "id": "11d48298"
      },
      "source": [
        "## H) Export and import helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd0257b",
      "metadata": {
        "id": "dbd0257b"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "def list_exports(base=base_dir, n=10):\n",
        "    ex = sorted((Path(base)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)[:n]\n",
        "    for p in ex: print(p.name)\n",
        "\n",
        "def set_resume_from(path):\n",
        "    global RESUME_FROM\n",
        "    RESUME_FROM = str(Path(path))\n",
        "    print('RESUME_FROM =', RESUME_FROM)\n",
        "\n",
        "def write_model_meta(zip_path, action_set='SIMPLE_MOVEMENT', frame_stack=2, action_repeat=2, reward_mode='spec'):\n",
        "    mp = Path(zip_path).with_suffix('.meta.json')\n",
        "    mp.write_text(json.dumps(dict(action_set=action_set, frame_stack=int(frame_stack), action_repeat=int(action_repeat), reward_mode=str(reward_mode)), indent=2), encoding='utf-8')\n",
        "    print('Model metadata written:', mp.name)\n",
        "\n",
        "print('Helpers: list_exports(), set_resume_from(path), write_model_meta(zip, ...)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d06a11cb",
      "metadata": {
        "id": "d06a11cb"
      },
      "source": [
        "## S-STATUS) Status overview (local artifacts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3534bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f3534bc",
        "outputId": "87aa508a-35f8-4880-81c9-b3a6253dc65c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest export:\n",
            "  - models/exports/ppo_quick_20251116_234415_quick_best.zip | 4.8 MB | 2025-11-16 23:47:55\n",
            "  - Meta: {'action_set': 'SIMPLE_MOVEMENT', 'frame_stack': 2, 'action_repeat': 2, 'reward_mode': 'spec'}\n",
            "\n",
            "Latest log:\n",
            "  - logs/_random/0.monitor.csv | 114.0 B | 2025-11-16 23:54:16\n",
            "  - Episodes: 2\n",
            "  - Timesteps: 349\n",
            "  - Mean reward over last 20: 96.50\n",
            "  - Best single-episode reward: 140.00\n",
            "\n",
            "Latest video:\n",
            "  - videos/_random/random_simple_movement-step-0-to-step-450.mp4 | 108.3 KB | 2025-11-16 23:54:19\n",
            "\n",
            "No reports found.\n",
            "\n",
            "No plots found.\n",
            "\n",
            "Status inspection complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import datetime as dt\n",
        "import json\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    pd = None\n",
        "\n",
        "root = Path(base_dir)\n",
        "assert root.exists(), f\"The base_dir path does not exist: {base_dir}\"\n",
        "\n",
        "def fmt_ts(p: Path) -> str:\n",
        "    try:\n",
        "        return dt.datetime.fromtimestamp(p.stat().st_mtime).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    except Exception: return \"?\"\n",
        "def fmt_sz(n: int) -> str:\n",
        "    units = [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]; i=0; f=float(n)\n",
        "    while f>=1024 and i<len(units)-1: f/=1024; i+=1\n",
        "    return f\"{f:.1f} {units[i]}\"\n",
        "def newest(glob_iter):\n",
        "    files = sorted(glob_iter, key=lambda p: p.stat().st_mtime, reverse=True); return files[0] if files else None\n",
        "def short(p: Path):\n",
        "    try: return str(p.relative_to(root))\n",
        "    except Exception: return str(p)\n",
        "\n",
        "exp_dir = root/\"models\"/\"exports\"; latest_zip = newest(exp_dir.glob(\"*.zip\")) if exp_dir.exists() else None\n",
        "if latest_zip:\n",
        "    meta = {}\n",
        "    mp = latest_zip.with_suffix(\".meta.json\")\n",
        "    if mp.exists():\n",
        "        try: meta = json.loads(mp.read_text())\n",
        "        except Exception: pass\n",
        "    print(\"Latest export:\")\n",
        "    print(\"  -\", short(latest_zip), \"|\", fmt_sz(latest_zip.stat().st_size), \"|\", fmt_ts(latest_zip))\n",
        "    print(\"  - Meta:\", {k: meta.get(k) for k in (\"action_set\",\"frame_stack\",\"action_repeat\",\"reward_mode\")} if meta else \"(missing)\")\n",
        "else:\n",
        "    print(\"No latest export found.\")\n",
        "\n",
        "logs_dir = root/\"logs\"; latest_csv = newest(logs_dir.rglob(\"*.monitor.csv\")) if logs_dir.exists() else None\n",
        "if latest_csv and pd is not None:\n",
        "    print(\"\\nLatest log:\")\n",
        "    print(\"  -\", short(latest_csv), \"|\", fmt_sz(latest_csv.stat().st_size), \"|\", fmt_ts(latest_csv))\n",
        "    try:\n",
        "        df = pd.read_csv(latest_csv, comment=\"#\")\n",
        "        episodes = len(df); total_steps = int(df[\"l\"].sum()) if \"l\" in df else None\n",
        "        last20 = float(df[\"r\"].tail(20).mean()) if \"r\" in df and episodes>0 else None\n",
        "        best = float(df[\"r\"].max()) if \"r\" in df and episodes>0 else None\n",
        "        print(\"  - Episodes:\", episodes)\n",
        "        if total_steps is not None: print(\"  - Timesteps:\", total_steps)\n",
        "        if last20  is not None:    print(f\"  - Mean reward over last 20: {last20:.2f}\")\n",
        "        if best    is not None:    print(f\"  - Best single-episode reward: {best:.2f}\")\n",
        "    except Exception as e:\n",
        "        print(\"  - CSV parse failed:\", e)\n",
        "else:\n",
        "    print(\"\\nNo latest log or pandas unavailable.\")\n",
        "\n",
        "vid = newest((root/\"videos\").rglob(\"*.mp4\")) if (root/\"videos\").exists() else None\n",
        "if vid:\n",
        "    print(\"\\nLatest video:\")\n",
        "    print(\"  -\", short(vid), \"|\", fmt_sz(vid.stat().st_size), \"|\", fmt_ts(vid))\n",
        "else:\n",
        "    print(\"\\nNo latest video found.\")\n",
        "\n",
        "rep_dir = root/\"reports\"; reps = sorted(rep_dir.glob(\"report*.*\")) if rep_dir.exists() else []\n",
        "if reps:\n",
        "    print(\"\\nReports (up to 5):\")\n",
        "    for p in reps[:5]:\n",
        "        print(\"  -\", short(p), \"|\", fmt_sz(p.stat().st_size), \"|\", fmt_ts(p))\n",
        "else:\n",
        "    print(\"\\nNo reports found.\")\n",
        "\n",
        "plots_dir = root/\"plots\"; pl = sorted(plots_dir.glob(\"*\")) if root.joinpath(\"plots\").exists() else []\n",
        "if pl:\n",
        "    print(\"\\nPlots (up to 5):\")\n",
        "    for p in pl[:5]:\n",
        "        if p.is_file():\n",
        "            print(\"  -\", short(p), \"|\", fmt_sz(p.stat().st_size), \"|\", fmt_ts(p))\n",
        "else:\n",
        "    print(\"\\nNo plots found.\")\n",
        "\n",
        "print(\"\\nStatus inspection complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "036bbf61",
      "metadata": {
        "id": "036bbf61"
      },
      "source": [
        "## S-SIZE) Size overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f94843b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f94843b0",
        "outputId": "aff39fd0-eeff-4719-a07e-74546b31d263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bundle candidate path: /content/mario_rl_local\n",
            "  - models/exports  9.6 MB\n",
            "  - models          19.3 MB\n",
            "  - logs            0.0 MB\n",
            "  - videos          0.1 MB\n",
            "  - plots           0.0 MB\n",
            "  - reports         0.0 MB\n",
            "\n",
            "Run S-LOCAL for a full zip or S-LOCAL-LITE for a minimal zip.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path(base_dir); assert root.exists(), f\"The base_dir path does not exist: {base_dir}\"\n",
        "\n",
        "def fmt(n):\n",
        "    units = [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]; i=0; x=float(n)\n",
        "    while x>=1024 and i<len(units)-1: x/=1024; i+=1\n",
        "    return f\"{x:.1f} {units[i]}\"\n",
        "\n",
        "def dir_size(p: Path):\n",
        "    return sum(f.stat().st_size for f in p.rglob(\"*\") if p.is_dir() or f.is_file())\n",
        "\n",
        "total = sum(f.stat().st_size for f in root.rglob(\"*\") if f.is_file())\n",
        "print(f\"Bundle candidate path: {root}\")\n",
        "\n",
        "folders = [\"models/exports\",\"models\",\"logs\",\"videos\",\"plots\",\"reports\"]\n",
        "for sub in folders:\n",
        "    p = root/sub\n",
        "    if p.exists():\n",
        "        sz = sum(f.stat().st_size for f in p.rglob(\"*\") if f.is_file())\n",
        "        print(f\"  - {sub:<15} {sz/1024/1024:.1f} MB\")\n",
        "\n",
        "print(\"\\nRun S-LOCAL for a full zip or S-LOCAL-LITE for a minimal zip.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd772ea",
      "metadata": {
        "id": "abd772ea"
      },
      "source": [
        "## S-LOCAL) Export - full bundle (ZIP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41b37f8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "41b37f8d",
        "outputId": "1c3ca9bb-98fc-45d1-d75c-7856d2f6ebfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full bundle zip created: /content/mario_artifacts.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cff0dfab-37b3-4c40-85ec-59bd0daab71b\", \"mario_artifacts.zip\", 14751338)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "assert Path(base_dir).exists(), \"base_dir does not exist. Run B-LOCAL first.\"\n",
        "\n",
        "zip_path = \"/content/mario_artifacts.zip\"\n",
        "if Path(zip_path).exists():\n",
        "    Path(zip_path).unlink()\n",
        "\n",
        "shutil.make_archive(\"/content/mario_artifacts\", \"zip\", base_dir)\n",
        "print(\"Full bundle zip created:\", zip_path)\n",
        "files.download(zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e56acee",
      "metadata": {
        "id": "7e56acee"
      },
      "source": [
        "## S-LOCAL-LITE) Export - minimal bundle (ZIP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d78a0a9",
      "metadata": {
        "id": "9d78a0a9",
        "outputId": "ba593e88-01d4-4aba-b2cf-984fb7aa1cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimal bundle zip created: /content/mario_minimal_bundle.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_05d96467-6a45-4fff-93c1-0602816446e0\", \"mario_minimal_bundle.zip\", 3767426)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "import json, shutil\n",
        "\n",
        "root = Path(base_dir)\n",
        "out_dir = Path(\"/content/mario_minimal_bundle\")\n",
        "if out_dir.exists():\n",
        "    shutil.rmtree(out_dir)\n",
        "(out_dir / \"models/exports\").mkdir(parents=True, exist_ok=True)\n",
        "(out_dir / \"videos\").mkdir(parents=True, exist_ok=True)\n",
        "(out_dir / \"plots\").mkdir(parents=True, exist_ok=True)\n",
        "(out_dir / \"reports\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def newest(glob):\n",
        "    files = sorted(glob, key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return files[0] if files else None\n",
        "\n",
        "exp = newest((root/\"models\"/\"exports\").glob(\"*.zip\"))\n",
        "if exp:\n",
        "    shutil.copy2(exp, out_dir/\"models/exports\"/exp.name)\n",
        "    meta = exp.with_suffix(\".meta.json\")\n",
        "    if meta.exists():\n",
        "        shutil.copy2(meta, out_dir/\"models/exports\"/meta.name)\n",
        "\n",
        "vid = newest((root/\"videos\").rglob(\"*.mp4\"))\n",
        "if vid:\n",
        "    shutil.copy2(vid, out_dir/\"videos\"/vid.name)\n",
        "\n",
        "for p in (root/\"plots\").glob(\"*\"):\n",
        "    if p.is_file():\n",
        "        shutil.copy2(p, out_dir/\"plots\"/p.name)\n",
        "\n",
        "for r in (root/\"reports\").glob(\"report*.*\"):\n",
        "    shutil.copy2(r, out_dir/\"reports\"/r.name)\n",
        "\n",
        "zip_path = \"/content/mario_minimal_bundle.zip\"\n",
        "if Path(zip_path).exists():\n",
        "    Path(zip_path).unlink()\n",
        "shutil.make_archive(\"/content/mario_minimal_bundle\", \"zip\", out_dir)\n",
        "print(\"Minimal bundle zip created:\", zip_path)\n",
        "files.download(zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52447aa6",
      "metadata": {
        "id": "52447aa6"
      },
      "source": [
        "## J) Evaluation (N episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a2c9d8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a2c9d8f",
        "outputId": "4bf3b087-454f-41a2-f0ec-6567fec06ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyVecEnv created: 1\n",
            "VecDropResetKwargs active.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            "/tmp/ipython-input-738992027.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  total += float(reward)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation: episodes=5, mean=33.00, std=0.00, scores=[33.0, 33.0, 33.0, 33.0, 33.0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np, json\n",
        "from stable_baselines3 import PPO\n",
        "from pathlib import Path\n",
        "\n",
        "def find_latest_export_zip(base_dir_str):\n",
        "    ex = sorted((Path(base_dir_str)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return str(ex[0]) if ex else None\n",
        "\n",
        "model_zip = find_latest_export_zip(base_dir); assert model_zip, 'No exported model was found.'\n",
        "action_set_eval = 'SIMPLE_MOVEMENT'\n",
        "mp = Path(model_zip).with_suffix('.meta.json')\n",
        "if mp.exists():\n",
        "    try:\n",
        "        j=json.loads(mp.read_text()); action_set_eval=j.get('action_set',action_set_eval)\n",
        "    except Exception: pass\n",
        "\n",
        "eval_env = make_vector_env(1, f\"{base_dir}/logs/_eval\", None,\n",
        "                           action_set=action_set_eval, frame_skip=2,\n",
        "                           action_repeat=int(globals().get('action_repeat',2)),\n",
        "                           frame_stack=int(globals().get('frame_stack',2)),\n",
        "                           prefer_subproc=False)\n",
        "model = PPO.load(model_zip, env=eval_env, device=('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "N=5; returns=[]; obs = eval_env.reset()\n",
        "for ep in range(N):\n",
        "    done=np.array([False]); total=0.0\n",
        "    while not done.any():\n",
        "        action,_ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, _ = eval_env.step(action)\n",
        "        total += float(reward)\n",
        "    returns.append(total)\n",
        "    obs = eval_env.reset()\n",
        "eval_env.close()\n",
        "print(f'Evaluation: episodes={N}, mean={np.mean(returns):.2f}, std={np.std(returns):.2f}, scores={returns}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46f1bf76",
      "metadata": {
        "id": "46f1bf76"
      },
      "source": [
        "## J2) Evaluation with explicit distance (N episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6220c3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6220c3d",
        "outputId": "73a12393-372c-411f-a65c-a79b50c9a155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyVecEnv created: 1\n",
            "VecDropResetKwargs active.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2226529747.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  total += float(reward)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episodes=5\n",
            "Mean reward     = 33.00 (std 0.00)\n",
            "Mean x distance = 297.0 (per-episode: [297, 297, 297, 297, 297])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np, json, torch\n",
        "from stable_baselines3 import PPO\n",
        "from pathlib import Path\n",
        "\n",
        "def find_latest_export_zip(base_dir_str):\n",
        "    ex = sorted((Path(base_dir_str)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return str(ex[0]) if ex else None\n",
        "\n",
        "model_zip = find_latest_export_zip(base_dir); assert model_zip, 'No exported model was found.'\n",
        "action_set_eval = 'SIMPLE_MOVEMENT'\n",
        "mp = Path(model_zip).with_suffix('.meta.json')\n",
        "if mp.exists():\n",
        "    try:\n",
        "        j=json.loads(mp.read_text()); action_set_eval=j.get('action_set',action_set_eval)\n",
        "    except Exception: pass\n",
        "\n",
        "eval_env = make_vector_env(1, f\"{base_dir}/logs/_eval_distance\", None,\n",
        "                           action_set=action_set_eval, frame_skip=2,\n",
        "                           action_repeat=int(globals().get('action_repeat',2)),\n",
        "                           frame_stack=int(globals().get('frame_stack',2)),\n",
        "                           prefer_subproc=False)\n",
        "model = PPO.load(model_zip, env=eval_env, device=('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "N=5; returns=[]; distances=[]; obs = eval_env.reset()\n",
        "for ep in range(N):\n",
        "    done=np.array([False]); total=0.0; x_max=0\n",
        "    while not done.any():\n",
        "        action,_ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, infos = eval_env.step(action)\n",
        "        total += float(reward)\n",
        "        x = infos[0].get('x_pos', 0)\n",
        "        if x > x_max: x_max = x\n",
        "    returns.append(total); distances.append(x_max)\n",
        "    obs = eval_env.reset()\n",
        "eval_env.close()\n",
        "print(f'Episodes={N}')\n",
        "print(f'Mean reward     = {np.mean(returns):.2f} (std {np.std(returns):.2f})')\n",
        "print(f'Mean x distance = {np.mean(distances):.1f} (per-episode: {distances})')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d832e87",
      "metadata": {
        "id": "1d832e87"
      },
      "source": [
        "## U-LOCAL-PACK) Prepare GitHub-ready zip (NO tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a0f18ee1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "a0f18ee1",
        "outputId": "d55b254d-dff3-464d-cf21-2273ae1c8389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved current notebook snapshot to: /content/Mario_RL_PPO_Local_TrainingSuite.ipynb\n",
            "Created: /content/mario_publish_local.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fc6bc00e-0cde-482a-b8ec-0fbd4dd532be\", \"mario_publish_local.zip\", 82041)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# U-LOCAL-PACK) Prepare GitHub-ready zip (NO tokens) — with self-capture fallback\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "import shutil, textwrap, json\n",
        "\n",
        "BASE = \"/content/mario_rl_local\"\n",
        "NB_DEFAULT = \"/content/Mario_RL_PPO_Local_TrainingSuite.ipynb\"\n",
        "\n",
        "def ensure_notebook_on_disk(nb_target:str):\n",
        "    \"\"\"Ensure the current Colab notebook exists as a file on /content.\n",
        "    If not present, capture the in-memory notebook via Colab's internal API.\"\"\"\n",
        "    p = Path(nb_target)\n",
        "    if p.exists():\n",
        "        print(\"Found existing notebook file:\", p)\n",
        "        return p\n",
        "    # Try to capture the current notebook from Colab\n",
        "    try:\n",
        "        from google.colab import _message\n",
        "        data = _message.blocking_request('get_ipynb', timeout_sec=120)\n",
        "        name = (data.get('metadata', {})\n",
        "                    .get('colab', {})\n",
        "                    .get('name', 'Mario_RL_PPO_Local_TrainingSuite')).strip().replace(' ', '_')\n",
        "        out = Path('/content') / f\"{name}.ipynb\"\n",
        "        out.write_text(json.dumps(data), encoding='utf-8')\n",
        "        print(\"Saved current notebook snapshot to:\", out)\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        print(\"Could not auto-capture the current notebook:\", repr(e))\n",
        "        return None\n",
        "\n",
        "# 0) Make publish dir\n",
        "pub = Path(\"/content/mario_publish_local\")\n",
        "if pub.exists():\n",
        "    shutil.rmtree(pub)\n",
        "(pub / \"reports\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Notebook: ensure it exists, then copy\n",
        "nb_path = ensure_notebook_on_disk(NB_DEFAULT)\n",
        "assert nb_path and nb_path.exists(), (\n",
        "    \"Could not find or export the current notebook. \"\n",
        "    \"Try: File → Save, then re-run this cell.\"\n",
        ")\n",
        "shutil.copy2(nb_path, pub / nb_path.name)\n",
        "\n",
        "# 2) Reports (if generated in section G)\n",
        "rep_src = Path(BASE) / \"reports\"\n",
        "if rep_src.exists():\n",
        "    for p in rep_src.glob(\"report_local.*\"):\n",
        "        shutil.copy2(p, pub / \"reports\" / p.name)\n",
        "\n",
        "# 3) .gitignore (exclude heavy artifacts)\n",
        "(pub / \".gitignore\").write_text(textwrap.dedent(\"\"\"\\\n",
        "models/\n",
        "videos/\n",
        "logs/\n",
        "plots/\n",
        "*.zip\n",
        "*.mp4\n",
        "*.avi\n",
        "*.mov\n",
        "*.pth\n",
        "*.pt\n",
        ".DS_Store\n",
        ".ipynb_checkpoints/\n",
        "\"\"\"), encoding=\"utf-8\")\n",
        "\n",
        "# 4) README\n",
        "(pub / \"README.md\").write_text(textwrap.dedent(\"\"\"\\\n",
        "# Mario RL PPO — Local Training Suite\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/sarapersson/mario-rl-ppo/blob/main/Mario_RL_PPO_Local_TrainingSuite.ipynb)\n",
        "\n",
        "Train a PPO agent (Stable-Baselines3 + PyTorch) to play **Super Mario Bros** in a fully local, token-free Colab workflow.\n",
        "Observations use **84×84 grayscale** stacked frames; default action set is **SIMPLE_MOVEMENT**; default reward mode matches the project spec (**spec**).\n",
        "\n",
        "> **Note:** The `/content/mario_rl_local/` folder is generated at runtime and is **not** versioned.\n",
        "> Large artifacts are excluded by `.gitignore`:\n",
        "> `models/`, `videos/`, `logs/`, `plots/`, `*.mp4`, `*.zip`, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "- [Overview](#overview)\n",
        "- [Key Features](#key-features)\n",
        "- [Repo Layout](#repo-layout)\n",
        "- [Requirements](#requirements)\n",
        "- [Quick Start (Colab)](#quick-start-colab)\n",
        "- [Training Recipes](#training-recipes)\n",
        "- [Configuration](#configuration)\n",
        "- [Evaluation & Reporting](#evaluation--reporting)\n",
        "- [Exporting Artifacts](#exporting-artifacts)\n",
        "- [Troubleshooting](#troubleshooting)\n",
        "- [Reproducibility](#reproducibility)\n",
        "- [Notes on Reward Modes](#notes-on-reward-modes)\n",
        "- [Roadmap](#roadmap)\n",
        "- [Acknowledgments](#acknowledgments)\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This project implements a **PPO** reinforcement learning agent that learns to progress through **Super Mario Bros**. The agent receives only pixel observations and learns via reward feedback.\n",
        "\n",
        "- **Goal:** learn forward progress and avoid dying.\n",
        "- **Data:** generated on-the-fly from the environment (no static dataset).\n",
        "- **Observation preprocessing:** grayscale, resize to 84×84, stack frames.\n",
        "- **Action sets:** `SIMPLE_MOVEMENT` (default, 7 actions) or `RIGHT_ONLY` (5 actions).\n",
        "- **Default reward mode (\"spec\"):** +1 when moving forward within a step, −15 on death, 0 otherwise.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Local-only workflow:** no Drive, no tokens; everything under `/content/mario_rl_local`.\n",
        "- **Two reward modes:**\n",
        "  - `spec` (default) matches assignment spec.\n",
        "  - `shaped` is optional for faster early learning.\n",
        "- **Robustness patches:** JoypadSpace seed/options handling, nes-py overflow hotfix, NumPy pin.\n",
        "- **Auto-resume training:** warmup + configurable blocks; quick test and full runs.\n",
        "- **Evaluation:** aggregate reward (J) and reward+distance (J2).\n",
        "- **Video export:** trained agent (F1) and random baseline (F2).\n",
        "- **Report generator:** 1–2 pages summarizing data prep, model, metrics, and improvements (G).\n",
        "- **Token-free GitHub packer:** produce a clean ZIP for manual upload (U-LOCAL-PACK).\n",
        "\n",
        "---\n",
        "\n",
        "## Repo Layout\n",
        "\n",
        "**Root**\n",
        "- `Mario_RL_PPO_Local_TrainingSuite.ipynb` # main Colab notebook\n",
        "- `requirements.txt`\n",
        "- `.gitignore`\n",
        "- `README.md`\n",
        "\n",
        "**Folder `reports/`**\n",
        "- `report_local.md`\n",
        "- `report_local.html` (optional)\n",
        "\n",
        "Artifacts created during runs (ignored by git unless you add them):\n",
        "\n",
        "## Runtime Artifacts (not versioned)\n",
        "\n",
        "**Folder:** `/content/mario_rl_local/`\n",
        "\n",
        "- **logs/**\n",
        "  - `<run-id>/`\n",
        "    - `*.monitor.csv`\n",
        "    - `progress.txt` (optional)\n",
        "\n",
        "- **models/**\n",
        "  - `<run-id>/`\n",
        "    - `best_model.zip` (from EvalCallback)\n",
        "    - `ckpt_*.zip` (checkpoints)\n",
        "  - **exports/**\n",
        "    - `<timestamp>_*.zip` (exported models)\n",
        "    - `<timestamp>_*.meta.json`\n",
        "\n",
        "- **videos/**\n",
        "  - `play_*.mp4` (trained agent)\n",
        "  - `random_*.mp4` (random baseline)\n",
        "\n",
        "- **plots/**\n",
        "  - `*.png` (optional)\n",
        "\n",
        "- **reports/**\n",
        "  - `report_local.md`\n",
        "  - `report_local.html`\n",
        "\n",
        "---\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Google Colab (CPU or GPU). GPU recommended (T4 or better).\n",
        "- Python libs are installed by the notebook:\n",
        "  - `stable-baselines3`, `gymnasium==0.29.1`, `gym==0.26.2`, `shimmy`\n",
        "  - `nes-py==8.2.1`, `gym-super-mario-bros==7.4.0`\n",
        "  - `numpy==1.26.4` (pinned to avoid ABI issues)\n",
        "  - `pillow`, `imageio`, `imageio-ffmpeg`, `moviepy`, `markdown`, `pandas`, `matplotlib`\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Start (Colab)\n",
        "\n",
        "1. **Open the notebook** (Colab badge at top).\n",
        "2. Run **A1** (pin NumPy) → **Runtime → Restart runtime**.\n",
        "3. Run **A2–A3** to install and verify dependencies.\n",
        "4. Run **B-LOCAL** to set up local folders under `/content/mario_rl_local/`.\n",
        "5. Choose:\n",
        "   - **T** (Quick test): short warmup + short main pass.\n",
        "   - **D** (Full training with blocks): warmup + multiple blocks.\n",
        "6. Inspect curves (**E**), evaluate (**J/J2**), and generate the report (**G**).\n",
        "7. Package for GitHub (**U-LOCAL-PACK**) and upload via GitHub web UI.\n",
        "\n",
        "---\n",
        "\n",
        "## Training Recipes\n",
        "\n",
        "- **Quick Test (T):** a small warmup (e.g., 3k steps) + one short block (e.g., 8k steps).\n",
        "  - Good for smoke tests and for generating initial artifacts.\n",
        "- **Full Training (D):** warmup + N blocks with auto-resume and safe restarts.\n",
        "  - Increase `num_blocks` and `timesteps_per_block` as needed (GPU recommended).\n",
        "\n",
        "**Tip:** Start with `RIGHT_ONLY` for early forward motion, then switch to `SIMPLE_MOVEMENT` for richer behavior.\n",
        "Default here is `SIMPLE_MOVEMENT` to match the final spec.\n",
        "\n",
        "---\n",
        "\n",
        "## Configuration\n",
        "\n",
        "In section **C1** of the notebook:\n",
        "- `action_set = 'SIMPLE_MOVEMENT'` or `'RIGHT_ONLY'` (default: `SIMPLE_MOVEMENT`)\n",
        "- `frame_stack = 2` (stacked frames)\n",
        "- `action_repeat = 2` (repeat actions to reduce jitter)\n",
        "- `frame_skip = 4` (warmup skip; main pass often uses 2)\n",
        "- Global `REWARD_MODE` (in section C): `\"spec\"` (default) or `\"shaped\"`\n",
        "\n",
        "Model architecture:\n",
        "- Compact CNN feature extractor (`SmallCNNFeatures`)\n",
        "- PPO policy with `net_arch=[128, 128]`\n",
        "- Default PPO hyperparameters tuned for stability and speed in Colab\n",
        "\n",
        "---\n",
        "\n",
        "## Evaluation & Reporting\n",
        "\n",
        "- **E:** plots reward per episode with EMA(20).\n",
        "- **J:** evaluates N episodes and reports mean/std reward.\n",
        "- **J2:** evaluates N episodes and reports reward + max `x_pos` (how far Mario progressed).\n",
        "- **G:** generates a short report (1–2 pages) covering:\n",
        "  - Data preparation (84×84 grayscale, stacking, skip/repeat)\n",
        "  - Model selection (PPO) and motivation\n",
        "  - Metrics: episode rewards, last-20 mean, best reward, distance\n",
        "  - Improvement suggestions\n",
        "\n",
        "Reports are saved to `/content/mario_rl_local/reports/`.\n",
        "\n",
        "---\n",
        "\n",
        "## Exporting Artifacts\n",
        "\n",
        "- **F1:** 60s video of the trained agent (MP4).\n",
        "- **F2:** 15s random baseline video for comparison.\n",
        "- **S-LOCAL:** full ZIP of `/content/mario_rl_local` (large).\n",
        "- **S-LOCAL-LITE:** a small ZIP with latest export, video, plots, and reports.\n",
        "- **U-LOCAL-PACK:** GitHub-ready ZIP containing:\n",
        "  - Notebook, report(s), requirements.txt, .gitignore, README.\n",
        "\n",
        "Upload the contents of the ZIP to GitHub via the web UI (no tokens required).\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "**NumPy ABI or Tensorboard errors**\n",
        "- Always run **A1** first and pin `numpy==1.26.4`, then **restart runtime**.\n",
        "\n",
        "**`JoypadSpace.reset(...) got unexpected keyword argument 'seed'`**\n",
        "- The notebook patches JoypadSpace to drop unsupported kwargs and wraps vector envs to strip `seed/options`.\n",
        "\n",
        "**`OverflowError` in nes-py `_rom.py`**\n",
        "- A small overflow hotfix is applied in section C. Make sure A2 is run after restart.\n",
        "\n",
        "**`AssertionError: The number of environments ... set_env ...`**\n",
        "- When loading a model, the notebook uses `PPO.load(path, env=...)` to match `n_envs`. Avoid switching `n_envs` with `set_env` directly.\n",
        "\n",
        "**`VecVideoRecorder` requires `render_mode='rgb_array'`**\n",
        "- The video cells build envs with `render_mode='rgb_array'`. If you change code, keep that setting for video export.\n",
        "\n",
        "**Worker crashes (EOFError) in SubprocVecEnv**\n",
        "- The training loop auto-restarts envs and can fall back to `DummyVecEnv`. If instability persists, reduce `num_envs`.\n",
        "\n",
        "---\n",
        "\n",
        "## Reproducibility\n",
        "\n",
        "- Seeds are set for `numpy`, `random`, and `torch`.\n",
        "- Model exports include a small `.meta.json` capturing:\n",
        "  - `action_set`, `frame_stack`, `action_repeat`, `reward_mode`\n",
        "- Use the same reward mode and action set when resuming from exports.\n",
        "\n",
        "---\n",
        "\n",
        "## Notes on Reward Modes\n",
        "\n",
        "- **spec (default):**\n",
        "  +1 when forward progress occurs within a step; −15 on death; 0 otherwise.\n",
        "  This aligns with the assignment’s project specification.\n",
        "\n",
        "- **shaped (optional):**\n",
        "  Dense progress shaping (+dx), small per-step penalty, checkpoint bonuses, and death penalty.\n",
        "  Useful for faster early learning; consider switching back to `spec` for final evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "## Roadmap\n",
        "\n",
        "- Optional curriculum from `RIGHT_ONLY` to `SIMPLE_MOVEMENT`.\n",
        "- Entropy scheduling: 0.02 early → 0.005 later.\n",
        "- Slightly larger CNN (e.g., +64 filters) if learning plateaus.\n",
        "- Tune `frame_skip` and `action_repeat` for your runtime.\n",
        "- Longer training runs on GPU for level completion attempts.\n",
        "\n",
        "---\n",
        "\n",
        "## Acknowledgments\n",
        "\n",
        "- [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
        "- [gym-super-mario-bros](https://github.com/Kautenja/gym-super-mario-bros)\n",
        "- [Gymnasium](https://github.com/Farama-Foundation/Gymnasium) and [Gym](https://github.com/openai/gym)\n",
        "- [nes-py](https://github.com/Kautenja/nes-py)\n",
        "\"\"\"), encoding=\"utf-8\")\n",
        "\n",
        "# 6) Zip and download\n",
        "zip_path = \"/content/mario_publish_local.zip\"\n",
        "if Path(zip_path).exists():\n",
        "    Path(zip_path).unlink()\n",
        "shutil.make_archive(\"/content/mario_publish_local\", \"zip\", pub)\n",
        "print(\"Created:\", zip_path)\n",
        "files.download(zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f36dbd7c",
      "metadata": {
        "id": "f36dbd7c"
      },
      "source": [
        "## P) Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9d6f31",
      "metadata": {
        "id": "4c9d6f31"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gc, torch\n",
        "try:\n",
        "    if 'venv' in globals(): venv.close()\n",
        "    if 'eval_env' in globals(): eval_env.close()\n",
        "except Exception as e:\n",
        "    print('Info: env close raised:', e)\n",
        "for name in ['model','venv','eval_env']:\n",
        "    if name in globals(): del globals()[name]\n",
        "gc.collect()\n",
        "try:\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "except Exception: pass\n",
        "print('Cleanup complete.')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}