{"ipynb": {"cells": [{"cell_type": "markdown", "id": "d14450ce", "metadata": {"id": "d14450ce"}, "source": ["# Mario PPO - Local Training Suite\n", "\n", "This notebook trains a PPO agent (Stable-Baselines3, PyTorch) to play Super Mario Bros locally in Colab\n", "(no cloud storage required). Observations use 84x84 grayscale frames. Reward modes:\n", "- \"spec\" (default): +1 when forward progress occurs in a step, -15 on death, else 0 (matches project spec)\n", "- \"shaped\": dense progress shaping (+dx), step penalty, checkpoints, and death penalty\n", "\n", "Default action set: SIMPLE_MOVEMENT (7 actions).\n", "\n", "**Contents**\n", "- A0) Runtime hygiene and warning filters\n", "- A1) Pin NumPy version (requires runtime restart)\n", "- A2) Install dependencies\n", "- A3) Version information\n", "- B-LOCAL) Local storage in /content (no cloud)\n", "- C) Environment tools and wrappers (84x84 grayscale, reward mode toggle)\n", "- C1) Configuration panel\n", "- C2) Sanity check\n", "- C3) Action sets\n", "- D0) Hardware information\n", "- D) Training with auto-resume (warmup plus blocks)\n", "- T) Quick test (short training)\n", "- E) Learning analysis (reward curve)\n", "- F1) Video: trained model (60 s)\n", "- F2) Video: random agent (15 s)\n", "- G) Report generator (1\u20132 pages, covers all required points)\n", "- H) Export and import helpers\n", "- S-STATUS) Status overview (local artifacts)\n", "- S-SIZE) Size overview\n", "- S-LOCAL) Export - full bundle (ZIP)\n", "- S-LOCAL-LITE) Export - minimal bundle (ZIP)\n", "- J) Evaluation (N episodes)\n", "- J2) Evaluation with explicit distance (N episodes)\n", "- U-LOCAL-PACK) Prepare GitHub-ready zip (NO tokens)\n", "- P) Cleanup\n"]}, {"cell_type": "markdown", "id": "c8355652", "metadata": {"id": "c8355652"}, "source": ["## A0) Runtime hygiene and warning filters"]}, {"cell_type": "code", "execution_count": 1, "id": "4f237f57", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4f237f57", "executionInfo": {"status": "ok", "timestamp": 1763328403122, "user_tz": -60, "elapsed": 20, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "99a1ebbb-0f8e-4a78-e59b-320c52da920a"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Runtime hygiene and conservative settings have been applied.\n"]}], "source": ["\n", "import os, warnings\n", "os.environ['OMP_NUM_THREADS'] = '1'\n", "os.environ['MKL_NUM_THREADS'] = '1'\n", "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n", "warnings.filterwarnings('ignore', category=UserWarning, message='.*deprecated.*')\n", "print('Runtime hygiene and conservative settings have been applied.')\n"]}, {"cell_type": "markdown", "id": "4b3b06b3", "metadata": {"id": "4b3b06b3"}, "source": ["## A1) Pin NumPy version (requires runtime restart)"]}, {"cell_type": "code", "execution_count": 2, "id": "f06aaf33", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "f06aaf33", "executionInfo": {"status": "ok", "timestamp": 1763328442039, "user_tz": -60, "elapsed": 31338, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "8e6088fb-1d8a-43b6-c23b-92b5e455050c"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Found existing installation: numpy 2.0.2\n", "Uninstalling numpy-2.0.2:\n", "  Successfully uninstalled numpy-2.0.2\n", "\u001b[33mWARNING: Skipping nes-py as it is not installed.\u001b[0m\u001b[33m\n", "\u001b[0m\u001b[33mWARNING: Skipping gym-super-mario-bros as it is not installed.\u001b[0m\u001b[33m\n", "\u001b[0mFound existing installation: gym 0.25.2\n", "Uninstalling gym-0.25.2:\n", "  Successfully uninstalled gym-0.25.2\n", "Found existing installation: gymnasium 1.2.2\n", "Uninstalling gymnasium-1.2.2:\n", "  Successfully uninstalled gymnasium-1.2.2\n", "\u001b[33mWARNING: Skipping stable-baselines3 as it is not installed.\u001b[0m\u001b[33m\n", "\u001b[0m\u001b[33mWARNING: Skipping shimmy as it is not installed.\u001b[0m\u001b[33m\n", "\u001b[0mFound existing installation: tensorflow 2.19.0\n", "Uninstalling tensorflow-2.19.0:\n", "  Successfully uninstalled tensorflow-2.19.0\n", "Found existing installation: tensorboard 2.19.0\n", "Uninstalling tensorboard-2.19.0:\n", "  Successfully uninstalled tensorboard-2.19.0\n", "Found existing installation: tensorboard-data-server 0.7.2\n", "Uninstalling tensorboard-data-server-0.7.2:\n", "  Successfully uninstalled tensorboard-data-server-0.7.2\n", "\u001b[33mWARNING: Skipping tensorflow-estimator as it is not installed.\u001b[0m\u001b[33m\n", "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-io-gcs-filesystem as it is not installed.\u001b[0m\u001b[33m\n", "\u001b[0mCollecting numpy==1.26.4\n", "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n", "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m300.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hInstalling collected packages: numpy\n", "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n", "dopamine-rl 4.1.2 requires gym<=0.25.2, which is not installed.\n", "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, which is not installed.\n", "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n", "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, which is not installed.\n", "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n", "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n", "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n", "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n", "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n", "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n", "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n", "\u001b[0mSuccessfully installed numpy-1.26.4\n", "NumPy version: 2.0.2\n", "Please restart the runtime now: Runtime -> Restart session. After restarting, continue with section A2.\n"]}], "source": ["\n", "# Pin NumPy to 1.26.4 to avoid ABI issues with older RL and game libraries.\n", "!python -m pip uninstall -y numpy nes-py gym-super-mario-bros gym gymnasium stable-baselines3 shimmy\n", "!python -m pip uninstall -y tensorflow tensorboard tensorboard-data-server tensorflow-estimator tensorflow-io-gcs-filesystem || true\n", "!python -m pip install --no-cache-dir numpy==1.26.4\n", "import numpy as np; print('NumPy version:', np.__version__)\n", "print('Please restart the runtime now: Runtime -> Restart session. After restarting, continue with section A2.')\n"]}, {"cell_type": "markdown", "id": "257160c0", "metadata": {"id": "257160c0"}, "source": ["## A2) Install dependencies"]}, {"cell_type": "code", "execution_count": 1, "id": "174d8f66", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "174d8f66", "executionInfo": {"status": "ok", "timestamp": 1763328494449, "user_tz": -60, "elapsed": 37984, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "2e13ed7c-77c5-4f5b-b792-93fa4473d863"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Collecting stable-baselines3\n", "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n", "Collecting gymnasium==0.29.1\n", "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n", "Collecting shimmy\n", "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n", "Collecting gym==0.26.2\n", "  Downloading gym-0.26.2.tar.gz (721 kB)\n", "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n", "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n", "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n", "Collecting nes-py==8.2.1\n", "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n", "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m240.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n", "Collecting gym-super-mario-bros==7.4.0\n", "  Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl.metadata (10 kB)\n", "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.2)\n", "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (0.6.0)\n", "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n", "Collecting moviepy\n", "  Downloading moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n", "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n", "Collecting pillow\n", "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n", "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (3.10)\n", "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n", "Collecting pandas\n", "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n", "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m335.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n", "Collecting matplotlib\n", "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n", "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (1.26.4)\n", "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (3.1.2)\n", "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (4.15.0)\n", "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (0.0.4)\n", "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym==0.26.2) (0.1.0)\n", "Collecting pyglet<=1.5.21,>=1.4.0 (from nes-py==8.2.1)\n", "  Downloading pyglet-1.5.21-py3-none-any.whl.metadata (7.6 kB)\n", "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.12/dist-packages (from nes-py==8.2.1) (4.67.1)\n", "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.8.0+cu126)\n", "INFO: pip is looking at multiple versions of shimmy to determine which version is compatible with other requirements. This could take a while.\n", "Collecting shimmy\n", "  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n", "Requirement already satisfied: decorator<6.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n", "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n", "Requirement already satisfied: python-dotenv>=0.10 in /usr/local/lib/python3.12/dist-packages (from moviepy) (1.2.1)\n", "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n", "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n", "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n", "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n", "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n", "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n", "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n", "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n", "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n", "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n", "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n", "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n", "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.3)\n", "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n", "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n", "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n", "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n", "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n", "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n", "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n", "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n", "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n", "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n", "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n", "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n", "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n", "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.3)\n", "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n", "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n", "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n", "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.0)\n", "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n", "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n", "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hDownloading gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m231.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hDownloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m257.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hDownloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n", "Downloading moviepy-2.2.1-py3-none-any.whl (129 kB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m270.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m232.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hDownloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m213.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hDownloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m294.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hBuilding wheels for collected packages: gym, nes-py\n", "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n", "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827727 sha256=8f4bc1d9dab129456a392a6e0225080b2d70153c68f1804fae1aaa9797aedff3\n", "  Stored in directory: /tmp/pip-ephem-wheel-cache-ge92n0yb/wheels/95/51/6c/9bb05ebbe7c5cb8171dfaa3611f32622ca4658d53f31c79077\n", "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n", "  Created wheel for nes-py: filename=nes_py-8.2.1-cp312-cp312-linux_x86_64.whl size=535722 sha256=10ddb56feec1361c94f550ce9ed9c696971b385b01d118f5b727b380c984fa18\n", "  Stored in directory: /tmp/pip-ephem-wheel-cache-ge92n0yb/wheels/1f/a7/fa/9b0357f258d2e68bdc71df972e02418bceb02355ac1f365c59\n", "Successfully built gym nes-py\n", "Installing collected packages: pyglet, gymnasium, gym, shimmy, pandas, nes-py, moviepy, matplotlib, gym-super-mario-bros, stable-baselines3\n", "  Attempting uninstall: pandas\n", "    Found existing installation: pandas 2.2.2\n", "    Uninstalling pandas-2.2.2:\n", "      Successfully uninstalled pandas-2.2.2\n", "  Attempting uninstall: moviepy\n", "    Found existing installation: moviepy 1.0.3\n", "    Uninstalling moviepy-1.0.3:\n", "      Successfully uninstalled moviepy-1.0.3\n", "  Attempting uninstall: matplotlib\n", "    Found existing installation: matplotlib 3.10.0\n", "    Uninstalling matplotlib-3.10.0:\n", "      Successfully uninstalled matplotlib-3.10.0\n", "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n", "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n", "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, which is not installed.\n", "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n", "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\n", "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\n", "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n", "\u001b[0mSuccessfully installed gym-0.26.2 gym-super-mario-bros-7.4.0 gymnasium-0.29.1 matplotlib-3.10.7 moviepy-2.2.1 nes-py-8.2.1 pandas-2.3.3 pyglet-1.5.21 shimmy-1.3.0 stable-baselines3-2.7.0\n"]}], "source": ["\n", "!python -m pip install -U --no-cache-dir \\\n", "  stable-baselines3 \\\n", "  gymnasium==0.29.1 shimmy \\\n", "  gym==0.26.2 \\\n", "  nes-py==8.2.1 gym-super-mario-bros==7.4.0 \\\n", "  imageio imageio-ffmpeg moviepy pillow markdown pandas matplotlib\n"]}, {"cell_type": "markdown", "id": "89a88196", "metadata": {"id": "89a88196"}, "source": ["## A3) Version information"]}, {"cell_type": "code", "execution_count": 2, "id": "b92bd7a7", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "b92bd7a7", "executionInfo": {"status": "ok", "timestamp": 1763328505721, "user_tz": -60, "elapsed": 7924, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "211dd769-fe07-41a3-a61b-28f0d115777f"}, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n", "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n", "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n", "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"]}, {"output_type": "stream", "name": "stdout", "text": ["NumPy: 1.26.4\n", "Gym: 0.26.2\n", "Gymnasium: 0.29.1\n", "Stable-Baselines3: 2.7.0\n", "PyTorch CUDA available: True\n"]}], "source": ["\n", "import numpy, gym, gymnasium, stable_baselines3, torch\n", "print('NumPy:', numpy.__version__)\n", "print('Gym:', gym.__version__)\n", "print('Gymnasium:', gymnasium.__version__)\n", "print('Stable-Baselines3:', stable_baselines3.__version__)\n", "print('PyTorch CUDA available:', torch.cuda.is_available())\n"]}, {"cell_type": "markdown", "id": "f1a0762c", "metadata": {"id": "f1a0762c"}, "source": ["## B-LOCAL) Local storage in /content (no cloud)"]}, {"cell_type": "code", "execution_count": 3, "id": "7c6318e2", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "7c6318e2", "executionInfo": {"status": "ok", "timestamp": 1763328507543, "user_tz": -60, "elapsed": 8, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "1906aafb-4954-4f48-e419-797b1f64449a"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Local storage has been initialized at: /content/mario_rl_local\n"]}], "source": ["\n", "from pathlib import Path\n", "base_dir = \"/content/mario_rl_local\"\n", "for p in (\"logs\",\"models\",\"models/exports\",\"videos\",\"plots\",\"reports\"):\n", "    Path(f\"{base_dir}/{p}\").mkdir(parents=True, exist_ok=True)\n", "BASE = base_dir\n", "print('Local storage has been initialized at:', base_dir)\n"]}, {"cell_type": "markdown", "id": "14e99c0a", "metadata": {"id": "14e99c0a"}, "source": ["## C) Environment tools and wrappers (84x84 grayscale, reward mode toggle)"]}, {"cell_type": "code", "execution_count": 4, "id": "10f6c1f3", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "10f6c1f3", "executionInfo": {"status": "ok", "timestamp": 1763328509873, "user_tz": -60, "elapsed": 30, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "a5c5e8bd-1320-49cc-d924-5c36391218d4"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Info: nes-py hotfix could not be applied: module 'nes_py._rom' has no attribute 'Rom'\n", "JoypadSpace.reset patched to ignore seed/options.\n", "Environment utilities initialized. REWARD_MODE = spec\n"]}], "source": ["\n", "# Environment wrappers and utilities\n", "# - 84x84 grayscale frames (channel last)\n", "# - Frame skip and action repeat\n", "# - Reward modes: \"spec\" (default) or \"shaped\"\n", "# - Early stop on stagnation and max episode length cap\n", "# - Compatibility fixes for nes-py overflow and JoypadSpace.reset kwargs\n", "\n", "import os, numpy as np, torch, torch.nn as nn\n", "from PIL import Image\n", "\n", "import gym_super_mario_bros\n", "from nes_py.wrappers import JoypadSpace\n", "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT\n", "\n", "import gymnasium as gymn\n", "from gymnasium import spaces as gspaces\n", "\n", "from stable_baselines3.common.monitor import Monitor\n", "from stable_baselines3.common.vec_env import (\n", "    DummyVecEnv, SubprocVecEnv, VecFrameStack, VecTransposeImage, VecEnvWrapper\n", ")\n", "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n", "from stable_baselines3.common.env_util import make_vec_env\n", "\n", "# Default reward mode and action set\n", "REWARD_MODE = \"spec\"   # \"spec\" or \"shaped\"\n", "\n", "# nes-py overflow hotfix\n", "try:\n", "    import nes_py._rom as _rom\n", "    def _kb(x): return int(x) * (1<<10)\n", "    _rom.Rom.prg_rom_stop = property(lambda self: int(self.prg_rom_start) + _kb(self.prg_rom_size))\n", "    if hasattr(_rom.Rom,'chr_rom_stop'):\n", "        _rom.Rom.chr_rom_stop = property(lambda self: int(self.chr_rom_start) + _kb(self.chr_rom_size))\n", "    print('nes-py overflow hotfix active.')\n", "except Exception as e:\n", "    print('Info: nes-py hotfix could not be applied:', e)\n", "\n", "def convert_spaces_to_gymnasium(env):\n", "    if not isinstance(env.observation_space, gspaces.Space):\n", "        os_ = env.observation_space\n", "        env.observation_space = gspaces.Box(low=0, high=255, shape=os_.shape, dtype=np.uint8)\n", "    if not isinstance(env.action_space, gspaces.Space):\n", "        a = env.action_space\n", "        if getattr(a, 'n', None) is not None:\n", "            env.action_space = gspaces.Discrete(a.n)\n", "    return env\n", "\n", "class DropResetKwargs(gymn.Wrapper):\n", "    def reset(self, *args, **kwargs):\n", "        kwargs.pop('seed', None); kwargs.pop('options', None)\n", "        out = self.env.reset()\n", "        return out if (isinstance(out, tuple) and len(out)==2) else (out, {})\n", "\n", "class GrayscaleResize84(gymn.ObservationWrapper):\n", "    def __init__(self, env):\n", "        super().__init__(env); self.observation_space = gspaces.Box(0,255,shape=(84,84,1),dtype=np.uint8)\n", "    def observation(self, obs):\n", "        arr = np.array(Image.fromarray(obs).convert('L').resize((84,84)), dtype=np.uint8)\n", "        return arr[...,None]\n", "\n", "class FrameSkip(gymn.Wrapper):\n", "    def __init__(self, env, frame_skip=4): super().__init__(env); self.frame_skip=frame_skip\n", "    def step(self, a):\n", "        R=0.0; inf={}; d=t=False\n", "        for _ in range(self.frame_skip):\n", "            o,r,d,t,inf = self.env.step(a); R+=r\n", "            if d or t: break\n", "        return o,R,d,t,inf\n", "\n", "class ActionRepeatWrapper(gymn.Wrapper):\n", "    def __init__(self, env, action_repeat=2): super().__init__(env); self.action_repeat=action_repeat\n", "    def step(self, a):\n", "        R=0.0; inf={}; d=t=False\n", "        for _ in range(self.action_repeat):\n", "            o,r,d,t,inf = self.env.step(a); R+=r\n", "            if d or t: break\n", "        return o,R,d,t,inf\n", "\n", "class MaxStepsWrapper(gymn.Wrapper):\n", "    def __init__(self, env, max_steps=3000): super().__init__(env); self.max_steps=max_steps; self.t=0\n", "    def reset(self, **kw): self.t=0; return super().reset(**kw)\n", "    def step(self, a):\n", "        o,r,d,t,inf = self.env.step(a); self.t+=1\n", "        if self.t>=self.max_steps and not (d or t):\n", "            t=True; inf=dict(inf); inf['TimeLimit.truncated']=True\n", "        return o,r,d,t,inf\n", "\n", "class StagnationEarlyStop(gymn.Wrapper):\n", "    def __init__(self, env, patience=120): super().__init__(env); self.p=patience; self.prev=0; self.no=0\n", "    def reset(self, **kw): out=super().reset(**kw); self.prev=0; self.no=0; return out\n", "    def step(self, a):\n", "        o,r,d,t,inf = self.env.step(a); x=inf.get('x_pos',0)\n", "        if x>self.prev: self.no=0; self.prev=x\n", "        else:\n", "            self.no+=1\n", "            if self.no>=self.p and not (d or t):\n", "                t=True; inf=dict(inf); inf['EarlyStop.stagnation']=True\n", "        return o,r,d,t,inf\n", "\n", "class DeathPenaltyReward(gymn.Wrapper):\n", "    def step(self, a):\n", "        o,r,d,t,inf = self.env.step(a)\n", "        if d and not inf.get('flag_get'): r -= 15.0\n", "        return o,r,d,t,inf\n", "\n", "class ProgressShapingReward(gymn.Wrapper):\n", "    def __init__(self, env, progress_coef=0.5, per_step_penalty=0.01, progress_checkpoints=(120,300,700), checkpoint_bonus=(5.0,8.0,12.0)):\n", "        super().__init__(env)\n", "        self.c=progress_coef; self.ps=per_step_penalty\n", "        self.ck=list(progress_checkpoints); self.cb=list(checkpoint_bonus)\n", "        self.hit=None; self.prev=0\n", "    def reset(self, **kw): out=super().reset(**kw); self.hit=[False]*len(self.ck); self.prev=0; return out\n", "    def step(self, a):\n", "        o,r,d,t,inf = self.env.step(a); x=inf.get('x_pos',0); dx=max(0,x-self.prev)\n", "        shaped = r + self.c*dx - self.ps\n", "        for i,g in enumerate(self.ck):\n", "            if not self.hit[i] and self.prev < g <= x:\n", "                shaped += self.cb[i]; self.hit[i]=True\n", "        self.prev=x; return o,shaped,d,t,inf\n", "\n", "class SpecReward(gymn.Wrapper):\n", "    def __init__(self, env):\n", "        super().__init__(env); self.prev_x = 0\n", "    def reset(self, **kw):\n", "        obs, info = self.env.reset()\n", "        self.prev_x = info.get('x_pos', 0)\n", "        return obs, info\n", "    def step(self, a):\n", "        o, r, d, t, inf = self.env.step(a)\n", "        x = inf.get('x_pos', 0); dx = max(0, x - self.prev_x)\n", "        shaped = 1.0 if dx > 0 else 0.0\n", "        if d and not inf.get('flag_get', False):\n", "            shaped -= 15.0\n", "        self.prev_x = x\n", "        return o, shaped, d, t, inf\n", "\n", "class SmallCNNFeatures(BaseFeaturesExtractor):\n", "    def __init__(self, observation_space, features_dim=128):\n", "        super().__init__(observation_space, features_dim); C = observation_space.shape[0]\n", "        self.cnn = nn.Sequential(\n", "            nn.Conv2d(C,16,8,4), nn.ReLU(),\n", "            nn.Conv2d(16,32,4,2), nn.ReLU(),\n", "            nn.Flatten()\n", "        )\n", "        with torch.no_grad(): n_flat = self.cnn(torch.zeros(1,C,84,84)).shape[1]\n", "        self.linear = nn.Sequential(nn.Linear(n_flat, features_dim), nn.ReLU())\n", "    def forward(self, x): return self.linear(self.cnn(x.float()/255.0))\n", "\n", "def make_env_compact(render_mode=None, action_set='SIMPLE_MOVEMENT', frame_skip=4, action_repeat=2):\n", "    e = gym_super_mario_bros.make('SuperMarioBros-1-1-v3', apply_api_compatibility=True, render_mode=render_mode)\n", "    e = JoypadSpace(e, RIGHT_ONLY if action_set=='RIGHT_ONLY' else SIMPLE_MOVEMENT)\n", "    e = ActionRepeatWrapper(e, action_repeat=action_repeat)\n", "    e = FrameSkip(e, frame_skip=frame_skip)\n", "    e = GrayscaleResize84(e)\n", "    e = MaxStepsWrapper(e, 3000)\n", "    e = StagnationEarlyStop(e, 120)\n", "    if REWARD_MODE == \"spec\":\n", "        e = SpecReward(e)\n", "    else:\n", "        e = ProgressShapingReward(e, progress_coef=0.5, per_step_penalty=0.01,\n", "                                  progress_checkpoints=(120,300,700), checkpoint_bonus=(5,8,12))\n", "        e = DeathPenaltyReward(e)\n", "    e = convert_spaces_to_gymnasium(e)\n", "    e = Monitor(e)\n", "    e = DropResetKwargs(e)\n", "    return e\n", "\n", "class VecDropResetKwargs(VecEnvWrapper):\n", "    def reset(self, **kwargs):\n", "        kwargs.pop(\"seed\", None); kwargs.pop(\"options\", None)\n", "        try: return self.venv.reset(**kwargs)\n", "        except TypeError: return self.venv.reset()\n", "    def step_async(self, actions): return self.venv.step_async(actions)\n", "    def step_wait(self): return self.venv.step_wait()\n", "\n", "def make_vector_env(num_envs, log_dir, render_mode=None, action_set='SIMPLE_MOVEMENT', frame_skip=4, action_repeat=2, frame_stack=2, prefer_subproc=True):\n", "    if prefer_subproc and num_envs>1:\n", "        try:\n", "            v = make_vec_env(make_env_compact, n_envs=num_envs, vec_env_cls=SubprocVecEnv, monitor_dir=log_dir,\n", "                             env_kwargs=dict(render_mode=render_mode, action_set=action_set, frame_skip=frame_skip, action_repeat=action_repeat))\n", "            print(f'SubprocVecEnv created: {num_envs}')\n", "        except Exception as e:\n", "            print('Info: SubprocVecEnv failed, falling back to DummyVecEnv:', e)\n", "            v = make_vec_env(make_env_compact, n_envs=num_envs, vec_env_cls=DummyVecEnv, monitor_dir=log_dir,\n", "                             env_kwargs=dict(render_mode=render_mode, action_set=action_set, frame_skip=frame_skip, action_repeat=action_repeat))\n", "            print(f'DummyVecEnv created: {num_envs}')\n", "    else:\n", "        v = make_vec_env(make_env_compact, n_envs=1, vec_env_cls=DummyVecEnv, monitor_dir=log_dir,\n", "                         env_kwargs=dict(render_mode=render_mode, action_set=action_set, frame_skip=frame_skip, action_repeat=action_repeat))\n", "        print('DummyVecEnv created: 1')\n", "    v = VecFrameStack(v, n_stack=frame_stack, channels_order=\"last\"); v = VecTransposeImage(v)\n", "    try:\n", "        v = VecDropResetKwargs(v); print(\"VecDropResetKwargs active.\")\n", "    except Exception as e:\n", "        print(\"Info: VecDropResetKwargs could not be activated:\", e)\n", "    return v\n", "\n", "# Patch JoypadSpace.reset to ignore seed and options kwargs\n", "if not getattr(JoypadSpace.reset, \"_patched_ignore_seed\", False):\n", "    _orig_reset = JoypadSpace.reset\n", "    def _reset_ignore_seed(self, *args, **kwargs):\n", "        kwargs.pop(\"seed\", None); kwargs.pop(\"options\", None)\n", "        return _orig_reset(self)\n", "    _reset_ignore_seed._patched_ignore_seed = True\n", "    JoypadSpace.reset = _reset_ignore_seed\n", "    print(\"JoypadSpace.reset patched to ignore seed/options.\")\n", "\n", "print('Environment utilities initialized. REWARD_MODE =', REWARD_MODE)\n"]}, {"cell_type": "markdown", "id": "5b3b9463", "metadata": {"id": "5b3b9463"}, "source": ["## C1) Configuration panel"]}, {"cell_type": "code", "execution_count": 5, "id": "14b1cbc2", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "14b1cbc2", "executionInfo": {"status": "ok", "timestamp": 1763328516732, "user_tz": -60, "elapsed": 22, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "23556d93-3ae7-426c-9e1f-35176f411bca"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Configuration: action_set = SIMPLE_MOVEMENT | num_envs = 1 | frame_stack = 2 | action_repeat = 2 | frame_skip(warmup) = 4 | reward_mode = spec\n"]}], "source": ["\n", "action_set    = 'SIMPLE_MOVEMENT'  # 'SIMPLE_MOVEMENT' (default) or 'RIGHT_ONLY'\n", "num_envs      = 1\n", "frame_stack   = 2\n", "action_repeat = 2\n", "frame_skip    = 4\n", "print('Configuration:',\n", "      'action_set =', action_set,\n", "      '| num_envs =', num_envs,\n", "      '| frame_stack =', frame_stack,\n", "      '| action_repeat =', action_repeat,\n", "      '| frame_skip(warmup) =', frame_skip,\n", "      '| reward_mode =', REWARD_MODE)\n"]}, {"cell_type": "markdown", "id": "8b4e7fe4", "metadata": {"id": "8b4e7fe4"}, "source": ["## C2) Sanity check"]}, {"cell_type": "code", "execution_count": 6, "id": "464156fe", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "464156fe", "executionInfo": {"status": "ok", "timestamp": 1763328527496, "user_tz": -60, "elapsed": 571, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "6a76f1a0-ae3f-42b3-f38b-993ee09a36c1"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["DummyVecEnv created: 1\n", "VecDropResetKwargs active.\n", "Observation space: Box(0, 255, (2, 84, 84), uint8) | Action space: Discrete(7)\n", "Sanity check completed.\n"]}, {"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.12/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.spec to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.spec` for environment variables or `env.get_wrapper_attr('spec')` that will search the reminding wrappers.\u001b[0m\n", "  logger.warn(\n"]}], "source": ["\n", "venv = make_vector_env(1, f\"{base_dir}/logs/_sanity\", render_mode=None,\n", "                       action_set=('RIGHT_ONLY' if action_set=='RIGHT_ONLY' else 'SIMPLE_MOVEMENT'),\n", "                       frame_skip=frame_skip, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "print('Observation space:', venv.observation_space, '| Action space:', venv.action_space)\n", "venv.close(); print('Sanity check completed.')\n"]}, {"cell_type": "markdown", "id": "3b90f8d9", "metadata": {"id": "3b90f8d9"}, "source": ["## C3) Action sets"]}, {"cell_type": "code", "execution_count": 7, "id": "574ff68b", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "574ff68b", "executionInfo": {"status": "ok", "timestamp": 1763328529886, "user_tz": -60, "elapsed": 23, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "d6ea23a7-36c0-4953-c797-5fc01d808ff2"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["RIGHT_ONLY (n = 5): [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B']]\n", "SIMPLE_MOVEMENT (n = 7): [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left']]\n"]}], "source": ["\n", "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT\n", "print('RIGHT_ONLY (n = 5):', RIGHT_ONLY)\n", "print('SIMPLE_MOVEMENT (n = 7):', SIMPLE_MOVEMENT)\n"]}, {"cell_type": "markdown", "id": "c0acb6ef", "metadata": {"id": "c0acb6ef"}, "source": ["## D0) Hardware information"]}, {"cell_type": "code", "execution_count": 8, "id": "f83de041", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "f83de041", "executionInfo": {"status": "ok", "timestamp": 1763328531813, "user_tz": -60, "elapsed": 101, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "95b6324b-d21b-4dac-dded-111ac4794b7a"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["PyTorch CUDA availability: True\n", "GPU 0: Tesla T4 (UUID: GPU-3632d778-ecd2-23b4-40c7-495b86145088)\n", "Sun Nov 16 21:28:51 2025       \n", "Selected device: cuda\n"]}], "source": ["\n", "import torch, shutil, subprocess\n", "print('PyTorch CUDA availability:', torch.cuda.is_available())\n", "if shutil.which('nvidia-smi'):\n", "    print(subprocess.run(['nvidia-smi','-L'], capture_output=True, text=True).stdout.strip())\n", "    print(subprocess.run(['nvidia-smi'], capture_output=True, text=True).stdout.splitlines()[0])\n", "print('Selected device:', 'cuda' if torch.cuda.is_available() else 'cpu')\n"]}, {"cell_type": "markdown", "id": "3c9edc96", "metadata": {"id": "3c9edc96"}, "source": ["## D) Training with auto-resume (warmup plus blocks)"]}, {"cell_type": "code", "execution_count": null, "id": "8e480650", "metadata": {"id": "8e480650"}, "outputs": [], "source": ["\n", "from pathlib import Path\n", "from datetime import datetime\n", "from shutil import copy2\n", "import os, json, numpy as np, random, warnings, torch\n", "from stable_baselines3 import PPO\n", "from stable_baselines3.common.callbacks import EvalCallback\n", "warnings.filterwarnings(\"ignore\", category=UserWarning, message=r\".*env\\.spec.*deprecated.*\")\n", "\n", "def find_latest_export_zip(base_dir_str):\n", "    base = Path(base_dir_str)\n", "    if not base.exists(): return None\n", "    exp = sorted((base/\"models\"/\"exports\").glob(\"*.zip\"), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    if exp: return str(exp[0])\n", "    runs = sorted((base/\"models\").glob(\"*\"), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    for r in runs:\n", "        bm = r / \"best_model.zip\"\n", "        if bm.exists(): return str(bm)\n", "    zips = sorted((base/\"models\").glob(\"*/*.zip\"), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    return str(zips[0]) if zips else None\n", "\n", "def model_meta_path(zip_path):\n", "    return Path(zip_path).with_suffix(\".meta.json\")\n", "\n", "def read_model_meta(zip_path):\n", "    mp = model_meta_path(zip_path)\n", "    if mp.exists():\n", "        try: return json.loads(mp.read_text())\n", "        except Exception: pass\n", "    return None\n", "\n", "def write_model_meta(zip_path, action_set, frame_stack, action_repeat, reward_mode):\n", "    mp = model_meta_path(zip_path)\n", "    mp.write_text(json.dumps(dict(action_set=action_set,\n", "                                  frame_stack=int(frame_stack),\n", "                                  action_repeat=int(action_repeat),\n", "                                  reward_mode=str(reward_mode)), indent=2), encoding=\"utf-8\")\n", "    print(\"Model metadata written:\", mp.name)\n", "\n", "def export_model_copy(src_path, tag, base_dir_str, run_id):\n", "    dst = Path(base_dir_str)/\"models\"/\"exports\"/f\"{run_id}_{tag}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n", "    copy2(src_path, dst); print(\"Model exported:\", dst.name); return str(dst)\n", "\n", "def infer_action_set_from_model(zip_path):\n", "    m = read_model_meta(zip_path)\n", "    if m and m.get(\"action_set\") in (\"RIGHT_ONLY\",\"SIMPLE_MOVEMENT\"):\n", "        print(\"Action set from metadata:\", m[\"action_set\"]); return m[\"action_set\"]\n", "    tmp = PPO.load(zip_path, device=\"cpu\"); n_act = tmp.action_space.n\n", "    det = \"RIGHT_ONLY\" if n_act==5 else (\"SIMPLE_MOVEMENT\" if n_act==7 else None)\n", "    print(\"Action set inferred from action space:\", det); return det\n", "\n", "def make_training_bundle(frame_skip_used, ent_coef, action_set_used, num_envs, log_dir, action_repeat, frame_stack):\n", "    venv     = make_vector_env(num_envs, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=(num_envs>1))\n", "    eval_env = make_vector_env(1,       log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "    policy_kwargs = dict(features_extractor_class=SmallCNNFeatures, features_extractor_kwargs=dict(features_dim=128), net_arch=[128, 128])\n", "    model = PPO(\"CnnPolicy\", venv, policy_kwargs=policy_kwargs, n_steps=256, batch_size=512, n_epochs=3,\n", "                learning_rate=3e-4, gamma=0.999, gae_lambda=0.95, clip_range=0.2, ent_coef=ent_coef, vf_coef=0.5,\n", "                device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"), verbose=1, seed=42)\n", "    eval_cb = EvalCallback(eval_env, best_model_save_path=model_dir, log_path=log_dir, eval_freq=60000, n_eval_episodes=3, deterministic=True)\n", "    return model, venv, eval_env, eval_cb\n", "\n", "def learn_with_restart(model, total_timesteps, eval_cb, frame_skip_used, phase_tag, action_set_used, log_dir, action_repeat, frame_stack):\n", "    start = getattr(model, \"num_timesteps\", 0)\n", "    try:\n", "        model.learn(total_timesteps=total_timesteps, reset_num_timesteps=False, callback=eval_cb)\n", "        return\n", "    except (EOFError, BrokenPipeError, ConnectionResetError) as e:\n", "        print(f\"{phase_tag}: worker crashed ({type(e).__name__}), attempting restart.\")\n", "        try:\n", "            old_env = model.get_env(); n_model_envs = getattr(old_env, \"num_envs\", 1)\n", "        except Exception:\n", "            n_model_envs = 1\n", "        try: model.get_env().close()\n", "        except Exception: pass\n", "        train_re = make_vector_env(n_model_envs, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "        eval_re  = make_vector_env(1, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "        model.set_env(train_re)\n", "        cb2 = EvalCallback(eval_re, best_model_save_path=model_dir, log_path=log_dir, eval_freq=60000, n_eval_episodes=3, deterministic=True)\n", "        done_so_far = max(0, getattr(model, \"num_timesteps\", 0) - start)\n", "        remaining   = max(0, total_timesteps - done_so_far)\n", "        if remaining > 0:\n", "            model.learn(total_timesteps=remaining, reset_num_timesteps=False, callback=cb2)\n", "        try: train_re.close(); eval_re.close()\n", "        except Exception: pass\n", "\n", "from pathlib import Path\n", "run_id  = datetime.now().strftime(\"ppo_local_%Y%m%d_%H%M%S\")\n", "log_dir   = f\"{base_dir}/logs/{run_id}\"\n", "model_dir = f\"{base_dir}/models/{run_id}\"\n", "for d in (log_dir, model_dir): Path(d).mkdir(parents=True, exist_ok=True)\n", "Path(f\"{base_dir}/models/exports\").mkdir(parents=True, exist_ok=True)\n", "\n", "import random\n", "np.random.seed(42); random.seed(42); torch.manual_seed(42)\n", "\n", "num_blocks           = 2\n", "timesteps_per_block  = 30000\n", "warmup_timesteps     = 10000\n", "warmup_frame_skip    = int(globals().get('frame_skip',4))\n", "warmup_ent_coef      = 0.02\n", "\n", "resume_zip = find_latest_export_zip(base_dir)\n", "if resume_zip is not None:\n", "    det = infer_action_set_from_model(resume_zip)\n", "    if det and det != globals().get('action_set'):\n", "        print(\"Notebook action_set differs from model; switching notebook to model action_set.\")\n", "        action_set = det\n", "\n", "if resume_zip is None:\n", "    print(f\"Warmup: frame_skip={warmup_frame_skip}, ent_coef={warmup_ent_coef}, action_set={action_set}, reward_mode={REWARD_MODE}.\")\n", "    model, venv, eval_env, eval_cb = make_training_bundle(warmup_frame_skip, warmup_ent_coef, action_set, num_envs, log_dir, action_repeat, frame_stack)\n", "    learn_with_restart(model, warmup_timesteps, eval_cb, warmup_frame_skip, \"warmup\", action_set, log_dir, action_repeat, frame_stack)\n", "    ckpt_boot = Path(model_dir)/\"ckpt_bootstrap.zip\"; model.save(str(ckpt_boot)); print(\"Warmup checkpoint saved:\", ckpt_boot.name)\n", "    resume_zip = export_model_copy(ckpt_boot, \"bootstrap\", base_dir, run_id)\n", "    write_model_meta(resume_zip, action_set, frame_stack, action_repeat, REWARD_MODE)\n", "    try: venv.close(); eval_env.close()\n", "    except Exception: pass\n", "\n", "for b in range(1, num_blocks + 1):\n", "    print(f\"=== Training block {b}/{num_blocks} from {Path(resume_zip).name} | ACTION_SET={action_set} | REWARD_MODE={REWARD_MODE} ===\")\n", "    train_env = make_vector_env(num_envs, log_dir, None, action_set=action_set, frame_skip=2, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=(num_envs>1))\n", "    eval_env  = make_vector_env(1,       log_dir, None, action_set=action_set, frame_skip=2, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "    model = PPO.load(resume_zip, env=train_env, device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n", "    model.ent_coef = 0.01\n", "    eval_cb = EvalCallback(eval_env, best_model_save_path=model_dir, log_path=log_dir, eval_freq=60000, n_eval_episodes=3, deterministic=True)\n", "    learn_with_restart(model, timesteps_per_block, eval_cb, 2, f\"block-{b}\", action_set, log_dir, action_repeat, frame_stack)\n", "    ckpt = Path(model_dir) / f\"ckpt_auto_{b}.zip\"; model.save(str(ckpt)); print(\"Checkpoint saved:\", ckpt.name)\n", "    best_zip = Path(model_dir) / \"best_model.zip\"; src = best_zip if best_zip.exists() else ckpt\n", "    resume_zip = export_model_copy(src, f\"auto_best_b{b:02d}\", base_dir, run_id)\n", "    write_model_meta(resume_zip, action_set, frame_stack, action_repeat, REWARD_MODE)\n", "    try: train_env.close(); eval_env.close()\n", "    except Exception: pass\n", "\n", "print(\"Training complete.\")\n"]}, {"cell_type": "markdown", "id": "42158dcf", "metadata": {"id": "42158dcf"}, "source": ["## T) Quick test (short training)"]}, {"cell_type": "code", "execution_count": 9, "id": "fefe0483", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "fefe0483", "executionInfo": {"status": "ok", "timestamp": 1763328752810, "user_tz": -60, "elapsed": 215473, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "a332e19b-12e5-4785-f146-ebf1c2686db1"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Warmup: 3000 steps, frame_skip=4, ent=0.02, reward_mode=spec.\n", "DummyVecEnv created: 1\n", "VecDropResetKwargs active.\n", "DummyVecEnv created: 1\n", "VecDropResetKwargs active.\n", "Using cuda device\n"]}, {"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.12/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n", "  if not isinstance(terminated, (bool, np.bool8)):\n"]}, {"output_type": "stream", "name": "stdout", "text": ["---------------------------------\n", "| rollout/           |          |\n", "|    ep_len_mean     | 65.5     |\n", "|    ep_rew_mean     | 34.5     |\n", "| time/              |          |\n", "|    fps             | 35       |\n", "|    iterations      | 1        |\n", "|    time_elapsed    | 7        |\n", "|    total_timesteps | 256      |\n", "---------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 94            |\n", "|    ep_rew_mean          | 51.7          |\n", "| time/                   |               |\n", "|    fps                  | 35            |\n", "|    iterations           | 2             |\n", "|    time_elapsed         | 14            |\n", "|    total_timesteps      | 512           |\n", "| train/                  |               |\n", "|    approx_kl            | 2.1164306e-07 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.95         |\n", "|    explained_variance   | 5.92e-05      |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 63.8          |\n", "|    n_updates            | 3             |\n", "|    policy_gradient_loss | -3.73e-05     |\n", "|    value_loss           | 128           |\n", "-------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 119          |\n", "|    ep_rew_mean          | 59.6         |\n", "| time/                   |              |\n", "|    fps                  | 37           |\n", "|    iterations           | 3            |\n", "|    time_elapsed         | 20           |\n", "|    total_timesteps      | 768          |\n", "| train/                  |              |\n", "|    approx_kl            | 2.591405e-07 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.95        |\n", "|    explained_variance   | -7.82e-05    |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 49.4         |\n", "|    n_updates            | 6            |\n", "|    policy_gradient_loss | -2.02e-05    |\n", "|    value_loss           | 99.5         |\n", "------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 130           |\n", "|    ep_rew_mean          | 60.9          |\n", "| time/                   |               |\n", "|    fps                  | 38            |\n", "|    iterations           | 4             |\n", "|    time_elapsed         | 26            |\n", "|    total_timesteps      | 1024          |\n", "| train/                  |               |\n", "|    approx_kl            | 1.9324943e-07 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.95         |\n", "|    explained_variance   | 8.97e-05      |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 47.3          |\n", "|    n_updates            | 9             |\n", "|    policy_gradient_loss | 2.15e-05      |\n", "|    value_loss           | 95.5          |\n", "-------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 131          |\n", "|    ep_rew_mean          | 61.2         |\n", "| time/                   |              |\n", "|    fps                  | 38           |\n", "|    iterations           | 5            |\n", "|    time_elapsed         | 33           |\n", "|    total_timesteps      | 1280         |\n", "| train/                  |              |\n", "|    approx_kl            | 1.641456e-07 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.95        |\n", "|    explained_variance   | 2.93e-05     |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 35.7         |\n", "|    n_updates            | 12           |\n", "|    policy_gradient_loss | 1.08e-05     |\n", "|    value_loss           | 72.7         |\n", "------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 152           |\n", "|    ep_rew_mean          | 75.8          |\n", "| time/                   |               |\n", "|    fps                  | 38            |\n", "|    iterations           | 6             |\n", "|    time_elapsed         | 39            |\n", "|    total_timesteps      | 1536          |\n", "| train/                  |               |\n", "|    approx_kl            | 2.3981556e-07 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.95         |\n", "|    explained_variance   | 0.000334      |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 47            |\n", "|    n_updates            | 15            |\n", "|    policy_gradient_loss | -1.24e-05     |\n", "|    value_loss           | 96.3          |\n", "-------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 162          |\n", "|    ep_rew_mean          | 82.2         |\n", "| time/                   |              |\n", "|    fps                  | 38           |\n", "|    iterations           | 7            |\n", "|    time_elapsed         | 46           |\n", "|    total_timesteps      | 1792         |\n", "| train/                  |              |\n", "|    approx_kl            | 5.643815e-07 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.95        |\n", "|    explained_variance   | 2.09e-06     |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 69.1         |\n", "|    n_updates            | 18           |\n", "|    policy_gradient_loss | -3.04e-06    |\n", "|    value_loss           | 143          |\n", "------------------------------------------\n", "Eval num_timesteps=2000, episode_reward=1.00 +/- 0.00\n", "Episode length: 121.00 +/- 0.00\n", "-------------------------------------------\n", "| eval/                   |               |\n", "|    mean_ep_length       | 121           |\n", "|    mean_reward          | 1             |\n", "| time/                   |               |\n", "|    total_timesteps      | 2000          |\n", "| train/                  |               |\n", "|    approx_kl            | 1.7883722e-06 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.95         |\n", "|    explained_variance   | 0.000713      |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 51.6          |\n", "|    n_updates            | 21            |\n", "|    policy_gradient_loss | -8.64e-05     |\n", "|    value_loss           | 108           |\n", "-------------------------------------------\n", "New best mean reward!\n", "---------------------------------\n", "| rollout/           |          |\n", "|    ep_len_mean     | 155      |\n", "|    ep_rew_mean     | 80.1     |\n", "| time/              |          |\n", "|    fps             | 34       |\n", "|    iterations      | 8        |\n", "|    time_elapsed    | 59       |\n", "|    total_timesteps | 2048     |\n", "---------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 157           |\n", "|    ep_rew_mean          | 80.6          |\n", "| time/                   |               |\n", "|    fps                  | 35            |\n", "|    iterations           | 9             |\n", "|    time_elapsed         | 64            |\n", "|    total_timesteps      | 2304          |\n", "| train/                  |               |\n", "|    approx_kl            | 4.8526563e-06 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.95         |\n", "|    explained_variance   | -0.00126      |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 68.7          |\n", "|    n_updates            | 24            |\n", "|    policy_gradient_loss | -0.000102     |\n", "|    value_loss           | 143           |\n", "-------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 141          |\n", "|    ep_rew_mean          | 72.8         |\n", "| time/                   |              |\n", "|    fps                  | 35           |\n", "|    iterations           | 10           |\n", "|    time_elapsed         | 71           |\n", "|    total_timesteps      | 2560         |\n", "| train/                  |              |\n", "|    approx_kl            | 9.151176e-06 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.95        |\n", "|    explained_variance   | -0.000583    |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 36           |\n", "|    n_updates            | 27           |\n", "|    policy_gradient_loss | -6.31e-05    |\n", "|    value_loss           | 77.4         |\n", "------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 143          |\n", "|    ep_rew_mean          | 74.1         |\n", "| time/                   |              |\n", "|    fps                  | 36           |\n", "|    iterations           | 11           |\n", "|    time_elapsed         | 77           |\n", "|    total_timesteps      | 2816         |\n", "| train/                  |              |\n", "|    approx_kl            | 7.684343e-06 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.95        |\n", "|    explained_variance   | -0.00154     |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 45.7         |\n", "|    n_updates            | 30           |\n", "|    policy_gradient_loss | -2.1e-05     |\n", "|    value_loss           | 94.7         |\n", "------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 148           |\n", "|    ep_rew_mean          | 76            |\n", "| time/                   |               |\n", "|    fps                  | 36            |\n", "|    iterations           | 12            |\n", "|    time_elapsed         | 83            |\n", "|    total_timesteps      | 3072          |\n", "| train/                  |               |\n", "|    approx_kl            | 1.2998469e-05 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.95         |\n", "|    explained_variance   | -0.000706     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 57.9          |\n", "|    n_updates            | 33            |\n", "|    policy_gradient_loss | 2.92e-05      |\n", "|    value_loss           | 122           |\n", "-------------------------------------------\n", "Warmup checkpoint saved: ckpt_bootstrap.zip\n", "Warmup model exported: ppo_quick_20251116_212857_bootstrap.zip\n", "Model metadata written: ppo_quick_20251116_212857_bootstrap.meta.json\n", "Main quick pass: 8000 steps, frame_skip=2, ent=0.01.\n", "DummyVecEnv created: 1\n", "VecDropResetKwargs active.\n", "DummyVecEnv created: 1\n", "VecDropResetKwargs active.\n", "---------------------------------\n", "| rollout/           |          |\n", "|    ep_len_mean     | 143      |\n", "|    ep_rew_mean     | 74.1     |\n", "| time/              |          |\n", "|    fps             | 77       |\n", "|    iterations      | 1        |\n", "|    time_elapsed    | 3        |\n", "|    total_timesteps | 3328     |\n", "---------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 154           |\n", "|    ep_rew_mean          | 78.5          |\n", "| time/                   |               |\n", "|    fps                  | 76            |\n", "|    iterations           | 2             |\n", "|    time_elapsed         | 6             |\n", "|    total_timesteps      | 3584          |\n", "| train/                  |               |\n", "|    approx_kl            | 5.9486367e-05 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.95         |\n", "|    explained_variance   | -0.000106     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 85.1          |\n", "|    n_updates            | 39            |\n", "|    policy_gradient_loss | -0.00052      |\n", "|    value_loss           | 176           |\n", "-------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 149          |\n", "|    ep_rew_mean          | 76.4         |\n", "| time/                   |              |\n", "|    fps                  | 70           |\n", "|    iterations           | 3            |\n", "|    time_elapsed         | 10           |\n", "|    total_timesteps      | 3840         |\n", "| train/                  |              |\n", "|    approx_kl            | 8.922187e-05 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.95        |\n", "|    explained_variance   | -0.000235    |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 35.4         |\n", "|    n_updates            | 42           |\n", "|    policy_gradient_loss | -0.000689    |\n", "|    value_loss           | 73           |\n", "------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 149           |\n", "|    ep_rew_mean          | 76.4          |\n", "| time/                   |               |\n", "|    fps                  | 71            |\n", "|    iterations           | 4             |\n", "|    time_elapsed         | 14            |\n", "|    total_timesteps      | 4096          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00024176366 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.95         |\n", "|    explained_variance   | -0.000432     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 34.4          |\n", "|    n_updates            | 45            |\n", "|    policy_gradient_loss | -0.0013       |\n", "|    value_loss           | 69.9          |\n", "-------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 155          |\n", "|    ep_rew_mean          | 80.7         |\n", "| time/                   |              |\n", "|    fps                  | 72           |\n", "|    iterations           | 5            |\n", "|    time_elapsed         | 17           |\n", "|    total_timesteps      | 4352         |\n", "| train/                  |              |\n", "|    approx_kl            | 0.0003771328 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.94        |\n", "|    explained_variance   | -9.62e-05    |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 90.8         |\n", "|    n_updates            | 48           |\n", "|    policy_gradient_loss | -0.00106     |\n", "|    value_loss           | 185          |\n", "------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 164           |\n", "|    ep_rew_mean          | 84.3          |\n", "| time/                   |               |\n", "|    fps                  | 70            |\n", "|    iterations           | 6             |\n", "|    time_elapsed         | 21            |\n", "|    total_timesteps      | 4608          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00029313727 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.94         |\n", "|    explained_variance   | -0.00013      |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 62.3          |\n", "|    n_updates            | 51            |\n", "|    policy_gradient_loss | -0.000432     |\n", "|    value_loss           | 126           |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 168           |\n", "|    ep_rew_mean          | 87.8          |\n", "| time/                   |               |\n", "|    fps                  | 70            |\n", "|    iterations           | 7             |\n", "|    time_elapsed         | 25            |\n", "|    total_timesteps      | 4864          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00015170756 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.94         |\n", "|    explained_variance   | -4.77e-07     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 41.6          |\n", "|    n_updates            | 54            |\n", "|    policy_gradient_loss | -0.000636     |\n", "|    value_loss           | 84.6          |\n", "-------------------------------------------\n", "Eval num_timesteps=5072, episode_reward=33.00 +/- 0.00\n", "Episode length: 48.00 +/- 0.00\n", "-------------------------------------------\n", "| eval/                   |               |\n", "|    mean_ep_length       | 48            |\n", "|    mean_reward          | 33            |\n", "| time/                   |               |\n", "|    total_timesteps      | 5072          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00022553047 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.94         |\n", "|    explained_variance   | 3.3e-05       |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 59.2          |\n", "|    n_updates            | 57            |\n", "|    policy_gradient_loss | 4.71e-05      |\n", "|    value_loss           | 120           |\n", "-------------------------------------------\n", "New best mean reward!\n", "---------------------------------\n", "| rollout/           |          |\n", "|    ep_len_mean     | 172      |\n", "|    ep_rew_mean     | 89.9     |\n", "| time/              |          |\n", "|    fps             | 67       |\n", "|    iterations      | 8        |\n", "|    time_elapsed    | 30       |\n", "|    total_timesteps | 5120     |\n", "---------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 168           |\n", "|    ep_rew_mean          | 88            |\n", "| time/                   |               |\n", "|    fps                  | 66            |\n", "|    iterations           | 9             |\n", "|    time_elapsed         | 34            |\n", "|    total_timesteps      | 5376          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00011875923 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.94         |\n", "|    explained_variance   | 4.86e-05      |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 53.6          |\n", "|    n_updates            | 60            |\n", "|    policy_gradient_loss | -0.000324     |\n", "|    value_loss           | 108           |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 172           |\n", "|    ep_rew_mean          | 90.2          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 10            |\n", "|    time_elapsed         | 37            |\n", "|    total_timesteps      | 5632          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00012093014 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.93         |\n", "|    explained_variance   | -5.96e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 80.1          |\n", "|    n_updates            | 63            |\n", "|    policy_gradient_loss | -0.000225     |\n", "|    value_loss           | 162           |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 174           |\n", "|    ep_rew_mean          | 89.8          |\n", "| time/                   |               |\n", "|    fps                  | 68            |\n", "|    iterations           | 11            |\n", "|    time_elapsed         | 41            |\n", "|    total_timesteps      | 5888          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00010433467 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.93         |\n", "|    explained_variance   | -9.54e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 50.9          |\n", "|    n_updates            | 66            |\n", "|    policy_gradient_loss | 0.000105      |\n", "|    value_loss           | 103           |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 177           |\n", "|    ep_rew_mean          | 91.2          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 12            |\n", "|    time_elapsed         | 45            |\n", "|    total_timesteps      | 6144          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00010553817 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.93         |\n", "|    explained_variance   | -2.38e-05     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 29.5          |\n", "|    n_updates            | 69            |\n", "|    policy_gradient_loss | -0.000257     |\n", "|    value_loss           | 59.4          |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 177           |\n", "|    ep_rew_mean          | 91.2          |\n", "| time/                   |               |\n", "|    fps                  | 68            |\n", "|    iterations           | 13            |\n", "|    time_elapsed         | 48            |\n", "|    total_timesteps      | 6400          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00021646428 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.93         |\n", "|    explained_variance   | -2.62e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 36.2          |\n", "|    n_updates            | 72            |\n", "|    policy_gradient_loss | -0.000828     |\n", "|    value_loss           | 73.3          |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 174           |\n", "|    ep_rew_mean          | 90.3          |\n", "| time/                   |               |\n", "|    fps                  | 68            |\n", "|    iterations           | 14            |\n", "|    time_elapsed         | 52            |\n", "|    total_timesteps      | 6656          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00020095403 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.93         |\n", "|    explained_variance   | -1.35e-05     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 61.9          |\n", "|    n_updates            | 75            |\n", "|    policy_gradient_loss | 3.16e-05      |\n", "|    value_loss           | 125           |\n", "-------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 169          |\n", "|    ep_rew_mean          | 88.8         |\n", "| time/                   |              |\n", "|    fps                  | 69           |\n", "|    iterations           | 15           |\n", "|    time_elapsed         | 55           |\n", "|    total_timesteps      | 6912         |\n", "| train/                  |              |\n", "|    approx_kl            | 0.0001342753 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.93        |\n", "|    explained_variance   | -7.39e-06    |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 86.2         |\n", "|    n_updates            | 78           |\n", "|    policy_gradient_loss | -0.000459    |\n", "|    value_loss           | 173          |\n", "------------------------------------------\n", "Eval num_timesteps=7072, episode_reward=33.00 +/- 0.00\n", "Episode length: 48.00 +/- 0.00\n", "-------------------------------------------\n", "| eval/                   |               |\n", "|    mean_ep_length       | 48            |\n", "|    mean_reward          | 33            |\n", "| time/                   |               |\n", "|    total_timesteps      | 7072          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00037881383 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.93         |\n", "|    explained_variance   | -1.67e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 77.4          |\n", "|    n_updates            | 81            |\n", "|    policy_gradient_loss | -0.00142      |\n", "|    value_loss           | 155           |\n", "-------------------------------------------\n", "---------------------------------\n", "| rollout/           |          |\n", "|    ep_len_mean     | 166      |\n", "|    ep_rew_mean     | 87.3     |\n", "| time/              |          |\n", "|    fps             | 66       |\n", "|    iterations      | 16       |\n", "|    time_elapsed    | 61       |\n", "|    total_timesteps | 7168     |\n", "---------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 169          |\n", "|    ep_rew_mean          | 88.6         |\n", "| time/                   |              |\n", "|    fps                  | 67           |\n", "|    iterations           | 17           |\n", "|    time_elapsed         | 64           |\n", "|    total_timesteps      | 7424         |\n", "| train/                  |              |\n", "|    approx_kl            | 0.0005836042 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.93        |\n", "|    explained_variance   | -3.58e-07    |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 70.4         |\n", "|    n_updates            | 84           |\n", "|    policy_gradient_loss | -0.00168     |\n", "|    value_loss           | 142          |\n", "------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 171          |\n", "|    ep_rew_mean          | 89.4         |\n", "| time/                   |              |\n", "|    fps                  | 67           |\n", "|    iterations           | 18           |\n", "|    time_elapsed         | 68           |\n", "|    total_timesteps      | 7680         |\n", "| train/                  |              |\n", "|    approx_kl            | 0.0003951611 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.92        |\n", "|    explained_variance   | 5.36e-07     |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 57.4         |\n", "|    n_updates            | 87           |\n", "|    policy_gradient_loss | 0.000133     |\n", "|    value_loss           | 116          |\n", "------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 171           |\n", "|    ep_rew_mean          | 89.4          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 19            |\n", "|    time_elapsed         | 72            |\n", "|    total_timesteps      | 7936          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00020250166 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.92         |\n", "|    explained_variance   | -5.96e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 53.2          |\n", "|    n_updates            | 90            |\n", "|    policy_gradient_loss | -0.00024      |\n", "|    value_loss           | 107           |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 175           |\n", "|    ep_rew_mean          | 90.4          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 20            |\n", "|    time_elapsed         | 75            |\n", "|    total_timesteps      | 8192          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00032967422 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.92         |\n", "|    explained_variance   | -1.91e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 29.6          |\n", "|    n_updates            | 93            |\n", "|    policy_gradient_loss | -0.000916     |\n", "|    value_loss           | 59.9          |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 176           |\n", "|    ep_rew_mean          | 91.5          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 21            |\n", "|    time_elapsed         | 79            |\n", "|    total_timesteps      | 8448          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00028362288 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.92         |\n", "|    explained_variance   | -3.46e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 86            |\n", "|    n_updates            | 96            |\n", "|    policy_gradient_loss | 0.000213      |\n", "|    value_loss           | 173           |\n", "-------------------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 179          |\n", "|    ep_rew_mean          | 92.5         |\n", "| time/                   |              |\n", "|    fps                  | 67           |\n", "|    iterations           | 22           |\n", "|    time_elapsed         | 83           |\n", "|    total_timesteps      | 8704         |\n", "| train/                  |              |\n", "|    approx_kl            | 5.542976e-05 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.92        |\n", "|    explained_variance   | -8.34e-07    |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 68.2         |\n", "|    n_updates            | 99           |\n", "|    policy_gradient_loss | 0.000263     |\n", "|    value_loss           | 137          |\n", "------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 182           |\n", "|    ep_rew_mean          | 93.6          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 23            |\n", "|    time_elapsed         | 86            |\n", "|    total_timesteps      | 8960          |\n", "| train/                  |               |\n", "|    approx_kl            | 6.0458202e-05 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.92         |\n", "|    explained_variance   | -2.98e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 55.5          |\n", "|    n_updates            | 102           |\n", "|    policy_gradient_loss | -0.000159     |\n", "|    value_loss           | 112           |\n", "-------------------------------------------\n", "Eval num_timesteps=9072, episode_reward=33.00 +/- 0.00\n", "Episode length: 48.00 +/- 0.00\n", "------------------------------------------\n", "| eval/                   |              |\n", "|    mean_ep_length       | 48           |\n", "|    mean_reward          | 33           |\n", "| time/                   |              |\n", "|    total_timesteps      | 9072         |\n", "| train/                  |              |\n", "|    approx_kl            | 7.932703e-05 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.92        |\n", "|    explained_variance   | -1.2e-05     |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 41.3         |\n", "|    n_updates            | 105          |\n", "|    policy_gradient_loss | -0.000471    |\n", "|    value_loss           | 83.3         |\n", "------------------------------------------\n", "---------------------------------\n", "| rollout/           |          |\n", "|    ep_len_mean     | 182      |\n", "|    ep_rew_mean     | 94.3     |\n", "| time/              |          |\n", "|    fps             | 66       |\n", "|    iterations      | 24       |\n", "|    time_elapsed    | 91       |\n", "|    total_timesteps | 9216     |\n", "---------------------------------\n", "------------------------------------------\n", "| rollout/                |              |\n", "|    ep_len_mean          | 186          |\n", "|    ep_rew_mean          | 95.7         |\n", "| time/                   |              |\n", "|    fps                  | 66           |\n", "|    iterations           | 25           |\n", "|    time_elapsed         | 96           |\n", "|    total_timesteps      | 9472         |\n", "| train/                  |              |\n", "|    approx_kl            | 0.0002490126 |\n", "|    clip_fraction        | 0            |\n", "|    clip_range           | 0.2          |\n", "|    entropy_loss         | -1.92        |\n", "|    explained_variance   | -3.81e-06    |\n", "|    learning_rate        | 0.0003       |\n", "|    loss                 | 79.1         |\n", "|    n_updates            | 108          |\n", "|    policy_gradient_loss | -0.00183     |\n", "|    value_loss           | 159          |\n", "------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 184           |\n", "|    ep_rew_mean          | 94.7          |\n", "| time/                   |               |\n", "|    fps                  | 66            |\n", "|    iterations           | 26            |\n", "|    time_elapsed         | 99            |\n", "|    total_timesteps      | 9728          |\n", "| train/                  |               |\n", "|    approx_kl            | 6.4688036e-05 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.92         |\n", "|    explained_variance   | 5.3e-06       |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 15.2          |\n", "|    n_updates            | 111           |\n", "|    policy_gradient_loss | 0.000317      |\n", "|    value_loss           | 30.8          |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 184           |\n", "|    ep_rew_mean          | 94.7          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 27            |\n", "|    time_elapsed         | 102           |\n", "|    total_timesteps      | 9984          |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00013170717 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.91         |\n", "|    explained_variance   | -1.19e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 80.6          |\n", "|    n_updates            | 114           |\n", "|    policy_gradient_loss | -0.000568     |\n", "|    value_loss           | 162           |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 186           |\n", "|    ep_rew_mean          | 95.4          |\n", "| time/                   |               |\n", "|    fps                  | 66            |\n", "|    iterations           | 28            |\n", "|    time_elapsed         | 107           |\n", "|    total_timesteps      | 10240         |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00015088613 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.91         |\n", "|    explained_variance   | -2.15e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 66.6          |\n", "|    n_updates            | 117           |\n", "|    policy_gradient_loss | -0.000482     |\n", "|    value_loss           | 134           |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 184           |\n", "|    ep_rew_mean          | 95.3          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 29            |\n", "|    time_elapsed         | 110           |\n", "|    total_timesteps      | 10496         |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00016321847 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.91         |\n", "|    explained_variance   | -8.34e-07     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 55.2          |\n", "|    n_updates            | 120           |\n", "|    policy_gradient_loss | -0.000584     |\n", "|    value_loss           | 111           |\n", "-------------------------------------------\n", "-------------------------------------------\n", "| rollout/                |               |\n", "|    ep_len_mean          | 187           |\n", "|    ep_rew_mean          | 96.5          |\n", "| time/                   |               |\n", "|    fps                  | 67            |\n", "|    iterations           | 30            |\n", "|    time_elapsed         | 113           |\n", "|    total_timesteps      | 10752         |\n", "| train/                  |               |\n", "|    approx_kl            | 0.00017856201 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.91         |\n", "|    explained_variance   | -4.53e-06     |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 76.7          |\n", "|    n_updates            | 123           |\n", "|    policy_gradient_loss | -0.000541     |\n", "|    value_loss           | 154           |\n", "-------------------------------------------\n", "-----------------------------------------\n", "| rollout/                |             |\n", "|    ep_len_mean          | 188         |\n", "|    ep_rew_mean          | 97.1        |\n", "| time/                   |             |\n", "|    fps                  | 67          |\n", "|    iterations           | 31          |\n", "|    time_elapsed         | 117         |\n", "|    total_timesteps      | 11008       |\n", "| train/                  |             |\n", "|    approx_kl            | 0.000151305 |\n", "|    clip_fraction        | 0           |\n", "|    clip_range           | 0.2         |\n", "|    entropy_loss         | -1.91       |\n", "|    explained_variance   | 3.58e-07    |\n", "|    learning_rate        | 0.0003      |\n", "|    loss                 | 66.8        |\n", "|    n_updates            | 126         |\n", "|    policy_gradient_loss | -1.38e-05   |\n", "|    value_loss           | 135         |\n", "-----------------------------------------\n", "Eval num_timesteps=11072, episode_reward=33.00 +/- 0.00\n", "Episode length: 48.00 +/- 0.00\n", "-------------------------------------------\n", "| eval/                   |               |\n", "|    mean_ep_length       | 48            |\n", "|    mean_reward          | 33            |\n", "| time/                   |               |\n", "|    total_timesteps      | 11072         |\n", "| train/                  |               |\n", "|    approx_kl            | 8.4722415e-05 |\n", "|    clip_fraction        | 0             |\n", "|    clip_range           | 0.2           |\n", "|    entropy_loss         | -1.91         |\n", "|    explained_variance   | 9.54e-07      |\n", "|    learning_rate        | 0.0003        |\n", "|    loss                 | 63.2          |\n", "|    n_updates            | 129           |\n", "|    policy_gradient_loss | -2.29e-05     |\n", "|    value_loss           | 127           |\n", "-------------------------------------------\n", "---------------------------------\n", "| rollout/           |          |\n", "|    ep_len_mean     | 187      |\n", "|    ep_rew_mean     | 96.5     |\n", "| time/              |          |\n", "|    fps             | 66       |\n", "|    iterations      | 32       |\n", "|    time_elapsed    | 123      |\n", "|    total_timesteps | 11264    |\n", "---------------------------------\n", "Quick-pass checkpoint saved: best_model.zip\n", "Quick-pass best exported: ppo_quick_20251116_212857_quick_best.zip\n", "Quick test complete.\n"]}], "source": ["\n", "from pathlib import Path\n", "from datetime import datetime\n", "from shutil import copy2\n", "import os, json, numpy as np, random, warnings, torch\n", "from stable_baselines3 import PPO\n", "from stable_baselines3.common.callbacks import EvalCallback\n", "warnings.filterwarnings(\"ignore\", category=UserWarning, message=r\".*env\\.spec.*deprecated.*\")\n", "\n", "TEST = dict(action_set='SIMPLE_MOVEMENT', num_envs=1, frame_stack=2, action_repeat=2,\n", "            frame_skip=4, warmup_timesteps=3000, num_blocks=1, timesteps_per_block=8000,\n", "            warmup_ent=0.02, main_ent=0.01, eval_freq=2000)\n", "\n", "frame_stack   = int(TEST.get('frame_stack',2))\n", "action_repeat = int(TEST.get('action_repeat',2))\n", "frame_skip    = int(TEST.get('frame_skip',4))\n", "EVALF         = int(TEST.get('eval_freq',2000))\n", "SEED=42; random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n", "\n", "run_id  = datetime.now().strftime(\"ppo_quick_%Y%m%d_%H%M%S\")\n", "log_dir   = f\"{base_dir}/logs/{run_id}\"\n", "model_dir = f\"{base_dir}/models/{run_id}\"\n", "for d in (log_dir, model_dir): Path(d).mkdir(parents=True, exist_ok=True)\n", "Path(f\"{base_dir}/models/exports\").mkdir(parents=True, exist_ok=True)\n", "\n", "def write_model_meta(zip_path, action_set, frame_stack, action_repeat, reward_mode):\n", "    mp = Path(zip_path).with_suffix(\".meta.json\")\n", "    mp.write_text(json.dumps(dict(action_set=action_set,\n", "                                  frame_stack=int(frame_stack),\n", "                                  action_repeat=int(action_repeat),\n", "                                  reward_mode=str(reward_mode)), indent=2), encoding=\"utf-8\")\n", "    print(\"Model metadata written:\", mp.name)\n", "\n", "def make_training_bundle(frame_skip_used, ent_coef, eval_freq, action_set_used):\n", "    venv     = make_vector_env(1, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "    eval_env = make_vector_env(1, log_dir, None, action_set=action_set_used, frame_skip=frame_skip_used, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "    policy_kwargs = dict(features_extractor_class=SmallCNNFeatures, features_extractor_kwargs=dict(features_dim=128), net_arch=[128,128])\n", "    model = PPO('CnnPolicy', venv, policy_kwargs=policy_kwargs, n_steps=256, batch_size=256, n_epochs=3,\n", "                learning_rate=3e-4, gamma=0.999, gae_lambda=0.95, clip_range=0.2, ent_coef=ent_coef, vf_coef=0.5,\n", "                device=('cuda' if torch.cuda.is_available() else 'cpu'), verbose=1, seed=SEED)\n", "    eval_cb = EvalCallback(eval_env, best_model_save_path=model_dir, log_path=log_dir, eval_freq=eval_freq, n_eval_episodes=2, deterministic=True)\n", "    return model, venv, eval_env, eval_cb\n", "\n", "print(f\"Warmup: {TEST['warmup_timesteps']} steps, frame_skip={frame_skip}, ent={TEST['warmup_ent']}, reward_mode={REWARD_MODE}.\")\n", "model, venv, eval_env, eval_cb = make_training_bundle(frame_skip, TEST['warmup_ent'], EVALF, TEST['action_set'])\n", "model.learn(total_timesteps=TEST['warmup_timesteps'], reset_num_timesteps=False, callback=eval_cb)\n", "ckpt = Path(model_dir)/'ckpt_bootstrap.zip'; model.save(str(ckpt)); print('Warmup checkpoint saved:', ckpt.name)\n", "dst = (Path(base_dir)/'models'/'exports'/f\"{run_id}_bootstrap.zip\"); copy2(ckpt, dst); print(\"Warmup model exported:\", dst.name)\n", "write_model_meta(str(dst), TEST['action_set'], frame_stack, action_repeat, REWARD_MODE)\n", "try: venv.close(); eval_env.close()\n", "except: pass\n", "\n", "print(f\"Main quick pass: {TEST['timesteps_per_block']} steps, frame_skip=2, ent={TEST['main_ent']}.\")\n", "train_env = make_vector_env(1, log_dir, None, action_set=TEST['action_set'], frame_skip=2, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "eval_env  = make_vector_env(1, log_dir, None, action_set=TEST['action_set'], frame_skip=2, action_repeat=action_repeat, frame_stack=frame_stack, prefer_subproc=False)\n", "model = PPO.load(str(dst), env=train_env, device=('cuda' if torch.cuda.is_available() else 'cpu')); model.ent_coef = TEST['main_ent']\n", "eval_cb = EvalCallback(eval_env, best_model_save_path=model_dir, log_path=log_dir, eval_freq=EVALF, n_eval_episodes=3, deterministic=True)\n", "model.learn(total_timesteps=TEST['timesteps_per_block'], reset_num_timesteps=False, callback=eval_cb)\n", "best_zip = Path(model_dir)/'best_model.zip'\n", "src = best_zip if best_zip.exists() else (Path(model_dir)/'ckpt_quick.zip'); model.save(str(src)); print('Quick-pass checkpoint saved:', src.name)\n", "dst2 = (Path(base_dir)/'models'/'exports'/f\"{run_id}_quick_best.zip\"); copy2(src, dst2); print(\"Quick-pass best exported:\", dst2.name)\n", "(Path(str(dst2))).with_suffix(\".meta.json\").write_text(json.dumps(dict(action_set=TEST['action_set'], frame_stack=frame_stack, action_repeat=action_repeat, reward_mode=REWARD_MODE), indent=2), encoding='utf-8')\n", "print('Quick test complete.')\n"]}, {"cell_type": "markdown", "id": "5ecc3dda", "metadata": {"id": "5ecc3dda"}, "source": ["## E) Learning analysis (reward curve)"]}, {"cell_type": "code", "execution_count": 10, "id": "75e0eeef", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 442}, "id": "75e0eeef", "executionInfo": {"status": "ok", "timestamp": 1763328759234, "user_tz": -60, "elapsed": 499, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "8c29501c-9471-47d6-8771-3047dca48077"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Selected log directory: /content/mario_rl_local/logs/ppo_quick_20251116_212857\n"]}, {"output_type": "display_data", "data": {"text/plain": ["<Figure size 800x400 with 1 Axes>"], "image/png": "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\n"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["Episode count: 40\n", "Mean reward over the last 20 episodes: 108.9\n", "Total timesteps from logs (sum of l): 5961\n"]}], "source": ["\n", "from pathlib import Path\n", "import pandas as pd, matplotlib.pyplot as plt\n", "\n", "def find_latest_log_dir(base_logs):\n", "    mfiles = sorted(Path(base_logs).glob('**/*.monitor.csv'), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    return mfiles[0].parent if mfiles else None\n", "\n", "_ld = find_latest_log_dir(f\"{base_dir}/logs\"); assert _ld, 'No log directory was found.'\n", "log_dir = str(_ld); print('Selected log directory:', log_dir)\n", "files = sorted(Path(log_dir).glob('**/*.monitor.csv'))\n", "df = pd.concat([pd.read_csv(f, comment='#') for f in files], ignore_index=True).reset_index(drop=True)\n", "df['episode'] = range(1, len(df)+1); df['ema20'] = df['r'].ewm(span=20).mean()\n", "plt.figure(figsize=(8,4)); plt.plot(df['episode'], df['r'], alpha=0.3, label='reward'); plt.plot(df['episode'], df['ema20'], label='EMA20')\n", "plt.legend(); plt.title('Reward per episode'); plt.grid(True); plt.tight_layout(); plt.show()\n", "print('Episode count:', len(df))\n", "print('Mean reward over the last 20 episodes:', float(df['r'].tail(20).mean()))\n", "print('Total timesteps from logs (sum of l):', int(df['l'].sum()))\n"]}, {"cell_type": "markdown", "id": "11eca9fa", "metadata": {"id": "11eca9fa"}, "source": ["## F1) Video: trained model (60 s)"]}, {"cell_type": "code", "execution_count": null, "id": "d7cc337e", "metadata": {"id": "d7cc337e"}, "outputs": [], "source": ["\n", "from stable_baselines3.common.vec_env import VecVideoRecorder\n", "from stable_baselines3 import PPO\n", "from pathlib import Path\n", "import json, torch\n", "\n", "def find_latest_export_zip(base_dir_str):\n", "    ex = sorted((Path(base_dir_str)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    return str(ex[0]) if ex else None\n", "\n", "def model_meta_path(zip_path):\n", "    return Path(zip_path).with_suffix('.meta.json')\n", "\n", "def infer_action_set_from_model(zip_path):\n", "    mp = model_meta_path(zip_path)\n", "    if mp.exists():\n", "        try:\n", "            m = json.loads(mp.read_text())\n", "            if m.get('action_set') in ('RIGHT_ONLY','SIMPLE_MOVEMENT'):\n", "                print('Action set (metadata):', m['action_set'])\n", "                return m['action_set']\n", "        except Exception:\n", "            pass\n", "    tmp = PPO.load(zip_path, device='cpu')\n", "    n_act = tmp.action_space.n\n", "    return 'RIGHT_ONLY' if n_act == 5 else 'SIMPLE_MOVEMENT'\n", "\n", "model_zip = find_latest_export_zip(base_dir); assert model_zip, 'No exported model was found.'\n", "action_set_play  = infer_action_set_from_model(model_zip)\n", "frame_stack_play = int(globals().get('frame_stack',2))\n", "action_repeat_play = int(globals().get('action_repeat',2))\n", "\n", "play_env = make_vector_env(1, f\"{base_dir}/logs/_play\", render_mode='rgb_array',\n", "                           action_set=action_set_play, frame_skip=2, action_repeat=action_repeat_play, frame_stack=frame_stack_play, prefer_subproc=False)\n", "try:\n", "    RENDER_FPS = play_env.get_attr('metadata')[0].get('render_fps',30)\n", "except Exception:\n", "    RENDER_FPS = 30\n", "\n", "VIDEO_SECONDS=60; VIDEO_STEPS=int(RENDER_FPS*VIDEO_SECONDS)\n", "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n", "model = PPO.load(model_zip, env=play_env, device=device)\n", "\n", "p=Path(model_zip)\n", "VIDEO_DIR=p.parent.as_posix().replace('/models/','/videos/') if '/models/' in p.as_posix() else f'{base_dir}/videos'\n", "Path(VIDEO_DIR).mkdir(parents=True, exist_ok=True)\n", "\n", "video_env = VecVideoRecorder(play_env, VIDEO_DIR, record_video_trigger=lambda step: step==0, video_length=VIDEO_STEPS, name_prefix=f'play_{p.stem}')\n", "obs = video_env.reset(); steps=0\n", "while steps<VIDEO_STEPS:\n", "    a,_=model.predict(obs, deterministic=True); obs,_,done,_=video_env.step(a); steps+=1\n", "    if done.any(): obs=video_env.reset()\n", "try: video_env.close()\n", "except Exception as e: print('Info: video_env.close raised:', e)\n", "try: play_env.close()\n", "except Exception: pass\n", "print('Trained-model video saved in:', VIDEO_DIR)\n"]}, {"cell_type": "markdown", "id": "af497394", "metadata": {"id": "af497394"}, "source": ["## F2) Video: random agent (15 s)"]}, {"cell_type": "code", "execution_count": 19, "id": "4d236207", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4d236207", "executionInfo": {"status": "ok", "timestamp": 1763328932705, "user_tz": -60, "elapsed": 11236, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "80ac76c9-af24-46b3-dcf2-9397678b68ca"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Action set (metadata): SIMPLE_MOVEMENT\n", "DummyVecEnv created: 1\n", "VecDropResetKwargs active.\n", "Saving video to /content/mario_rl_local/videos/_random/random_simple_movement-step-0-to-step-450.mp4\n", "MoviePy - Building video /content/mario_rl_local/videos/_random/random_simple_movement-step-0-to-step-450.mp4.\n", "MoviePy - Writing video /content/mario_rl_local/videos/_random/random_simple_movement-step-0-to-step-450.mp4\n", "\n"]}, {"output_type": "stream", "name": "stderr", "text": []}, {"output_type": "stream", "name": "stdout", "text": ["MoviePy - Done !\n", "MoviePy - video ready /content/mario_rl_local/videos/_random/random_simple_movement-step-0-to-step-450.mp4\n", "Random-agent video saved in: /content/mario_rl_local/videos/_random\n"]}], "source": ["\n", "from stable_baselines3.common.vec_env import VecVideoRecorder\n", "from pathlib import Path\n", "import numpy as np, json\n", "\n", "def find_latest_export_zip(base_dir_str):\n", "    ex = sorted((Path(base_dir_str)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    return str(ex[0]) if ex else None\n", "\n", "def infer_action_set_from_latest(base_dir_str, default='SIMPLE_MOVEMENT'):\n", "    z = find_latest_export_zip(base_dir_str)\n", "    if not z:\n", "        print(\"No model found. Using default ACTION_SET:\", default)\n", "        return default\n", "    mp = Path(z).with_suffix('.meta.json')\n", "    if mp.exists():\n", "        try:\n", "            m = json.loads(mp.read_text())\n", "            if m.get('action_set') in ('RIGHT_ONLY','SIMPLE_MOVEMENT'):\n", "                print('Action set (metadata):', m['action_set'])\n", "                return m['action_set']\n", "        except Exception: pass\n", "    print(\"Metadata not readable. Using default ACTION_SET:\", default)\n", "    return default\n", "\n", "action_set_rand  = infer_action_set_from_latest(base_dir, default='SIMPLE_MOVEMENT')\n", "frame_stack_play = int(globals().get('frame_stack',2))\n", "action_repeat_play = int(globals().get('action_repeat',2))\n", "\n", "play_env = make_vector_env(1, f\"{base_dir}/logs/_random\", render_mode='rgb_array',\n", "                           action_set=action_set_rand, frame_skip=4, action_repeat=action_repeat_play, frame_stack=frame_stack_play, prefer_subproc=False)\n", "try:\n", "    RENDER_FPS = play_env.get_attr('metadata')[0].get('render_fps',30)\n", "except Exception:\n", "    RENDER_FPS = 30\n", "\n", "VIDEO_SECONDS=15; VIDEO_STEPS=int(RENDER_FPS*VIDEO_SECONDS)\n", "VIDEO_DIR=f\"{base_dir}/videos/_random\"; Path(VIDEO_DIR).mkdir(parents=True, exist_ok=True)\n", "\n", "video_env = VecVideoRecorder(play_env, VIDEO_DIR, record_video_trigger=lambda step: step == 0, video_length=VIDEO_STEPS, name_prefix=f'random_{action_set_rand.lower()}')\n", "\n", "obs = video_env.reset(); steps=0\n", "while steps<VIDEO_STEPS:\n", "    a = np.array([play_env.action_space.sample()], dtype=np.int64)\n", "    obs,_,done,_=video_env.step(a); steps+=1\n", "    if done.any(): obs=video_env.reset()\n", "try: video_env.close()\n", "except Exception as e: print('Info: video_env.close raised:', e)\n", "try: play_env.close()\n", "except Exception: pass\n", "print('Random-agent video saved in:', VIDEO_DIR)\n"]}, {"cell_type": "markdown", "id": "0f4c00b8", "metadata": {"id": "0f4c00b8"}, "source": ["## G) Report generator (1\u20132 pages, covers all required points)"]}, {"cell_type": "code", "execution_count": 21, "id": "f9ca5942", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "f9ca5942", "executionInfo": {"status": "ok", "timestamp": 1763329144900, "user_tz": -60, "elapsed": 24, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "1769a231-7daf-4815-a55a-9abc94cf7d8d"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Report saved:\n", " - /content/mario_rl_local/reports/report_local.md\n", " - /content/mario_rl_local/reports/report_local.html\n"]}], "source": ["\n", "from pathlib import Path\n", "import pandas as pd, datetime as dt, markdown as mdlib, json\n", "\n", "def find_latest_log_dir(base_logs):\n", "    mfiles = sorted(Path(base_logs).glob('**/*.monitor.csv'), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    return mfiles[0].parent if mfiles else None\n", "\n", "LOGP = find_latest_log_dir(f\"{base_dir}/logs\"); assert LOGP, \"No log directory was found.\"\n", "files = sorted(Path(LOGP).glob('**/*.monitor.csv'))\n", "df = pd.concat([pd.read_csv(f, comment='#') for f in files], ignore_index=True).reset_index(drop=True)\n", "\n", "episodes = int(len(df))\n", "timesteps = int(df['l'].sum()) if 'l' in df else 0\n", "mean_last20 = float(df['r'].tail(20).mean()) if episodes > 0 else 0.0\n", "best_reward = float(df['r'].max()) if episodes > 0 else 0.0\n", "\n", "ts = dt.datetime.now().strftime('%Y-%m-%d %H:%M')\n", "\n", "cfg = {\n", "    \"action_set\": globals().get(\"action_set\", \"SIMPLE_MOVEMENT\"),\n", "    \"frame_stack\": int(globals().get(\"frame_stack\", 2)),\n", "    \"action_repeat\": int(globals().get(\"action_repeat\", 2)),\n", "    \"reward_mode\": str(globals().get(\"REWARD_MODE\", \"spec\"))\n", "}\n", "\n", "report_md = f\"\"\"# Short Report \u2014 Mario PPO (Local Training Suite)\n", "\n", "**Author:** Sara Persson\n", "**Date:** {ts}\n", "\n", "## Data preparation\n", "Observations are derived directly from the environment (no static dataset). Each frame is converted to **84x84 grayscale** and we apply **frame stacking** (stack={cfg['frame_stack']}) to expose short-term temporal context.\n", "We also use **frame skip** and **action repeat** (repeat={cfg['action_repeat']}) to reduce computational load and improve sample efficiency.\n", "Reward mode is **{cfg['reward_mode']}**:\n", "- **spec (default):** +1 only when forward progress occurs within a step, and -15 on death; 0 otherwise.\n", "- **shaped (optional):** adds dense progress shaping and small step penalties.\n", "\n", "## Model choice and motivation\n", "We use **PPO (Proximal Policy Optimization)** from Stable-Baselines3 with a compact CNN feature extractor.\n", "PPO is chosen because it is:\n", "- **Stable and robust** for on-policy training in discrete-control environments like NES Mario.\n", "- **Well-supported** with reliable implementations, monitoring, and callbacks.\n", "- **Sample-efficient enough** for short Colab runs while still converging with modest tuning.\n", "\n", "## Performance and evaluation\n", "- **Episodes:** {episodes}\n", "- **Total timesteps (from logs):** {timesteps}\n", "- **Mean reward (last 20 episodes):** {mean_last20:.2f}\n", "- **Best single-episode reward:** {best_reward:.2f}\n", "\n", "We additionally provide two evaluation utilities:\n", "- **J:** aggregate rewards over N episodes.\n", "- **J2:** reports both reward and maximum `x_pos` (how far Mario progressed).\n", "\n", "## Improvement suggestions\n", "If performance is below target, we suggest:\n", "1. **Longer training** (increase warmup and block timesteps) and ensure GPU runtime.\n", "2. **Curriculum**: start with `RIGHT_ONLY`, then switch to `SIMPLE_MOVEMENT` once forward progress is consistent.\n", "3. **Entropy schedule**: higher entropy early, then lower (0.02 -> 0.005) to solidify behaviors.\n", "4. **Reward mode swap**: try `shaped` to speed early learning, then revert to `spec` for alignment with project spec.\n", "5. **Model capacity**: modestly larger CNN (e.g., +64 filters) if learning plateaus.\n", "6. **Frame skip/repeat**: tune (e.g., skip 2\u20134, repeat 2) to balance fidelity and speed.\n", "\n", "## Reproducibility and artifacts\n", "- Notebook: **Mario_RL_PPO_Local_TrainingSuite.ipynb**\n", "- Logs and monitor CSVs under `/content/mario_rl_local/logs`\n", "- Exported models under `/content/mario_rl_local/models/exports`\n", "- Videos under `/content/mario_rl_local/videos`\n", "\"\"\"\n", "\n", "reports_dir = Path(base_dir) / \"reports\"\n", "reports_dir.mkdir(parents=True, exist_ok=True)\n", "md_path = reports_dir / \"report_local.md\"\n", "html_path = reports_dir / \"report_local.html\"\n", "\n", "md_path.write_text(report_md, encoding='utf-8')\n", "html_path.write_text(mdlib.markdown(report_md, extensions=['tables']), encoding='utf-8')\n", "\n", "print(\"Report saved:\")\n", "print(\" -\", md_path)\n", "print(\" -\", html_path)\n"]}, {"cell_type": "markdown", "id": "11d48298", "metadata": {"id": "11d48298"}, "source": ["## H) Export and import helpers"]}, {"cell_type": "code", "execution_count": null, "id": "dbd0257b", "metadata": {"id": "dbd0257b"}, "outputs": [], "source": ["\n", "from pathlib import Path\n", "import json\n", "\n", "def list_exports(base=base_dir, n=10):\n", "    ex = sorted((Path(base)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)[:n]\n", "    for p in ex: print(p.name)\n", "\n", "def set_resume_from(path):\n", "    global RESUME_FROM\n", "    RESUME_FROM = str(Path(path))\n", "    print('RESUME_FROM =', RESUME_FROM)\n", "\n", "def write_model_meta(zip_path, action_set='SIMPLE_MOVEMENT', frame_stack=2, action_repeat=2, reward_mode='spec'):\n", "    mp = Path(zip_path).with_suffix('.meta.json')\n", "    mp.write_text(json.dumps(dict(action_set=action_set, frame_stack=int(frame_stack), action_repeat=int(action_repeat), reward_mode=str(reward_mode)), indent=2), encoding='utf-8')\n", "    print('Model metadata written:', mp.name)\n", "\n", "print('Helpers: list_exports(), set_resume_from(path), write_model_meta(zip, ...)')\n"]}, {"cell_type": "markdown", "id": "d06a11cb", "metadata": {"id": "d06a11cb"}, "source": ["## S-STATUS) Status overview (local artifacts)"]}, {"cell_type": "code", "execution_count": 13, "id": "2f3534bc", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "2f3534bc", "executionInfo": {"status": "ok", "timestamp": 1763328798590, "user_tz": -60, "elapsed": 47, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "fd10eea9-9334-4722-cb1b-ed48db77f194"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Latest export:\n", "  - models/exports/ppo_quick_20251116_212857_quick_best.zip | 4.8 MB | 2025-11-16 21:32:32\n", "  - Meta: {'action_set': 'SIMPLE_MOVEMENT', 'frame_stack': 2, 'action_repeat': 2, 'reward_mode': 'spec'}\n", "\n", "Latest log:\n", "  - logs/_random/0.monitor.csv | 148.0 B | 2025-11-16 21:32:59\n", "  - Episodes: 4\n", "  - Timesteps: 289\n", "  - Mean reward over last 20: 45.50\n", "  - Best single-episode reward: 74.00\n", "\n", "Latest video:\n", "  - videos/_random/random_simple_movement-step-0-to-step-450.mp4 | 105.7 KB | 2025-11-16 21:33:05\n", "\n", "Reports (up to 5):\n", "  - reports/report_local.html | 2.9 KB | 2025-11-16 21:33:12\n", "  - reports/report_local.md | 2.3 KB | 2025-11-16 21:33:12\n", "\n", "No plots found.\n", "\n", "Status inspection complete.\n"]}], "source": ["\n", "from pathlib import Path\n", "import datetime as dt\n", "import json\n", "\n", "try:\n", "    import pandas as pd\n", "except Exception:\n", "    pd = None\n", "\n", "root = Path(base_dir)\n", "assert root.exists(), f\"The base_dir path does not exist: {base_dir}\"\n", "\n", "def fmt_ts(p: Path) -> str:\n", "    try:\n", "        return dt.datetime.fromtimestamp(p.stat().st_mtime).strftime(\"%Y-%m-%d %H:%M:%S\")\n", "    except Exception: return \"?\"\n", "def fmt_sz(n: int) -> str:\n", "    units = [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]; i=0; f=float(n)\n", "    while f>=1024 and i<len(units)-1: f/=1024; i+=1\n", "    return f\"{f:.1f} {units[i]}\"\n", "def newest(glob_iter):\n", "    files = sorted(glob_iter, key=lambda p: p.stat().st_mtime, reverse=True); return files[0] if files else None\n", "def short(p: Path):\n", "    try: return str(p.relative_to(root))\n", "    except Exception: return str(p)\n", "\n", "exp_dir = root/\"models\"/\"exports\"; latest_zip = newest(exp_dir.glob(\"*.zip\")) if exp_dir.exists() else None\n", "if latest_zip:\n", "    meta = {}\n", "    mp = latest_zip.with_suffix(\".meta.json\")\n", "    if mp.exists():\n", "        try: meta = json.loads(mp.read_text())\n", "        except Exception: pass\n", "    print(\"Latest export:\")\n", "    print(\"  -\", short(latest_zip), \"|\", fmt_sz(latest_zip.stat().st_size), \"|\", fmt_ts(latest_zip))\n", "    print(\"  - Meta:\", {k: meta.get(k) for k in (\"action_set\",\"frame_stack\",\"action_repeat\",\"reward_mode\")} if meta else \"(missing)\")\n", "else:\n", "    print(\"No latest export found.\")\n", "\n", "logs_dir = root/\"logs\"; latest_csv = newest(logs_dir.rglob(\"*.monitor.csv\")) if logs_dir.exists() else None\n", "if latest_csv and pd is not None:\n", "    print(\"\\nLatest log:\")\n", "    print(\"  -\", short(latest_csv), \"|\", fmt_sz(latest_csv.stat().st_size), \"|\", fmt_ts(latest_csv))\n", "    try:\n", "        df = pd.read_csv(latest_csv, comment=\"#\")\n", "        episodes = len(df); total_steps = int(df[\"l\"].sum()) if \"l\" in df else None\n", "        last20 = float(df[\"r\"].tail(20).mean()) if \"r\" in df and episodes>0 else None\n", "        best = float(df[\"r\"].max()) if \"r\" in df and episodes>0 else None\n", "        print(\"  - Episodes:\", episodes)\n", "        if total_steps is not None: print(\"  - Timesteps:\", total_steps)\n", "        if last20  is not None:    print(f\"  - Mean reward over last 20: {last20:.2f}\")\n", "        if best    is not None:    print(f\"  - Best single-episode reward: {best:.2f}\")\n", "    except Exception as e:\n", "        print(\"  - CSV parse failed:\", e)\n", "else:\n", "    print(\"\\nNo latest log or pandas unavailable.\")\n", "\n", "vid = newest((root/\"videos\").rglob(\"*.mp4\")) if (root/\"videos\").exists() else None\n", "if vid:\n", "    print(\"\\nLatest video:\")\n", "    print(\"  -\", short(vid), \"|\", fmt_sz(vid.stat().st_size), \"|\", fmt_ts(vid))\n", "else:\n", "    print(\"\\nNo latest video found.\")\n", "\n", "rep_dir = root/\"reports\"; reps = sorted(rep_dir.glob(\"report*.*\")) if rep_dir.exists() else []\n", "if reps:\n", "    print(\"\\nReports (up to 5):\")\n", "    for p in reps[:5]:\n", "        print(\"  -\", short(p), \"|\", fmt_sz(p.stat().st_size), \"|\", fmt_ts(p))\n", "else:\n", "    print(\"\\nNo reports found.\")\n", "\n", "plots_dir = root/\"plots\"; pl = sorted(plots_dir.glob(\"*\")) if root.joinpath(\"plots\").exists() else []\n", "if pl:\n", "    print(\"\\nPlots (up to 5):\")\n", "    for p in pl[:5]:\n", "        if p.is_file():\n", "            print(\"  -\", short(p), \"|\", fmt_sz(p.stat().st_size), \"|\", fmt_ts(p))\n", "else:\n", "    print(\"\\nNo plots found.\")\n", "\n", "print(\"\\nStatus inspection complete.\")\n"]}, {"cell_type": "markdown", "id": "036bbf61", "metadata": {"id": "036bbf61"}, "source": ["## S-SIZE) Size overview"]}, {"cell_type": "code", "execution_count": 14, "id": "f94843b0", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "f94843b0", "executionInfo": {"status": "ok", "timestamp": 1763328811662, "user_tz": -60, "elapsed": 29, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "83708d62-ad35-466f-f513-78525ee070f9"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Bundle candidate path: /content/mario_rl_local\n", "  - models/exports  9.6 MB\n", "  - models          19.3 MB\n", "  - logs            0.0 MB\n", "  - videos          0.1 MB\n", "  - plots           0.0 MB\n", "  - reports         0.0 MB\n", "\n", "Run S-LOCAL for a full zip or S-LOCAL-LITE for a minimal zip.\n"]}], "source": ["\n", "from pathlib import Path\n", "\n", "root = Path(base_dir); assert root.exists(), f\"The base_dir path does not exist: {base_dir}\"\n", "\n", "def fmt(n):\n", "    units = [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]; i=0; x=float(n)\n", "    while x>=1024 and i<len(units)-1: x/=1024; i+=1\n", "    return f\"{x:.1f} {units[i]}\"\n", "\n", "def dir_size(p: Path):\n", "    return sum(f.stat().st_size for f in p.rglob(\"*\") if p.is_dir() or f.is_file())\n", "\n", "total = sum(f.stat().st_size for f in root.rglob(\"*\") if f.is_file())\n", "print(f\"Bundle candidate path: {root}\")\n", "\n", "folders = [\"models/exports\",\"models\",\"logs\",\"videos\",\"plots\",\"reports\"]\n", "for sub in folders:\n", "    p = root/sub\n", "    if p.exists():\n", "        sz = sum(f.stat().st_size for f in p.rglob(\"*\") if f.is_file())\n", "        print(f\"  - {sub:<15} {sz/1024/1024:.1f} MB\")\n", "\n", "print(\"\\nRun S-LOCAL for a full zip or S-LOCAL-LITE for a minimal zip.\")\n"]}, {"cell_type": "markdown", "id": "abd772ea", "metadata": {"id": "abd772ea"}, "source": ["## S-LOCAL) Export - full bundle (ZIP)"]}, {"cell_type": "code", "execution_count": 15, "id": "41b37f8d", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 35}, "id": "41b37f8d", "executionInfo": {"status": "ok", "timestamp": 1763328824279, "user_tz": -60, "elapsed": 884, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "1c3ca9bb-98fc-45d1-d75c-7856d2f6ebfb"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Full bundle zip created: /content/mario_artifacts.zip\n"]}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.Javascript object>"], "application/javascript": ["\n", "    async function download(id, filename, size) {\n", "      if (!google.colab.kernel.accessAllowed) {\n", "        return;\n", "      }\n", "      const div = document.createElement('div');\n", "      const label = document.createElement('label');\n", "      label.textContent = `Downloading \"${filename}\": `;\n", "      div.appendChild(label);\n", "      const progress = document.createElement('progress');\n", "      progress.max = size;\n", "      div.appendChild(progress);\n", "      document.body.appendChild(div);\n", "\n", "      const buffers = [];\n", "      let downloaded = 0;\n", "\n", "      const channel = await google.colab.kernel.comms.open(id);\n", "      // Send a message to notify the kernel that we're ready.\n", "      channel.send({})\n", "\n", "      for await (const message of channel.messages) {\n", "        // Send a message to notify the kernel that we're ready.\n", "        channel.send({})\n", "        if (message.buffers) {\n", "          for (const buffer of message.buffers) {\n", "            buffers.push(buffer);\n", "            downloaded += buffer.byteLength;\n", "            progress.value = downloaded;\n", "          }\n", "        }\n", "      }\n", "      const blob = new Blob(buffers, {type: 'application/binary'});\n", "      const a = document.createElement('a');\n", "      a.href = window.URL.createObjectURL(blob);\n", "      a.download = filename;\n", "      div.appendChild(a);\n", "      a.click();\n", "      div.remove();\n", "    }\n", "  "]}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.Javascript object>"], "application/javascript": ["download(\"download_cff0dfab-37b3-4c40-85ec-59bd0daab71b\", \"mario_artifacts.zip\", 14751338)"]}, "metadata": {}}], "source": ["\n", "from pathlib import Path\n", "from google.colab import files\n", "import shutil\n", "\n", "assert Path(base_dir).exists(), \"base_dir does not exist. Run B-LOCAL first.\"\n", "\n", "zip_path = \"/content/mario_artifacts.zip\"\n", "if Path(zip_path).exists():\n", "    Path(zip_path).unlink()\n", "\n", "shutil.make_archive(\"/content/mario_artifacts\", \"zip\", base_dir)\n", "print(\"Full bundle zip created:\", zip_path)\n", "files.download(zip_path)\n"]}, {"cell_type": "markdown", "id": "7e56acee", "metadata": {"id": "7e56acee"}, "source": ["## S-LOCAL-LITE) Export - minimal bundle (ZIP)"]}, {"cell_type": "code", "execution_count": null, "id": "9d78a0a9", "metadata": {"id": "9d78a0a9"}, "outputs": [], "source": ["\n", "from pathlib import Path\n", "from google.colab import files\n", "import json, shutil\n", "\n", "root = Path(base_dir)\n", "out_dir = Path(\"/content/mario_minimal_bundle\")\n", "if out_dir.exists():\n", "    shutil.rmtree(out_dir)\n", "(out_dir / \"models/exports\").mkdir(parents=True, exist_ok=True)\n", "(out_dir / \"videos\").mkdir(parents=True, exist_ok=True)\n", "(out_dir / \"plots\").mkdir(parents=True, exist_ok=True)\n", "(out_dir / \"reports\").mkdir(parents=True, exist_ok=True)\n", "\n", "def newest(glob):\n", "    files = sorted(glob, key=lambda p: p.stat().st_mtime, reverse=True)\n", "    return files[0] if files else None\n", "\n", "exp = newest((root/\"models\"/\"exports\").glob(\"*.zip\"))\n", "if exp:\n", "    shutil.copy2(exp, out_dir/\"models/exports\"/exp.name)\n", "    meta = exp.with_suffix(\".meta.json\")\n", "    if meta.exists():\n", "        shutil.copy2(meta, out_dir/\"models/exports\"/meta.name)\n", "\n", "vid = newest((root/\"videos\").rglob(\"*.mp4\"))\n", "if vid:\n", "    shutil.copy2(vid, out_dir/\"videos\"/vid.name)\n", "\n", "for p in (root/\"plots\").glob(\"*\"):\n", "    if p.is_file():\n", "        shutil.copy2(p, out_dir/\"plots\"/p.name)\n", "\n", "for r in (root/\"reports\").glob(\"report*.*\"):\n", "    shutil.copy2(r, out_dir/\"reports\"/r.name)\n", "\n", "zip_path = \"/content/mario_minimal_bundle.zip\"\n", "if Path(zip_path).exists():\n", "    Path(zip_path).unlink()\n", "shutil.make_archive(\"/content/mario_minimal_bundle\", \"zip\", out_dir)\n", "print(\"Minimal bundle zip created:\", zip_path)\n", "files.download(zip_path)\n"]}, {"cell_type": "markdown", "id": "52447aa6", "metadata": {"id": "52447aa6"}, "source": ["## J) Evaluation (N episodes)"]}, {"cell_type": "code", "execution_count": 16, "id": "4a2c9d8f", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4a2c9d8f", "executionInfo": {"status": "ok", "timestamp": 1763328836650, "user_tz": -60, "elapsed": 3529, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "c916deb1-a651-4a0d-9763-b965c4df713a"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["DummyVecEnv created: 1\n", "VecDropResetKwargs active.\n"]}, {"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.12/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n", "  if not isinstance(terminated, (bool, np.bool8)):\n", "/tmp/ipython-input-738992027.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n", "  total += float(reward)\n"]}, {"output_type": "stream", "name": "stdout", "text": ["Evaluation: episodes=5, mean=33.00, std=0.00, scores=[33.0, 33.0, 33.0, 33.0, 33.0]\n"]}], "source": ["\n", "import numpy as np, json\n", "from stable_baselines3 import PPO\n", "from pathlib import Path\n", "\n", "def find_latest_export_zip(base_dir_str):\n", "    ex = sorted((Path(base_dir_str)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    return str(ex[0]) if ex else None\n", "\n", "model_zip = find_latest_export_zip(base_dir); assert model_zip, 'No exported model was found.'\n", "action_set_eval = 'SIMPLE_MOVEMENT'\n", "mp = Path(model_zip).with_suffix('.meta.json')\n", "if mp.exists():\n", "    try:\n", "        j=json.loads(mp.read_text()); action_set_eval=j.get('action_set',action_set_eval)\n", "    except Exception: pass\n", "\n", "eval_env = make_vector_env(1, f\"{base_dir}/logs/_eval\", None,\n", "                           action_set=action_set_eval, frame_skip=2,\n", "                           action_repeat=int(globals().get('action_repeat',2)),\n", "                           frame_stack=int(globals().get('frame_stack',2)),\n", "                           prefer_subproc=False)\n", "model = PPO.load(model_zip, env=eval_env, device=('cuda' if torch.cuda.is_available() else 'cpu'))\n", "N=5; returns=[]; obs = eval_env.reset()\n", "for ep in range(N):\n", "    done=np.array([False]); total=0.0\n", "    while not done.any():\n", "        action,_ = model.predict(obs, deterministic=True)\n", "        obs, reward, done, _ = eval_env.step(action)\n", "        total += float(reward)\n", "    returns.append(total)\n", "    obs = eval_env.reset()\n", "eval_env.close()\n", "print(f'Evaluation: episodes={N}, mean={np.mean(returns):.2f}, std={np.std(returns):.2f}, scores={returns}')\n"]}, {"cell_type": "markdown", "id": "46f1bf76", "metadata": {"id": "46f1bf76"}, "source": ["## J2) Evaluation with explicit distance (N episodes)"]}, {"cell_type": "code", "execution_count": 17, "id": "a6220c3d", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "a6220c3d", "executionInfo": {"status": "ok", "timestamp": 1763328845160, "user_tz": -60, "elapsed": 3435, "user": {"displayName": "Sara Persson", "userId": "02692616265797696959"}}, "outputId": "41be899c-ab0c-4908-8df0-4b3d27120120"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["DummyVecEnv created: 1\n", "VecDropResetKwargs active.\n"]}, {"output_type": "stream", "name": "stderr", "text": ["/tmp/ipython-input-2226529747.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n", "  total += float(reward)\n"]}, {"output_type": "stream", "name": "stdout", "text": ["Episodes=5\n", "Mean reward     = 33.00 (std 0.00)\n", "Mean x distance = 297.0 (per-episode: [297, 297, 297, 297, 297])\n"]}], "source": ["\n", "import numpy as np, json, torch\n", "from stable_baselines3 import PPO\n", "from pathlib import Path\n", "\n", "def find_latest_export_zip(base_dir_str):\n", "    ex = sorted((Path(base_dir_str)/'models'/'exports').glob('*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)\n", "    return str(ex[0]) if ex else None\n", "\n", "model_zip = find_latest_export_zip(base_dir); assert model_zip, 'No exported model was found.'\n", "action_set_eval = 'SIMPLE_MOVEMENT'\n", "mp = Path(model_zip).with_suffix('.meta.json')\n", "if mp.exists():\n", "    try:\n", "        j=json.loads(mp.read_text()); action_set_eval=j.get('action_set',action_set_eval)\n", "    except Exception: pass\n", "\n", "eval_env = make_vector_env(1, f\"{base_dir}/logs/_eval_distance\", None,\n", "                           action_set=action_set_eval, frame_skip=2,\n", "                           action_repeat=int(globals().get('action_repeat',2)),\n", "                           frame_stack=int(globals().get('frame_stack',2)),\n", "                           prefer_subproc=False)\n", "model = PPO.load(model_zip, env=eval_env, device=('cuda' if torch.cuda.is_available() else 'cpu'))\n", "N=5; returns=[]; distances=[]; obs = eval_env.reset()\n", "for ep in range(N):\n", "    done=np.array([False]); total=0.0; x_max=0\n", "    while not done.any():\n", "        action,_ = model.predict(obs, deterministic=True)\n", "        obs, reward, done, infos = eval_env.step(action)\n", "        total += float(reward)\n", "        x = infos[0].get('x_pos', 0)\n", "        if x > x_max: x_max = x\n", "    returns.append(total); distances.append(x_max)\n", "    obs = eval_env.reset()\n", "eval_env.close()\n", "print(f'Episodes={N}')\n", "print(f'Mean reward     = {np.mean(returns):.2f} (std {np.std(returns):.2f})')\n", "print(f'Mean x distance = {np.mean(distances):.1f} (per-episode: {distances})')\n"]}, {"cell_type": "markdown", "id": "1d832e87", "metadata": {"id": "1d832e87"}, "source": ["## U-LOCAL-PACK) Prepare GitHub-ready zip (NO tokens)"]}, {"cell_type": "code", "execution_count": null, "id": "a0f18ee1", "metadata": {"id": "a0f18ee1"}, "outputs": [], "source": ["# U-LOCAL-PACK) Prepare GitHub-ready zip (NO tokens) \u2014 with self-capture fallback\n", "from pathlib import Path\n", "from google.colab import files\n", "import shutil, textwrap, json\n", "\n", "BASE = \"/content/mario_rl_local\"\n", "NB_DEFAULT = \"/content/Mario_RL_PPO_Local_TrainingSuite.ipynb\"\n", "\n", "def ensure_notebook_on_disk(nb_target:str):\n", "    \"\"\"Ensure the current Colab notebook exists as a file on /content.\n", "    If not present, capture the in-memory notebook via Colab's internal API.\"\"\"\n", "    p = Path(nb_target)\n", "    if p.exists():\n", "        print(\"Found existing notebook file:\", p)\n", "        return p\n", "    # Try to capture the current notebook from Colab\n", "    try:\n", "        from google.colab import _message\n", "        data = _message.blocking_request('get_ipynb', timeout_sec=120)\n", "        name = (data.get('metadata', {})\n", "                    .get('colab', {})\n", "                    .get('name', 'ColabNotebook')).strip().replace(' ', '_')\n", "        out = Path('/content') / f\"{name}.ipynb\"\n", "        out.write_text(json.dumps(data), encoding='utf-8')\n", "        print(\"Saved current notebook snapshot to:\", out)\n", "        return out\n", "    except Exception as e:\n", "        print(\"Could not auto-capture the current notebook:\", repr(e))\n", "        return None\n", "\n", "# 0) Make publish dir\n", "pub = Path(\"/content/mario_publish_local\")\n", "if pub.exists():\n", "    shutil.rmtree(pub)\n", "(pub / \"reports\").mkdir(parents=True, exist_ok=True)\n", "\n", "# 1) Notebook: ensure it exists, then copy\n", "nb_path = ensure_notebook_on_disk(NB_DEFAULT)\n", "assert nb_path and nb_path.exists(), (\n", "    \"Could not find or export the current notebook. \"\n", "    \"Try: File \u2192 Save, then re-run this cell.\"\n", ")\n", "shutil.copy2(nb_path, pub / nb_path.name)\n", "\n", "# 2) Reports (if generated in section G)\n", "rep_src = Path(BASE) / \"reports\"\n", "if rep_src.exists():\n", "    for p in rep_src.glob(\"report_local.*\"):\n", "        shutil.copy2(p, pub / \"reports\" / p.name)\n", "\n", "# 3) .gitignore (exclude heavy artifacts)\n", "(pub / \".gitignore\").write_text(textwrap.dedent(\"\"\"\\\n", "models/\n", "videos/\n", "logs/\n", "plots/\n", "*.zip\n", "*.mp4\n", "*.avi\n", "*.mov\n", "*.pth\n", "*.pt\n", ".DS_Store\n", ".ipynb_checkpoints/\n", "\"\"\"), encoding=\"utf-8\")\n", "\n", "# 4) README\n", "(pub / \"README.md\").write_text(textwrap.dedent(\"\"\"\\\n", "# Mario RL PPO \u2014 Local Training Suite\n", "\n", "This repository contains:\n", "- The Colab notebook (end-to-end training and evaluation)\n", "- Generated report(s) in `reports/` (create via section G in the notebook)\n", "\n", "## How to run (Colab)\n", "1. Run A1 (pin NumPy) and restart the runtime.\n", "2. Run A2\u2013A3, then B-LOCAL.\n", "3. Train via T (quick) or D (full).\n", "4. Generate metrics (E/J/J2) and report (G).\n", "\n", "Default action set: `SIMPLE_MOVEMENT`\n", "Default reward mode: `spec` (+1 on forward step, -15 on death).\n", "\"\"\"), encoding=\"utf-8\")\n", "\n", "# 5) requirements.txt (minimal)\n", "(pub / \"requirements.txt\").write_text(textwrap.dedent(\"\"\"\\\n", "numpy==1.26.4\n", "gymnasium==0.29.1\n", "gym==0.26.2\n", "shimmy\n", "nes-py==8.2.1\n", "gym-super-mario-bros==7.4.0\n", "stable-baselines3\n", "imageio\n", "imageio-ffmpeg\n", "moviepy\n", "pillow\n", "markdown\n", "pandas\n", "matplotlib\n", "\"\"\"), encoding=\"utf-8\")\n", "\n", "# 6) Zip and download\n", "zip_path = \"/content/mario_publish_local.zip\"\n", "if Path(zip_path).exists():\n", "    Path(zip_path).unlink()\n", "shutil.make_archive(\"/content/mario_publish_local\", \"zip\", pub)\n", "print(\"Created:\", zip_path)\n", "files.download(zip_path)\n"]}, {"cell_type": "markdown", "id": "f36dbd7c", "metadata": {"id": "f36dbd7c"}, "source": ["## P) Cleanup"]}, {"cell_type": "code", "execution_count": null, "id": "4c9d6f31", "metadata": {"id": "4c9d6f31"}, "outputs": [], "source": ["\n", "import gc, torch\n", "try:\n", "    if 'venv' in globals(): venv.close()\n", "    if 'eval_env' in globals(): eval_env.close()\n", "except Exception as e:\n", "    print('Info: env close raised:', e)\n", "for name in ['model','venv','eval_env']:\n", "    if name in globals(): del globals()[name]\n", "gc.collect()\n", "try:\n", "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n", "except Exception: pass\n", "print('Cleanup complete.')\n"]}], "metadata": {"colab": {"provenance": [], "toc_visible": true, "gpuType": "T4"}, "kernelspec": {"display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}, "accelerator": "GPU"}, "nbformat": 4, "nbformat_minor": 5}}